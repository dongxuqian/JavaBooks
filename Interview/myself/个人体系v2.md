# 自我介绍
- 面试官您好，我叫买峰，来自电子科技大学2018届应届硕士生，所学专业为软件工程。

- 首先在项目经历上，做了3个科研项目、2个自主研发项目（其中有一个自主研发项目是我最近分析本学校的一个班车预约平台并重新采用新的技术栈进行研发）。其次，在校期间也撰写了4个软件著作权。最后，在科研方面的方式属于深度学习中的音乐分离方向，同时发表了一篇会议论文。

- 平时比较喜欢关注互联网新技术，比如在今日头条、掘金、知乎和微信公众号上。其次，我会将自己的感受撰写文章发布在自己的博客、掘金和微信公众号上分享给大家。

- 最后，平时也喜欢听歌跑步陶冶自己的情操和锻炼自己的身体。

# Java

## Java基础
### 8大基础类型

![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-15/86735519.jpg)

- 装箱：将基本类型用它们对应的**引用类型**包装起来；
- 拆箱：将包装类型转换为**基本数据类型**；
- valueOf
    ```java
    // This method will always cache values in the range -128 to 127,
    public static Integer valueOf(int i) {
        if (i >= IntegerCache.low && i <= IntegerCache.high) // 条件
            return IntegerCache.cache[i + (-IntegerCache.low)];// 取缓存，
            // Integeer的源码中：
            // static final int low = -128; IntegerCache.low = -128
        return new Integer(i);
    }
    ```
> 当使用自动装箱方式创建一个Integer对象时，当数值在-128 ~127时，会将创建的 Integer 对象缓存起来，当下次再出现该数值时，直接从缓存中取出对应的Integer对象。所以上述代码中，x和y引用的是相同的Integer对象。

### ==、equals和hashcode

#### ==
它的作用是**判断两个对象的地址是不是相等**。即，判断两个对象是不是同一个对象：

- 基本数据类型==比较的是**值** 
- 引用数据类型==比较的是**内存地址**

#### equals
它的作用也是判断两个对象是否相等。但它一般有两种使用情况：

- 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过`==`比较这两个对象。
- 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。

举个hashset的例子

### 面向对象
#### 封装
封装把一个对象的**属性私有化**，同时提供一些可以**被外界访问的属性的方法**。

#### 继承
继承是使用**已存在的类**的定义作为基础建立新类的技术，新类的定义可以增加**新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类**。通过使用继承我们能够非常方便地复用以前的代码。

注意：
- 子类拥有父类对象**所有的属性和方法**（包括私有属性和私有方法），但是**父类中的私有属性和方法子类是无法访问，只是拥有**。
- 子类可以拥有自己属性和方法，即子类可以对父类进行**扩展**。
- 子类可以用自己的方式实现父类的方法。（以后介绍）。

#### 多态

三要素：加黑的地方！

首先我觉得即**一个引用变量到底会指向哪个类的实例对象**，该**引用变量发出的方法调用到底是哪个类中实现的方法**，必须在由程序**运行期间**才能决定。

举个例子：

任何事物的多个姿态，多个形态。比如，你说一个猫在吃东西，同样的，你也能说一个动物在吃东西。

```java

public class Test {
    public static void main(String[] args){
        Animal animal = new Cat();
        animal.eat() // 猫也会吃饭
        // 你看到了一只猫，同样它也是动物
        // 比如有很多其他种类继承了动物哈，
        // 当编译期间的animal引用变量，到底指的哪个实例对象，（重要）（主语是引用变量）
        // 或者该引用调用的eat方法，到底是哪个实例对象的eat，编译期间恐怕不知道哦（主语是引用变量）
        // 只有运行期间，哦哦， 原来是猫的eat方法哇...
    }
}
```

##### 表现形式

所以多态的表现形式：

- **Java的方法重载，就是在类中可以创建多个方法，它们具有相同的名字，但可具有不同的参数列表、返回值类型。调用方法时通过传递的参数类型来决定具体使用哪个方法**，这就是多态性。
- **Java的方法重写，是父类与子类之间的多态性，子类可继承父类中的方法，但有时子类并不想原封不动地继承父类的方法，而是想作一定的修改，这就需要采用方法的重写。重写的参数列表和返回类型均不可修改**。这也是多态性。

##### 底层

首先要说：首先当程序运行需要某个类时，类加载器会将相应的class文件载入到JVM中，并在方法区建立该类的类型信息（包括方法代码，类变量、成员变量以及**方法表**。（标黑的这个玩意）



面试官：方法表有啥？

我：方法表的结构如同字段表一样，依次包括了**访问标志、名称索引、描述符索引、属性表集合**几项。

接着回答：**方法表是实现动态调用的核心。为了优化对象调用方法的速度，方法区的类型信息会增加一个指针，该指针指向记录该类方法的方法表，方法表中的每一个项都是对应方法的指针**。

到这里：就要分情况讨论了，一个是方法调用，一个是接口

###### 方法调用

先说方法调用：举个例子

```java
class Person {
    // 重写object的toString
    public String toString(){
        return "I'm a person.";
    }
    public void eat(){}
    public void speak(){}

}

class Boy extends Person{
    // 重写object的toString
    public String toString(){
        return "I'm a boy";
    }
    // 继承Person的speak
    public void speak(){}
    // 自己实现的自定义方法
    public void fight(){}
}

class Girl extends Person{
    // 重写object的toString
    public String toString(){
        return "I'm a girl";
    }
    // 继承Person的speak
    public void speak(){}
    // 自己实现的自定义方法
    public void sing(){}
}
```

![参考](https://imgkr.cn-bj.ufileos.com/aba89335-fb8c-44b8-84ea-ff6a0bfa9548.png)

这张图的指向：你可以根据颜色对应上，注意方法表条目指向的具体的**方法地址**。其次注意蓝色部分其继承自于 Person 的方法 eat() 和 speak() 分别指向 **Person 的方法实现和本身的实现**。如果子类改写了父类的方法，那么子类和父类的那些**同名的方法共享一个方法表项**。因此，**所有继承父类的子类的方法表中，其父类所定义的方法的偏移量也总是一个定值**。Person 或 Object中的任意一个方法，在它们的方法表和其子类 Girl 和 Boy 的方法表中的位置 (index) 是一样的。这样 JVM 在调用实例方法其实只需要指定调用方法表中的第几个方法即可。



调用过程：

1. 在常量池里找到方法调用的**符号引用**（肯定先看到Person定义引用类型） 
2. 查看Person的方法表，得到speak方法在该**方法表的偏移量**（假设为15），这样就得到该方法的直接引用。 
3. 根据this（invoker this字节码）指针得到**具体的对象**（即 girl 所指向的位于堆中的对象）。
4. 根据对象得到该对象对应的方法表，根据偏移量15查看**有无重写（override）该方法**，如果重写，则可以直接调用（Girl的方法表的speak项指向自身的方法而非父类）；如果没有重写，则需要拿到按照继承关系从下往上的基类（这里是Person类）的方法表，同样按照这个偏移量15查看有无该方法。



###### 接口调用

一个类可以实现多个接口，那么就像多继承一样，这样的话，在方法表中的索引就会不一样，所以Java 对于接口方法的调用是采用**搜索方法表**的方式。

补充一下：


#### 重载和重写的区别
- 重载：发生在同一个类中，**方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同**。
- 重写：重写是子类对父类的允许访问的方法的实现过程进行重新编写,发生在子类中，**方法名、参数列表必须相同，返回值范围小于等于父类**，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。另外，如果父类方法访问修饰符为 private 则子类就不能重写该方法。也就是说方法提供的行为改变，而方法的外貌并没有改变。

#### 接口和抽象类的区别
1. 方法是否能实现：所有**方法在接口中不能有实现**(Java 8 开始接口方法可以有默认实现），而**抽象类可以有非抽象的方法**。
2. 变量：接口中除了**static、final变量**，不能有其他变量，而抽象类中则不一定。
3. 实现：一个类可以实现**多个接口**，但**只能实现一个抽象类**。接口自己本身可以通过implement关键字扩展多个接口。
4. 修饰符：接口方法默认修饰符是public，抽象方法可以有public、protected和default这些修饰符（抽象方法就是为了被重写所以不能使用private关键字修饰！）。

#### [匿名内部类传参数为什么需要final](https://blog.csdn.net/tianjindong0804/article/details/81710268?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight)

### String
#### String StringBuffer 和 StringBuilder 的区别是什么?
1. 可变性

- 简单的来说：`String` 类中使用 `final` 关键字修饰字符数组来保存字符串，`private　final　char　value[]`，所以 `String` 对象是不可变的。
- `StringBuilder` 与 `StringBuffer` 都继承自 `AbstractStringBuilder` 类，在 `AbstractStringBuilder` 中也是使用字符数组保存字符串char[]value 但是没有用 `final` 关键字修饰，所以这两种对象都是可变的。

2. 线程安全
- `String` 中的对象是不可变的，也就可以理解为常量，线程安全。
- `AbstractStringBuilder` 是 `StringBuilder` 与 `StringBuffer` 的公共父类，定义了一些字符串的基本操作，如 `expandCapacity`、`append`、`insert`、`indexOf` 等公共方法。`StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的。


3. 性能
- 每次对 `String` 类型进行改变的时候，都会生成一个新的 `String` 对象，然后将指针指向新的 `String` 对象。
- `StringBuffer` 每次都会对 `StringBuffer` 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 `StringBuilder` 相比使用 `StringBuffer` 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。


- 操作少量的数据: 适用String
- 单线程操作字符串缓冲区下操作大量数据: 适用StringBuilder
- 多线程操作字符串缓冲区下操作大量数据: 适用StringBuffer

#### String对象和常量池
```java
public class StringTest {
    public static void main(String[] args) {
        String str1 = "todo"; // 常量池
        String str2 = "todo"; // 从常量池找了str1
        String str3 = "to"; // 常量池
        String str4 = "do"; // 常量池
        String str5 = str3 + str4; // 内部用StringBuilder拼接了一波。 因此， 并非常量池
        String str6 = new String(str1); //  创建对象了， 那还能是常量池的引用？
    }
}
```

分析一波：
- 成的class文件中会在常量池中**保存“todo”、“to”和“do”三个String常量**。
- 变量str1和str2均保存的是常量池中“todo”的引用，所以str1==str2成立；
- 在执行 str5 = str3 + str4这句时，**JVM会先创建一个StringBuilder对象，通过StringBuilder.append()方法将str3与str4的值拼接**，然后通过StringBuilder.toString()返回一个堆中的String对象的引用，赋值给str5，因此str1和str5指向的不是同一个String对象，str1 == str5不成立；
- String str6 = new String(str1)一句显式创建了一个新的String对象，因此str1 == str6不成立便是显而易见的事了。

#### intern
- jdk6：
执行intern()方法时，**若常量池中不存在等值的字符串，JVM就会在常量池中创建一个等值的字符串，然后返回该字符串的引用**。
- jdk7：
执行intern操作时，如果常量池已经存在该字符串，则直接返回字符串引用，否则**复制该字符串对象的引用到常量池中并返回**。

### 关键字
#### final
final关键字主要用在三个地方：变量、方法、类。

- 对于一个final变量，如果是**基本数据类型的变量，则其数值一旦在初始化之后便不能更改**；如果是引用类型的变量，则在对其初始化之后便**不能再让其指向另一个对象**。
- 当用final修饰一个类时，表明**这个类不能被继承**。final类中的所有成员方法都会被隐式地指定为final方法。
- 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现在的Java版本已经不需要使用final方法进行这些优化了）。类中所有的private方法都隐式地指定为final。

final修饰有啥好处

- final的关键字**提高了性能**，JVM和java应用会**缓存final变量**；
- final变量可以在多线程环境下保持**线程安全**；
- 使用final的关键字提高了性能，JVM会对方法变量类进行优化；

#### static
- **修饰成员变量和成员方法:** 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议通过类名调用。被static 声明的成员变量属于静态成员变量，静态变量存放在 Java 内存区域的方法区。调用格式：`类名.静态变量名` `类名.静态方法名()`
- **静态代码块:** 静态代码块定义在类中方法外, 静态代码块在非静态代码块之前执行(静态代码块—>非静态代码块—>构造方法)。 该类不管创建多少对象，静态代码块只执行一次.
- **静态内部类（static修饰类的话只能修饰内部类）：** 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：1. 它的创建是不需要依赖外围类的创建。2. 它不能使用任何外围类的非static成员变量和方法。
- **静态导包(用来导入类中的静态资源，1.5之后的新特性):** 格式为：`import static` 这两个关键字连用可以指定导入某个类中的指定静态资源，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。

### Java值传递
下面再总结一下 Java 中方法参数的使用情况：

- 一个方法**不能修改一个基本数据类型的参数**（即数值型或布尔型）。
- 一个方法可以改变**一个对象参数的状态**。
- 一个方法**不能让对象参数引用一个新的对象**。

[个人写的例子](https://dreamcater.gitee.io/javabooks/#/codes/Java%E5%80%BC%E4%BC%A0%E9%80%92%E7%9A%84%E9%97%AE%E9%A2%98)

### 异常
#### Error

面试官：给我讲讲什么是Error？

我：其实就是明显的给自己挖坑，哈能咋滴！**Error描述了Java运行时系统的内部错误和资源耗尽错误，你比如栈溢出和堆溢出啦**？不好，面试官微笑了。

面试官：讲一下什么是栈溢出和堆溢出？

我：哎，中枪了，这咋害能扯到虚拟机上了

- StackOverFlowError：**如果线程请求的栈深度大于虚拟机所允许的深度**，将抛出此异常。比如，**无限递归方法**，其实面试官按捺不住的问

面试官：为什么无限递归方法就可以抛出该异常？

我：因为我们知道，**每次调用方法所产生资源都存放在了虚拟机栈中**，如果无限递归下去，那岂不是？

面试官：虚拟机栈存了什么资源？

我：我真的是！虚拟机栈存了**局部变量表、操作数栈、动态链接和方法出口**。

面试官：局部变量表中存了什么？

我：啊？还好我会，存放了编译期可知的各种**基本数据类型(8大基本类型)**，**对象引用类型**，它不等同于对象本身，可能是一个指向对象**起始地址的引用指针**，也可能是指向一个**代表对象的句柄或其他与此对象相关的位置**。

面试官：好，开始讲堆溢出

我：害能给我绕回来...如果**虚拟机可动态扩展，如果扩展时无法申请到足够的内存**，就会抛出OutOfMemoryError异常，当然，**如果在堆中没有内存完成实例分配，并且堆也无法再扩展时**，也会抛出该异常。比如，我又挖坑，举例子：无限创建线程。这次我主动说原因：操作系统分配给每个进程内存是有限的，比如32位的windows限制为2G。虚拟机提供了参数来控制堆和方法区的内存的最大值，而剩下的内存，忽略其他因素，就由虚拟机栈和本地方法栈“瓜分天下了”。**每个线程分配到栈容越大，可以建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽。**

面试官：**嘿嘿，方法区会溢出吗？**

我：嘿嘿，会。比如方法区中有一个**运行时常量池**，晓得吧？其中String.intern()方法是一个native方法，它(1.6)的作用是：如果字符串常量池中已经包含了此String对象的字符串，则返回代表池中这个字符串String对象；**否则，将此String对象所包含的字符串添加到常量池中，并且返回此String对象的引用**。在1.7版本就不一样了，**而是从堆中实例String对象的引用复制到常量池并返回**。当然，还有很多带有**反射**机制的框架，大量使用反射创建类来填满方法区。

面试官：嘿嘿，直接内存会溢出吗？

我：简直了，太能问了。那肯定也是能的哦，比如DirectByteBuffer。

#### Exception

面试官：可以了，聊Exception

我：无限退出递模式！Exception又分解为**RuntimeException**（运行时）和程序本身没有问题，由于像IO错误这类问题导致的异常（编译）。

面试官：RuntimeException中有哪些，举一些？

我：好的，比如，NullPointerException，ArithmeticException，ClassCastException，ArrayIndexOutOfBoundsException等

面试官：什么是受检异常和非受检异常？

我：派生于**Error类或RuntimeException类**的所有异常称为非受检异常，所有其他的异常称为受检异常。

#### 捕获异常

面试官：如何捕获异常？

我：

- `try` 块： 用于捕获异常。其后可接零个或多个`catch`块，如果没有`catch`块，则必须跟一个`finally`块。

- `catch` 块： 用于处理`try`捕获到的异常。

- `finally` 块： 无论是否捕获或处理异常，`finally`块里的语句都会被执行。当在`try`块或`catch`块中遇到`return`语句时，`finally`语句块将在方法返回之前被执行。

throw 抛出异常,throws是方法可能抛出异常的声明。(用在声明方法时，表示该方法可能要抛出异常)



[https://blog.csdn.net/efei7968/article/details/87077218](https://blog.csdn.net/efei7968/article/details/87077218)

[https://blog.csdn.net/efei7968/article/details/87174324?](https://blog.csdn.net/efei7968/article/details/87174324?)

### IO
#### BIO
**BIO (Blocking I/O)**:**同步阻塞I/O模式**，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。

#### NIO
**NIO (New I/O)**:NIO是一种**同步非阻塞的I/O模型**，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 `Channel` , `Selector`，`Buffer`等抽象。NIO中的N可以理解为`Non-blocking`，不单纯是New。它支持**面向缓冲**的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。

[NIO底层原理](https://blog.csdn.net/u013857458/article/details/82424104)

#### AIO
**AIO (Asynchronous I/O)**: AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是**异步非阻塞的IO模型**。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。

### 反射

> 面试遇到这个问题，必须好好的想想如何回答这个问题

反射三要素？

面试官：反射是什么？

我：在Java的反射机制中是指在**运行状态**中，对于任意一个类都能够知道这个类所有的**属性和方法**；并且对于任意一个对象，都能够调用它的**任意一个方法**；这种**动态获取信息以及动态调用对象方法**的功能成为 Java 语言的反射机制。

面试官：哦？有什么好处？

我：怎么说呢，跟多态是的，比如在Java程序中许多对象在运行是都会出现两种类型：**编译时类型和运行时类型**。其中，编译时类型由**声明对象时使用的类型来决定**，运行时的类型由**实际赋值给对象的类型决定** 。比如

`People = = new Man();`程序在运行的时候，有时候需要注入外部资源，那么这个外部资源在编译时是object，如果想要它的运行时类型中的某个方法，为了解决这些问题，程序在运行时发现对象和类的真实信息，但是编译时根本无法预知该对象和类属于哪些类，程序只能靠运行时信息来发现该对象和类的信息，那就要用到反射了。

面试官：举几个反射的API

我：

1.  Class 类：反射的核心类，可以获取类的属性，方法等信息。
2. Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。
3. Method 类： Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法。
4. Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法

面试官：获取class对象的三种方式？

我：

```java

Student student = new Student(); *// 这一new 产生一个Student对象，一个Class对象。*

Class studentClass2 = Student.class; // 调用某个类的 class 属性来获取该类对应的 Class 对象

Class studentClass3 = Class.forName("com.reflect.Student") // 使用 Class 类中的 forName() 静态方法 ( 最安全 / 性能最好 )

```

面试官：三者区别？

我：

- Class.class 的形式会使 JVM 将使用类装载器将类装入内存（前提是类还没有装入内存），不做类的初始化工作，返回 Class 对象。
- Class.forName() 的形式会装入类并做类的静态初始化，返回 Class 对象。
- getClass() 的形式会对类进行静态初始化、非静态初始化，返回引用运行时真正所指的对象（因为子对象的引用可能会赋给父对象的引用变量中）所属的类的 Class 对象。

> 静态属性初始化是在加载类的时候初始化，而非静态属性初始化是 new 类实例对象的时候初始化。它们三种情况在生成 Class 对象的时候都会先判断内存中是否已经加载此类。

面试官：除了通过反射创建对象，还有？

我：new呗，clone一个呗

面试官：反射都有哪些应用场景

我：我可以说Spring，Dubbo，RocketMQ吗？这些优秀的框架背后都用到了反射，这说明，反射的优点之一灵活，提高了代码的灵活度，但同时性能受损。因为反射要进行一系列的解释操作。



[https://www.cnblogs.com/chanshuyi/p/head_first_of_reflection.html](https://www.cnblogs.com/chanshuyi/p/head_first_of_reflection.html)

### 深浅拷贝
- **浅拷贝**：对**基本数据类型进行值传递**，对**引用数据类型进行引用传递般的拷贝**，此为浅拷贝。
- **深拷贝**：对**基本数据类型进行值传递**，对**引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝**
- 也就二者对引用数据类型有区别

[个人写的例子](https://dreamcater.gitee.io/javabooks/#/codes/%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%BE%8B%E5%AD%90)

### Object
```java
public final native Class<?> getClass();
public native int hashCode(); // 返回对象的哈希代码值。
public boolean equals(Object obj) 
protected native Object clone() // 创建并返回此对象的副本。
public String toString() // 返回对象的字符串表示形式。
public final native void notify(); // 唤醒正在该对象的监视器上等待的单个线程。
public final native void notifyAll(); // 唤醒正在该对象的监视器上等待的全部线程。
public final native void wait(); // 使当前线程等待，直到另一个线程调用此对象的方法或方法。
protected void finalize(); // 当垃圾回收确定不再有对对象的引用时，由对象上的垃圾回收器调用。
```

### 四种修饰符的限制范围
1. public：可以被所有其他类所访问。

2. private：只能被自己访问和修改。

3. protected：自身，子类及同一个包中类可以访问。

4. default（默认）：同一包中的类可以访问

### 序列化
1. 所有需要网络传输的对象都需要实现序列化接口，通过建议所有的javaBean都实现Serializable接口。
2. 对象的类名、实例变量（包括基本类型，数组，对其他对象的引用）都会被序列化；方法、类变量、transient实例变量都不会被序列化。
3. 如果想让某个变量不被序列化，使用transient修饰。
4. 序列化对象的引用类型成员变量，也必须是可序列化的，否则，会报错。
5. 反序列化时必须有序列化对象的class文件。
6. 当通过文件、网络来读取序列化后的对象时，必须按照实际写入的顺序读取。
7. 单例类序列化，需要重写readResolve()方法；否则会破坏单例原则。
8. 同一对象序列化多次，只有第一次序列化为二进制流，以后都只是保存序列化编号，不会重复序列化。
9. 建议所有可序列化的类加上serialVersionUID 版本号，方便项目升级。

[https://juejin.im/post/5ce3cdc8e51d45777b1a3cdf#heading-9](https://juejin.im/post/5ce3cdc8e51d45777b1a3cdf#heading-9)

### 泛型
泛型是Java SE 1.5的新特性，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。

**好处**：
- **类型安全**，提供编译期间的类型检测
- **前后兼容**
- **泛化代码,代码可以更多的重复利用**
- **性能较高**，用GJ(泛型JAVA)编写的代码可以为java编译器和虚拟机带来更多的类型信息，这些信息对java程序做进一步优化提供条件

[泛型擦除原理](https://www.jianshu.com/p/328efeb01940)

## Java集合
### ArrayList和LinkedList的区别
- ArrayList是实现了基于**动态数组**的数据结构，LinkedList基于**链表**的数据结构。
- 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。
- 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。

### ArrayList源代码
#### 底层数据结构
```java
private static final int DEFAULT_CAPACITY = 10; // 默认容量
transient Object[] elementData; // Object 数组
private int size; // 大小
```

#### 构造方法
- 无参数：`this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; // 默认10`
- 有参数：`this.elementData = new Object[initialCapacity];`


#### 扩容
最主要的两句代码
```java
int newCapacity = oldCapacity + (oldCapacity >> 1); // old + old / 2 就在这...
elementData = Arrays.copyOf(elementData, newCapacity); // 使用Arrays的复制
```

#### add
```java
public boolean add(E e) {
    // 扩容判断
    ensureCapacityInternal(size + 1);  // Increments modCount!! 这个参数，起到并发异常作用。 
    elementData[size++] = e; // 这一步非原子性，并发容易出错，好几种情况。 下次分析
    return true;
}
```

#### 并发问题
> 其实就是size++ 这一步的问题。 越界就是两个线程临界值去扩容都满足，于是一个线程size++导致的，另外一个线程就溢出了，null就是element[size] = e,第一个线程还没来得及size++，第二个线程就在原先的索引上把值给覆盖了，并且在下一个索引为null。

越界
- 列表大小为9，即size=9
- 线程A开始进入add方法，这时它获取到size的值为9，调用ensureCapacityInternal方法进行容量判断。
- 线程B此时也进入add方法，它和获取的size的值也为9，也开始调用ensureCapacityInternal方法。
- 线程A发现需求大小为10，而elementData的大小就为10，可以容纳。于是它不再扩容，返回。
- 线程B也发现需要大小为10，也可以容纳，返回。
- 好了，**问题来了哈**
- 线程A开始进行设置值操作，elementData[size++] = e操作。此时size变为10。
- 线程B也开始进行设置值操作，它尝试设置elementData[10] = e, 而elementData没有进行过扩容，它的下标最大为
- 于是此时会报出一个数组越界的异常`ArrayIndexOutOfBoundsException`。

null
- 列表大小为10，即size=0
- 线程A开始添加元素，值为A。此时它执行第一条操作，将A放在了elementData下标为0的位置上。也就是说，线程挂在了`element[0] = e`上。
- 接着线程B刚好也要开始添加一个值为B的元素，且走到了第一条的操作。此时线程B获取的size的值依然为0，于是它将B也放在了elementData下标为0的位置上。
- **问题来了**，其实上面也是问题，覆盖了。。。
- 线程A将size的值增加为1
- 线程B开始将size的值增加为2
- 当你获取1索引的时候，那不就是null了？

#### get 
```java
// 一般获取元素，第一步都要判断索引是否越界
public E get(int index) {
    rangeCheck(index); // 判断给定索引是否越界
    return elementData(index);
}
```



#### Fair-Fast机制
ArrayList也采用了快速失败的机制，**通过记录modCount参数来实现**。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。

### LinkedList源代码
#### 底层数据结构
```java
transient int size = 0;
transient Node<E> first; // 经常用
transient Node<E> last; // 经常用
// Node是私有的内部类，跟双向链表定义没什么区别
...
```

#### getFirst和getLast
> 说白了，getFirst就是获取全局变量的first，getLast就是获取全局变量的last

```java
public E getFirst() {
    final Node<E> f = first; // 第一个节点
    if (f == null)
        throw new NoSuchElementException();
    return f.item;
}
public E getLast() {
    final Node<E> l = last; // 最后一个节点
    if (l == null)
        throw new NoSuchElementException();
    return l.item;
}
```

#### add
> add内部调用的是linkLast，在后边插入

```java
void linkLast(E e) {
    final Node<E> l = last; // 要在尾部添加，所以要找last
    final Node<E> newNode = new Node<>(l, e, null); // last->e->null
    last = newNode;
    if (l == null)
        first = newNode; // 如果l为空，说明没有链表没有元素，那么first和last都指向e，
    else
        l.next = newNode; // 否则就将l.next指向新节点
    size++;
    modCount++; // 依然存在并发危险哦
}
```

#### remove
> 其实就是遍历，unlink而已，这里考点，感觉是这样的，移除node，要先让pre和next互相链接，然后在移除node。从你代码里也可以看出，先prev.next = next; 然后x.prev = null;

```java
E unlink(Node<E> x) {
    // assert x != null;
    final E element = x.item; // 当前值
    final Node<E> next = x.next; // 后
    final Node<E> prev = x.prev; // 前

    if (prev == null) { // 如果x的前是null，说明，x是首节点，直接让first指向next
        first = next;
    } else { // x不是首节点，意味着pre是有值哦。
        prev.next = next; // prev.next的箭头指向x的next
        x.prev = null; // 将x.prev指向null 双向链表？
    }

    if (next == null) { // 同上，说明x是最后节点了
        last = prev; // 让last指向x的prev
    } else {
        next.prev = prev; // 否则x不是最后节点， 让next.prev 指向prev
        x.next = null; // x.next 指向null ， 双向链表
    }

    x.item = null; // GC回收
    size--;
    modCount++;
    return element;
}
```

### HashMap(1.8)
#### 底层结构
HashMap的底层结构是是**数组+链表**。关于为什么是链表，那是因为哈希冲突，采取链表一种方式。

#### 常见参数
```java
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16 初始容量
static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认负载因子0.75
// 给定的默认容量为16，负载因子为0.75.
// Map在使用过程中不断的往里面存放数据，当数量达到了16 * 0.75 = 12就需要将当前16的容量进行扩容，
static final int TREEIFY_THRESHOLD = 8;// 成为红黑树的阈值，为什么是8？
static final int UNTREEIFY_THRESHOLD = 6; // 红黑树转链表阈值6
static final int MIN_TREEIFY_CAPACITY = 64;
```

- 为什么容量要是 2 的整数次幂？
因为获取 key 在数组中对应的下标是通过 key 的哈希值与数组长度 -1 进行与运算，如：tab[i = (n - 1) & hash]

1. n 为 2 的整数次幂，这样 n-1 后之前为 1 的位后面全是 1，这样就能保证 (n-1) & hash 后相应的位数既可能是 0 又可能是 1，这取决于 hash 的值，这样能保证散列的均匀，同时与运算效率高
2. 如果 n 不是 2 的整数次幂，会造成更多的 hash 冲突

> 举个例子：如 16：10000, 16-1=15：1111, 1111 再与 hash 做 & 运算的时候，各个位置的取值取决于 hash，如果不是2的整数次幂，必然会有的0的位，这样再进行 & 操作的时候就为 0了，会造成哈希冲突。

> 注意：HashMap的tableSizeFor方法做了处理，能保证n永远都是2次幂

[https://zhuanlan.zhihu.com/p/90816780](https://zhuanlan.zhihu.com/p/90816780)

- 为什么负载因子是0.75？
> 负载因子过低，频繁扩容，扩容会重新哈希，性能下降;负载因子过高，容易浪费容量.

- 为什么红黑树的阈值是8？
> 在 hash 函数设计合理的情况下，发生 hash 碰撞 8 次的几率为百万分之 6，概率说话。(泊松分布)

- 为什么退化链表的阈值6？
> 6是因为如果 hash 碰撞次数在 8 附近徘徊，会一直发生链表和红黑树的转化，为了预防这种情况的发生。

#### hash
```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

hash 函数是先拿到通过 key 的 hashcode，**是 32 位的 int 值**，然后让 **hashcode 的高 16 位和低 16 位进行异或操作**。这个也叫扰动函数，这么设计有二点原因：

- **一定要尽可能降低 hash 碰撞，越分散越好**；
- 算法一定要尽可能高效，因为这是高频操作, 因此采用位运算；

#### put
![put过程](https://imgkr.cn-bj.ufileos.com/b2206341-08ce-4e67-87bd-3a467ccac31e.png)

- 判断数组是否为空，为空进行初始化;（初始化）
- 不为空，计算 k 的 hash 值，通过(n - 1) & hash计算应当存放在数组中的下标 index;（通过hash计算index）
- 查看 table[index] 是否存在数据，没有数据就构造一个 Node 节点存放在 table[index] 中；（查看数组中是否哈希冲突）
- 存在数据，说明发生了 hash 冲突(存在二个节点 key 的 hash 值一样), 继续判断 key 是否相等，相等，用新的 value 替换原数据(onlyIfAbsent 为 false)；（冲突，判断key是否相等，相等则替换）
- 如果不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中；（判断是否红黑树）
- 如果不是树型节点，创建普通 Node 加入链表中；判断链表长度是否大于 8， 大于的话链表转换为红黑树；（判断是否转成红黑树）
- 插入完成之后判断当前节点数是否大于阈值，如果大于开始扩容为原数组的二倍。（扩容）

#### get

> get比较简单，定位桶，逻辑来了。

1. 判断：是否为空，为空，返回null
2. 不为空，判断第一个位置是否为查询key，是，返回value
3. 不是，下一个节点继续判断是否为红黑树，是，按树查找
4. 不是，按链表查找

#### 扩容
> 先说1.7吧
```java
for (HashMapEntry<K, V> e : table) {
    // 如果这个数组位置上有元素且存在哈希冲突的链表结构则继续遍历链表
    while (null != e) {
        //取当前数组索引位上单向链表的下一个元素
        HashMapEntry<K, V> next = e.next;
        //重新依据hash值计算元素在扩容后数组中的索引位置
        int i = indexFor(e.hash, newCapacity);
        e.next = newTable[i]; // 这一步和下一步就是头插法了，并且这两步出现线程不安全死循环问题
        newTable[i] = e;
        e = next; // 遍历链表
    }
}
```
> 可以适当画图讲， 最好！

> 1.8
HashMap的扩容使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。也就是说省略了重新计算hash值的时间，而且新增的1位是0还是1机会是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。如果在新表的数组索引位置相同，则链表元素不会倒置。

#### 1.8的优化
- 数组+链表改成了**数组+链表或红黑树**；
- 链表的插入方式从**头插法改成了尾插法**，简单说就是插入时，如果数组位置上已经有元素，1.7 将新元素放到数组中，原始节点作为新节点的后继节点，1.8 遍历链表，将元素放置到链表的最后；
- 扩容的时候 1.7 需要对原数组中的元素进行**重新 hash 定位在新数组的位置**，1.8 采用更简单的判断逻辑，**位置不变或索引+旧容量大小**；
- 在插入时，**1.7 先判断是否需要扩容，再插入，1.8 先进行插入，插入完成再判断是否需要扩容**；

#### 并发问题
- HashMap扩容的时候会调用resize()方法，就是这里的并发操作容易在一个桶上形成环形链表
- 这样当获取一个不存在的key时，计算出的index正好是环形链表的下标就会出现死循环。
- **但是1.7的头插法造成的问题，1.8改变了插入顺序，就解决了这个问题，但是为了内存可见性等安全性，还是需要ConCurrentHashMap**
- HashTable 是直接在操作方法上加 synchronized 关键字，锁住整个数组，粒度比较大
- Collections.synchronizedMap 是使用 Collections 集合工具的内部类，通过传入 Map 封装出一个 SynchronizedMap 对象，内部定义了一个对象锁，方法内通过对象锁实现
- ConcurrentHashMap 使用分段锁，降低了锁粒度，让并发度大大提高。(jdk1.8 CAS+ synchronized)


### ConcurrentHashMap
#### 1.7
##### segment
- 唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。
- ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 `ReentrantLock`。
- 不会像HashTable那样不管是put还是get操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。
- **每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。**

##### put
- 虽然HashEntry中的value是用volatile关键字修饰的，但是并不能保证并发的原子性，所以put操作仍然需要加锁处理。
- 首先第一步的时候会尝试获取锁，如果获取失败肯定就是其他线程存在竞争，则利用 `scanAndLockForPut()` 自旋获取锁。
  - 尝试获取自旋锁
  - 如果重试的次数达到了`MAX_SCAN_RETRIES` 则改为阻塞锁获取，保证能获取成功。

总的来说：

- 将当前的Segment中的table通过key的hashcode定位到HashEntry
- 遍历该HashEntry，如果不为空则判断传入的key和当前遍历的key是否相等，相等则覆盖旧的value
- 不为空则需要新建一个HashEntry并加入到Segment中，同时会先判断是否需要扩容
- 最后会解除在1中所获取当前Segment的锁。

##### get
- 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。
- 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。
- ConcurrentHashMap 的 get 方法是非常高效的，**因为整个过程都不需要加锁。**

##### size
在 JDK1.7 中，第一种方案他会使用不加锁的模式去尝试多次计算 ConcurrentHashMap 的 size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的。 第二种方案是如果第一种方案不符合，他就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回

#### 1.8
1.7 查询遍历链表效率太低。其中抛弃了原有的 Segment 分段锁，而采用了 `CAS + synchronized` 来保证并发安全性

##### put
- 根据key计算出hashcode
- 判断是否需要进行初始化
- 如果f为null，说明table中这个位置第一次插入元素，利用Unsafe.compareAndSwapObject方法插入Node节点。
    - 如果CAS成功，说明Node节点已经插入，随后addCount(1L, binCount)方法会检查当前容量是否需要进行扩容。
    - 如果CAS失败，说明有其它线程提前插入了节点，自旋重新尝试在这个位置插入节点。
- 如果f的hash值为-1，说明当前f是ForwardingNode节点，意味有其它线程正在扩容，则一起进行扩容操作。
- 如果都不满足，则利用`synchronized`锁写入数据
- 如果数量大于TREEIFY_THRESHOLD 则要转换为红黑树。

##### get
- 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。
- 如果是红黑树那就按照树的方式获取值。
- 就不满足那就按照链表的方式遍历获取值。

##### size
ConcurrentHashMap 提供了 baseCount、counterCells 两个辅助变量和一个 CounterCell 辅助内部类。sumCount() 就是迭代 counterCells 来统计 sum 的过程。 put 操作时，肯定会影响 size()，在 put() 方法最后会调用 addCount() 方法。

在addCount()方法中：
- 如果 counterCells == null, 则对 baseCount 做 CAS 自增操作。
- 如果并发导致 baseCount CAS 失败了使用 counterCells。
- 如果counterCells CAS 失败了，在 fullAddCount 方法中，会继续死循环操作，直到成功。
- CounterCell使用了 @sun.misc.Contended 标记的类
> 缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。

实际上：
- JDK1.8 size 是通过对 baseCount 和 counterCell 进行 CAS 计算，最终通过 baseCount 和 遍历 CounterCell 数组得出 size。
- JDK 8 推荐使用mappingCount 方法，因为这个方法的返回值是 long 类型，不会因为 size 方法是 int 类型限制最大值。

[https://zhuanlan.zhihu.com/p/40627259](https://zhuanlan.zhihu.com/p/40627259)

### HashSet
HashSet中不允许有重复元素，这是因为HashSet是基于HashMap实现的，HashSet中的元素都存放在HashMap的key上面，而value中的值都是统一的一个`private static final Object PRESENT = new Object();`。 HashSet跟HashMap一样，都是一个存放链表的数组。

### 手写lru
> 双向链表+HashMap，Java中的LinkedHashMap就实现了该算法。

#### get
```java
public int get(int key) {
    if (map.containsKey(key)) {
        Node n = map.get(key); // 获取内存中存在的值，比如A
        remove(n); //使用链表的方法，移除该节点
        setHead(n); //依然使用链表的方法，将该节点放入头部
        return n.value;
    } 
    return -1;
}
```
- 由于当一个节点通过key来访问到这个节点，那么这个节点就是刚被访问了，
- 就把这个节点删除掉，然后放到队列头，这样队列的头部都是最近访问的，
- 队列尾部是最近没有被访问的。

#### set
```java
public void set(int key, int value) {
    if (map.containsKey(key)) {
        Node old = map.get(key);
        old.value = value;
        remove(old); // 移除旧节点
        setHead(old); // 放到队头
    } else {
        Node created = new Node(key, value);
        if (map.size() >= capacity) {
            map.remove(end.key); // clear该key
            remove(end); //链表也是依次
            setHead(created); // 将created放入队头
        } else {
            setHead(created); // 如果没满，直接放入队头
        }
        map.put(key,created);
    }
}
```


## 多线程
### 线程与进程的区别
进程

**进程是程序的一次执行过程，是系统运行程序的基本单位**。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

比如：当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

线程

- **线程是一个比进程更小的执行单位**
- 一个进程在其执行的过程中可以产生**多个线程**
- 与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程

### 并行与并发
- 并行：**单位时间内**，多个任务同时执行。
- 并发：**同一时间段**，多个任务都在执行 (单位时间内不一定同时执行)；

### 上下文切换
多线程编程中一般**线程的个数都大于 CPU 核心的个数**，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配**时间片并轮转**的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。

实际上就是**任务从保存到再加载的过程就是一次上下文切换**。

### 什么是线程安全？
> 我的理解是：多个线程交替执行，本身是没有问题的，但是如果访问共享资源，结果可能会出现问题，于是就出现了线程不安全的问题。
1. 访问共享变量或资源
2. 依赖时序的操作
3. 不同数据之间存在绑定关系
4. 对方没有声明自己是线程安全的

### 线程周期

![](https://www.pdai.tech/_images/pics/ace830df-9919-48ca-91b5-60b193f593d2.png)

- 线程创建之后它将处于`New`（新建）状态，调用 `start()` 方法后开始运行，线程这时候处于 `READY`（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 `RUNNING`（运行） 状态。
- 当线程执行 `wait()`方法之后，线程进入 `WAITING`（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 `TIME_WAITING`(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将 Java 线程置于 `TIMED WAITING` 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。
- 当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 `BLOCKED`（阻塞）状态。
- 线程在执行 Runnable 的` run() `方法之后将会进入到 `TERMINATED`（终止） 状态。

#### 直接调用Thread的run方法不行吗？
**start**

通过该方法启动线程的同时**也创建了一个线程，真正实现了多线程**。**无需等待run()方法中的代码执行完毕，就可以接着执行下面的代码**。此时start()的这个线程处于**就绪状态**，当得到CPU的时间片后就会执行其中的run()方法。这个run()方法包含了要执行的这个线程的内容，run()方法运行结束，此线程也就终止了。

从源码当中可以看到：
当一个线程启动的时候，它的状态（threadStatus）被设置为0，如果不为0，则抛出`IllegalThreadStateException`异常。正常的话，将该**线程加入线程组**，最后尝试调用start0方法，**而start0方法是私有的native方法**（Native Method是一个java调用非java代码的接口）。

**run**

通过run方法启动线程其实就是调用一个类中的方法，**当作普通的方法的方式调用**。并没有创建一个线程，程序中依旧只有一个主线程，必须等到run()方法里面的代码执行完毕，才会继续执行下面的代码，这样就没有达到写线程的目的。

### wait/notify 和 sleep 方法的异同？
相同点：
1. 它们都可以让线程阻塞。
2. 它们都可以响应 interrupt 中断：在等待的过程中如果收到中断信号，都可以进行响应，并抛出 InterruptedException 异常。

不同点：
1. wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。
2. 在同步代码中执行 sleep 方法时，并不会释放 monitor 锁，但执行 wait 方法时会主动释放 monitor 锁。
3. sleep 方法中会要求必须定义一个时间，时间到期后会主动恢复，而对于没有参数的 wait 方法而言，意味着永久等待，直到被中断或被唤醒才能恢复，它并不会主动恢复。
4. wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。

### 4种创建方式
Thread

```java
public class Test extents Thread {
    public void run() {
      // 重写Thread的run方法
      System.out.println("dream");
    }
    
    public static void main(String[] args) {
        new Test().start();
    }
}
```
Runnable

```java
public class Test {
    public static void main(String[] args) {
        new Thread(() -> {
            System.out.println("dream");
        }).start();
    } 
}
```
---

源码：
```java
@FunctionalInterface
public interface Runnable {
   /**
    * 被线程执行，没有返回值也无法抛出异常
    */
    public abstract void run();
}
```
Callable
```java
public class Test {
    public static void main(String[] args) {
        // FutureTask 构造方法包装了Callable和Runnable。
        FutureTask<Integer> task = new FutureTask<>(() -> {
            System.out.println("dream");
            return 0;
        });
        new Thread(task).start();
    }
}
```
---
源码：
```java
@FunctionalInterface
public interface Callable<V> {
    /**
     * 计算结果，或在无法这样做时抛出异常。
     * @return 计算得出的结果
     * @throws 如果无法计算结果，则抛出异常
     */
    V call() throws Exception;
}
```
线程池
```java
public class Test {
    public static void main(String[] args) {
        ExecutorService threadPool = Executors.newFixedThreadPool(1);
        threadPool.submit(() -> {
            System.out.println("dream");
        });
        threadPool.shutdown();
    }
}
```

### 死锁
- **互斥条件**：该资源任意一个时刻只由一个线程占用。(同一时刻，这个碗是我的，你不能碰)
- **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。（我拿着这个碗一直不放）
- **不剥夺条件**:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。（我碗中的饭没吃完，你不能抢，释放权是我自己的，我想什么时候放就什么时候放）
- **循环等待条件**:若干进程之间形成一种头尾相接的循环等待资源关系。（我拿了A碗，你拿了B碗，但是我还想要你的B碗，你还想我的A碗）

---
```java
public class Test {
    private static Object res1 = new Object();
    private static Object res2 = new Object();

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (res1) {
                System.out.println(Thread.currentThread().getName() + " res1");
                // 延迟一下, 确保B拿到了res2
                try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }
                synchronized (res2) {
                    System.out.println(Thread.currentThread().getName() + " res2");
                }
            }
        }, "ThreadA").start();

        new Thread(() -> {
            synchronized (res2) {
                System.out.println(Thread.currentThread().getName() + " res2");
                // 延迟一下，确保A拿到了res1
                synchronized (res1) {
                    System.out.println(Thread.currentThread().getName() + " res1");
                }
            }
        }, "ThreadB").start();
    }
}
```

### 主线程等待子线程方式
- sleep:好用是好用，但是缺点太明显，不可控的延迟
- Thread.activeCount()：缺点也明显，结合while一直判断
- Join：值得考虑，但是不优雅

```java
public class Test {
    void m() {
        System.out.println(Thread.currentThread().getName());
    }

    public static void main(String[] args) {
        Test t1 = new Test();
        ArrayList<Thread> threads = new ArrayList<>();
        for (int i = 0; i < 5; i++) {
            threads.add(new Thread(t1::m, "Thread " + i));
        }
        threads.forEach(o -> o.start());
        threads.forEach(o -> {
            try {
                o.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        System.out.println("main thread");
    }
}
```

CountDownLatch

```java
public class Test {
    private CountDownLatch latch;

    public Test(CountDownLatch latch) {
        this.latch = latch;
    }

    void m() {
        System.out.println(Thread.currentThread().getName());
        latch.countDown();
    }

    public static void main(String[] args) throws InterruptedException {
        CountDownLatch countDownLatch = new CountDownLatch(5);
        Test t1 = new Test(countDownLatch);
        for (int i = 0; i < 5; i++) {
            new Thread(t1::m, "Thread " + i).start();
        }
        countDownLatch.await();
        System.out.println("main thread");
    }
}
```

### Java锁介绍
#### 公平锁/非公平锁
- 公平锁指多个线程按照**申请锁的顺序来获取锁**。
- 非公平锁指多个线程获取锁的顺序**并不是按照申请锁的顺序**，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象（很长时间都没获取到锁-非洲人...）。

#### 可重入锁
可重入锁又名递归锁，是指在同一个线程在**外层方法获取锁的时候，在进入内层方法会自动获取锁**，典型的synchronized，了解一下。

#### 独享锁/共享锁
- 独享锁：是指该锁一次只能**被一个线程所持有**。
- 共享锁：是该锁可**被多个线程所持有**。

#### 互斥锁/读写锁
上面讲的独享锁/共享锁就是一种**广义的说法**，互斥锁/读写锁就是其具体的实现。

#### 乐观锁/悲观锁
- 悲观锁认为对于同一个人数据的并发操作，**一定是会发生修改的，哪怕没有修改，也会认为修改**。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。**悲观的认为，不加锁的并发操作一定会出现问题**。
- **乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据**。乐观的认为，不加锁的并发操作时没有事情的。
- **悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁带来大量的性能提升。**
- 悲观锁在Java中的使用，就是利用各种锁。乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子类操作的更新。重量级锁是悲观锁的一种，自旋锁、轻量级锁与偏向锁属于乐观锁。

#### 分段锁
- 分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来哦实现高效的并发操作。
- 以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是ReentrantLock（Segment继承了ReentrantLock）**
- 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。**
- **分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。**

#### 偏向锁/轻量级锁/重量级锁
- 这三种锁是锁的状态，并且是针对这synchronized。在Java5通过引入锁升级的机制来实现高效synchronized。这三种锁的状态是通过**对象监视器在对象头中的字段来表明的**。偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
- 偏向锁的适用场景：**始终只有一个线程在执行代码块，在它没有执行完释放锁之前，没有其它线程去执行同步快，在锁无竞争的情况下使用**，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；在有锁竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向锁的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。
- **轻量级锁是指当锁是偏向锁的时候，被另一个线程锁访问，偏向锁就会升级为轻量级锁，其他线程会通过自选的形式尝试获取锁，不会阻塞，提高性能。**
- **重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。**

#### 自旋锁
自旋锁其实就是在拿锁时发现已经有线程拿了锁，自己如果去拿会阻塞自己，这个时候会选择进行一次忙循环尝试。也就是不停循环看是否能等到上个线程自己释放锁。自适应自旋锁指的是例如第一次设置最多自旋10次，结果在自旋的过程中成功获得了锁，那么下一次就可以设置成最多自旋20次。

##### 手写自旋锁
```java
public class SpinLock {

    // 原子引用线程
    AtomicReference<Thread> atomicReference =  new AtomicReference<>();

    public void mylock() {
        Thread thread = Thread.currentThread();
        System.out.println(Thread.currentThread().getName() + " como in...");
        while (!atomicReference.compareAndSet(null, thread)) {
//            System.out.println("不爽，重新获取一次值瞧瞧...");
        }
    }

    public void  myUnlock() {
        Thread thread = Thread.currentThread();
        atomicReference.compareAndSet(thread, null);
        System.out.println(Thread.currentThread().getName() + " invoke myUnLock...");
    }

    public static void main(String[] args) {
        SpinLock spinLock = new SpinLock();
        new Thread(() -> {
            spinLock.mylock();
            try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
            spinLock.myUnlock();
        }, "t1").start();
        try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }

        new Thread(() -> {
            spinLock.mylock();
            spinLock.myUnlock();
        }, "t2").start();
    }

}
```

### volatile
#### 可见性
> 问题所在：首先有一个这样的程序，首先有个变量isStart为true，然而有一个方法，该方法有个while(isStart)。也就是说，只要不改变isStart为false，此方法的while一直循环。倘若，我在主线程更改为false。那么理论上应该会while会停止，但是实际上个没有。此时要分析JMM

分析：一开始isReady为true，m方法中的while会一直循环，而主线程开启开线程之后会延迟1s将isReady赋值为false，若不加volatile修饰，则程序一直在运行，若加了volatile修饰，则程序最后会输出t1 m end...

**这里要聊一下JMM内存模型**
[https://www.processon.com/view/link/5e129d57e4b0da16bb11d127](https://www.processon.com/view/link/5e129d57e4b0da16bb11d127)

#### 可序性
```java
public class Test {
    private volatile static Test instance = null;
    private Test(){}

    private static Test getInstance() {
        if (instance != null) {
            synchronized (Test.class) {
                if (instance != null) {
                    instance = new Test();
                }
            }
        }
        return instance;
    }
}
```
上面的代码是一个很常见的单例模式实现方式，但是上述代码在多线程环境下是有问题的。为什么呢，问题出在instance对象的初始化上，因为`instance = new Singleton();`这个初始化操作并不是原子的，在JVM上会对应下面的几条指令：

```c
memory =allocate();    //1. 分配对象的内存空间 
ctorInstance(memory);  //2. 初始化对象 
instance = memory;     //3. 设置instance指向刚分配的内存地址
```
上面三个指令中，步骤2依赖步骤1，但是步骤3不依赖步骤2，所以JVM可能针对他们进行指令重拍序优化，重排后的指令如下：

```c
memory =allocate();    //1. 分配对象的内存空间 
instance = memory;     //3. 设置instance指向刚分配的内存地址
ctorInstance(memory);  //2. 初始化对象 
```

这样优化之后，内存的初始化被放到了instance分配内存地址的后面，这样的话当线程1执行步骤3这段赋值指令后，刚好有另外一个线程2进入getInstance方法判断instance不为null，这个时候线程2拿到的instance对应的内存其实还未初始化，这个时候拿去使用就会导致出错。

#### 不能保证原子性
> 假设：我们这边有20个线程，每个线程分别执行10000次count++；那么最终全部执行完毕的结果理论上是200000,但实际运行却达不到。分析一波

- JMM都了解，暂时不说了
- 当T1从主内存读取count拷贝到自己的工作内存为0，那么T2也是如此。
- T1开始执行一次count++，那么，T1的count为1并挂起，T2也是如此执行count++，T2的count也是1。
- T1唤醒，将count写入总内存，此时问题来了。
- **此时会通过总线嗅探机制将T2的工作内存的count失效。也就意味着，T2虽然读取了内存的count为1，但是它终归丢失了一次操作呀，也就意味着这两次执行的count++，在总内存上理论上是2的，但实际上是1**。

分析图：[https://www.processon.com/view/link/5e130e51e4b07db4cfac9d2c](https://www.processon.com/view/link/5e130e51e4b07db4cfac9d2c)

#### 内存屏障(补充)
**Java的Volatile的特征是任何读都能读到最新值，本质上是JVM通过内存屏障来实现的；为了实现volatile内存语义，JMM会分别限制重排序类型。**

- 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。
- 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。
- 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。

**为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：**

- 在每个volatile写操作的前面插入一个StoreStore屏障。
- 在每个volatile写操作的后面插入一个StoreLoad屏障。
- 在每个volatile读操作的后面插入一个LoadLoad屏障。
- 在每个volatile读操作的后面插入一个LoadStore屏障。

#### volatile汇编
**可见其本质是通过一个lock指令来实现的。**

**它的作用是使得本CPU的Cache写入了内存，该写入动作也会引起别的CPU invalidate其Cache。所以通过这样一个空操作，可让前面volatile变量的修改对其他CPU立即可见。**

- 锁住内存
- 任何读必须在写完成之后再执行
- 使其它线程这个值的栈缓存失效


### synchronized

#### 修饰范围
- 实例方法：作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁
- 静态方法：作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁
- 修饰代码块：指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁

#### 底层原理
代码块

**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。**

方法

**synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。**

#### 1.6版本的优化
##### 1.6前
在 Java 早期版本中，`synchronized` 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 **Mutex Lock** 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要**操作系统**帮忙完成，而操作系统实现线程之间的切换时需要从**用户态转换到内核态**，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。

##### 1.6后
庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如**自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等**技术来减少锁操作的开销。


##### 偏向锁
**引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉**。

- 访问Mark Word中**偏向锁的标识是否设置成1**，**锁标识位是否为01**，确认偏向状态
- 如果为可偏向状态，则判断**当前线程ID是否为偏向线程**
- 如果偏向线程未当前线程，则通过**cas操作竞争锁**，如果竞争成功则操作Mark Word中线程ID设置为当前线程ID
- 如果cas偏向锁获取失败，则挂起当前偏向锁线程，偏向锁升级为**轻量级锁**      

##### 轻量级锁
倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。**轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。**
**轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

- 线程由偏向锁升级为轻量级锁时，会先把**锁的对象头MarkWord复制一份到线程的栈帧中，建立一个名为锁记录空间（Lock Record），用于存储当前Mark Word的拷贝**。
- 虚拟机使用cas操作尝试将**对象的Mark Word指向Lock Record的指针，并将Lock record里的owner指针指对象的Mark Word**。
- 如果cas操作成功，则该线程拥有了对象的轻量级锁。第二个线程cas自旋锁等待锁线程释放锁。
- 如果多个线程竞争锁，轻量级锁要膨胀为**重量级锁**，**Mark Word中存储的就是指向重量级锁（互斥量）的指针**。其他等待线程进入阻塞状态。

##### 锁消除
锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

##### 自旋锁和自适应锁
**一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。** 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。**为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋**。

**在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定**。

##### 锁粗化
原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，——直在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。

##### 总升级过程
- 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
- 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
- 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
- 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
- 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
- 如果自旋成功则依然处于轻量级状态。
- 如果自旋失败，则升级为重量级锁。

#### 和ReentractLock对比
- **两者都是可重入锁**:两者都是可重入锁。“可重入锁”概念是：**自己可以再次获取自己的内部锁**。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。
- **synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API**:synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。
- **ReenTrantLock 比 synchronized 增加了一些高级功能**
   1. **等待可中断**：过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
   2. **可实现公平锁**
   3. **可实现选择性通知（锁可以绑定多个条件）**：线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”
   4. **性能已不是选择标准**：在jdk1.6之前synchronized 关键字吞吐量随线程数的增加，下降得非常严重。1.6之后，**synchronized 和 ReenTrantLock 的性能基本是持平了。**


### CAS
> **我们在读Concurrent包下的类的源码时，发现无论是**ReenterLock内部的AQS，还是各种Atomic开头的原子类，内部都应用到了`CAS`，并且在调用getAndAddInt方法中，会有compareAndSwapInt方法

`compareAndSwapInt（obj, offset, expect, update）`比较清楚，**意思就是如果`obj`内的`value`和`expect`相等，就证明没有其他线程改变过这个变量，那么就更新它为`update`，如果这一步的`CAS`没有成功，那就采用自旋的方式继续进行`CAS`操作**，取出乍一看这也是两个步骤了啊，其实在`JNI`里是借助于一个`CPU`指令完成的。所以还是原子操作。

调用了`Atomic::cmpxchg(x, addr, e)`, 其中参数x是即将更新的值，参数e是原内存的值。代码中能看到cmpxchg有基于各个平台的实现。

#### ABA问题
> 描述: 第一个线程取到了变量 x 的值 A，然后巴拉巴拉干别的事，总之就是只拿到了变量 x 的值 A。这段时间内第二个线程也取到了变量 x 的值 A，然后把变量 x 的值改为 B，然后巴拉巴拉干别的事，最后又把变量 x 的值变为 A （相当于还原了）。在这之后第一个线程终于进行了变量 x 的操作，但是此时变量 x 的值还是 A，所以 compareAndSet 操作是成功。

**目前在JDK的atomic包里提供了一个类`AtomicStampedReference`来解决ABA问题。**

说白了，就是版本号


### AQS
> AQS 使用一个 int 成员变量来表示同步状态（state），通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。(重点)

state

```java
//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}

```

常用方法

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

#### ReentrantLock
##### 构造方法
```java
// 默认是非公平锁
public ReentrantLock() {
    sync = new NonfairSync();
}
// 可选参数，是否公平
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```

##### 公平锁的实现
```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (!hasQueuedPredecessors() && // 判断队列是否轮到该线程
            compareAndSetState(0, acquires)) { // 利用cas更换状态
            setExclusiveOwnerThread(current); // 如果都ok，就设置独占锁
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {// 判断当前独占锁是否还是当前线程
        int nextc = c + acquires;// 状态累加
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc); // 设置状态
        return true;
    } // 否则false
    return false;
}
```

##### 非公平锁的实现
```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {// 在这里...
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

#### CountDownLatch
> CountDownLatch是共享锁的一种实现,它默认构造 `AQS` 的 `state` 值为 `count`。当线程使用`countDown`方法时,其实使用了`tryReleaseShared`方法以CAS的操作来减少`state`,直至`state`为0就代表所有的线程都调用了`countDown`方法。当调用`await`方法的时候，如果`state`不为0，就代表仍然有线程没有调用countDown方法，那么就把已经调用过countDown的线程都放入**阻塞队列Park,并自旋CAS判断state == 0**，直至最后一个线程调用了countDown，使得state == 0，于是阻塞的线程便判断成功，全部往下执行。

##### 构造方法
```java
public CountDownLatch(int count) {
    if (count < 0) throw new IllegalArgumentException("count < 0");
    this.sync = new Sync(count); // 这里设置state的次数 
}
```
##### countDown
```java
public void countDown() {
    sync.releaseShared(1);
}
```

##### tryReleaseShared
```java
protected boolean tryReleaseShared(int releases) {
    // Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1; // 每执行一次该方法，状态减一
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}
```

##### 用法
- 某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：`new CountDownLatch(n)`，每当一个任务线程执行完毕，就将计数器减 1 `countdownlatch.countDown()`，当计数器的值变为 0 时，在`CountDownLatch上 await()` 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。
- 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 `CountDownLatch` 对象，将其计数器初始化为 1 ：`new CountDownLatch(1)`，多个线程在开始执行任务前首先 `coundownlatch.await()`，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。
- 死锁检测：一个非常方便的使用场景是，你可以使用 n 个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。


#### CyclicBarrier
> CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 `CyclicBarrier(int parties)`，其参数表示屏障拦截的线程数量，每个线程调用`await`方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。


##### dowait
当调用 `CyclicBarrier` 对象调用 `await()` 方法时，实际上调用的是`dowait(false, 0L)`方法。 `await()` 方法就像树立起一个栅栏的行为一样，将线程挡住了，当拦住的线程数量达到 parties 的值时，栅栏才会打开，线程才得以通过执行。

代码就不贴了。要看，就去jdk上看

总结：`CyclicBarrier` 内部通过一个 count 变量作为计数器，count 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减一。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。

#### Semaphore
**synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。**

### ThreadLocal
> 如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的`ThreadLocal`类正是为了解决这样的问题。 **`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。


#### 原理
```java
public class Thread implements Runnable {
 ......
//与此线程有关的ThreadLocal值。由ThreadLocal类维护
ThreadLocal.ThreadLocalMap threadLocals = null;

//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护
ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
 ......
}
```

从上面`Thread`类 源代码可以看出`Thread` 类中有一个 `threadLocals` 和 一个 `inheritableThreadLocals` 变量，它们都是 `ThreadLocalMap` 类型的变量,我们可以把 `ThreadLocalMap` 理解为`ThreadLocal` 类实现的定制化的 `HashMap`。默认情况下这两个变量都是null，只有当前线程调用 `ThreadLocal` 类的 `set`或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的 `get()`、`set() `方法。

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
```
**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。**

**每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。** 比如我们在同一个线程中声明了两个 `ThreadLocal` 对象的话，会使用 `Thread`内部都是使用仅有那个`ThreadLocalMap` 存放数据的，`ThreadLocalMap`的 key 就是 `ThreadLocal`对象，value 就是 `ThreadLocal` 对象调用`set`方法设置的值。`ThreadLocal` 是 map结构是为了让每个线程可以关联多个 `ThreadLocal`变量。这也就解释了ThreadLocal声明的变量为什么在每一个线程都有自己的专属本地变量。

#### 内存泄漏
`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候会 key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法。


### BlockingQueue
- ArrayBlockingQueue：由数组结构组成的有界阻塞队列.
- LinkedBlockingQueue：由链表结构组成的有界(但大小默认值Integer>MAX_VALUE)阻塞队列.
- PriorityBlockingQueue：支持优先级排序（堆）的无界阻塞队列.
- DelayQueue：使用优先级队列实现的延迟无界阻塞队列.
- SynchronousQueue：不存储元素的阻塞队列,也即是单个元素的队列.
每个插入操作必须等待另一个线程相应的删除操作，反之亦然。 同步队列没有任何内部容量，甚至没有一个容量。 个人感觉是生产者生产一个元素，消费者必须消费，生产者才能继续生产。内部也维护了一个TransferQueue，其中部分操作是利用cas。
- LinkedTransferQueue：基于链接节点的无界TransferQueue 。 这个队列相对于任何给定的生产者订购元素FIFO（先进先出）。 队列的头部是那些已经排队的元素是一些生产者的最长时间。 队列的尾部是那些已经在队列上的元素是一些生产者的最短时间。
- LinkedBlockingDuque：由了解结构组成的双向阻塞队列.

#### 常见方法
- 抛出异常：add/remove
- 不抛出异常：offer/poll
- 阻塞：put/take
- 带时间：offer/poll

### 生产者和消费者
#### synchronized
```java
public class Test {

    private final LinkedList<String> lists = new LinkedList<>();

    public synchronized void put(String s) {
        while (lists.size() != 0) { // 用while怕有存在虚拟唤醒线程
            // 满了， 不生产了
            try {
                this.wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        lists.add(s);
        System.out.println(Thread.currentThread().getName() + " " + lists.peekFirst());
        this.notifyAll(); // 这里可是通知所有被挂起的线程，包括其他的生产者线程
    }

    public synchronized void get() {
        while (lists.size() == 0) {
            try {
                this.wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        System.out.println(Thread.currentThread().getName() + " " + lists.removeFirst());
        this.notifyAll(); // 通知所有被wait挂起的线程  用notify可能就死锁了。
    }

    public static void main(String[] args) {
        Test test = new Test();

        // 启动消费者线程
        for (int i = 0; i < 5; i++) {
            new Thread(test::get, "ConsA" + i).start();
        }

        // 启动生产者线程
        for (int i = 0; i < 5; i++) {
            int tempI = i;
            new Thread(() -> {
                test.put("" + tempI);
            }, "ProdA" + i).start();
        }
    }
}
```

#### ReentrantLock
```java
public class Test {

    private LinkedList<String> lists = new LinkedList<>();
    private Lock lock = new ReentrantLock();
    private Condition prod = lock.newCondition();
    private Condition cons = lock.newCondition();

    public void put(String s) {
        lock.lock();
        try {
            // 1. 判断
            while (lists.size() != 0) {
                // 只要队列有元素，就不生产了，就停会儿
                prod.await();
            }
            // 2.干活
            lists.add(s);
            System.out.println(Thread.currentThread().getName() + " " + lists.peekFirst());
            // 3. 通知
            cons.signalAll();
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

    public void get() {
        lock.lock();
        try {
            // 1. 判断
            while (lists.size() == 0) {
                // 队列为空，消费者肯定等待呀
                cons.await();
            }
            // 2.干活
            System.out.println(Thread.currentThread().getName() + " " + lists.removeFirst());
            // 3. 通知
            prod.signalAll();
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

    public static void main(String[] args) {
        Test test = new Test();
        for (int i = 0; i < 5; i++) {
            int tempI = i;
            new Thread(() -> {
                test.put(tempI + "");
            }, "ProdA" + i).start();
        }
        for (int i = 0; i < 5; i++) {
            new Thread(test::get, "ConsA" + i).start();
        }
    }
}
```
这里讲一下为什么用while，不用if？
假如，此时队列元素为空，那么消费者肯定都挂起来了哈。在挂起前通知了生产者线程去生产，那么，生产者产了一个之后唤醒消费者，所有消费者醒了以后，就一个消费者抢到锁，开始消费，当消费过后释放锁，其他消费者线程的某一个抢到锁之后，从唤醒处走代码，如果是if，往下走取元素发现队列空的，直接抛异常。如果是while的话，还会继续判断队列是否为空，空就挂起。不会抛异常。

#### BlockingQueue
```java
public class Test {
    public static void main(String[] args) {
        ArrayBlockingQueue<Object> queue = new ArrayBlockingQueue<>(10);
        // 生产者
        Runnable product = () -> {
            while (true) {
                try {
                    String s = "生产者：" + Thread.currentThread().getName() + " "+ new Object();
                    System.out.println(s);
                    queue.put(s);
                    TimeUnit.SECONDS.sleep(1);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
        new Thread(product, "p1").start();
        new Thread(product, "p2").start();
        // 消费者
        Runnable consume = () -> {
            while (true) {
                try {
                    Object o = queue.take();
                    System.out.println("消费者：" + Thread.currentThread().getName() + " " + o);
                    TimeUnit.SECONDS.sleep(1);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
        new Thread(consume, "c1").start();
        new Thread(consume, "c2").start();
    }
}
```
利用 BlockingQueue 实现生产者消费者模式的代码。虽然代码非常简单，但实际上 ArrayBlockingQueue 已经在背后完成了很多工作，比如队列满了就去阻塞生产者线程，队列有空就去唤醒生产者线程等。

### 线程池
- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

#### FixedThreadPool
```java
/**
 * 创建一个可重用固定数量线程的线程池
 */
public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>(),
                                  threadFactory);
}
```

**从上面源代码可以看出新创建的 `FixedThreadPool` 的 `corePoolSize` 和 `maximumPoolSize` 都被设置为 nThreads，这个 nThreads 参数是我们使用的时候自己传递的。**

- 如果当前运行的线程数小于 corePoolSize， 如果再来新任务的话，就创建新的线程来执行任务；
- 当前运行的线程数等于 corePoolSize 后， 如果再来新任务的话，会将任务加入 `LinkedBlockingQueue`；
- 线程池中的线程执行完 手头的任务后，会在循环中反复从 `LinkedBlockingQueue` 中获取任务来执行；

不推荐使用

**`FixedThreadPool` 使用无界队列 `LinkedBlockingQueue`（队列的容量为 Intger.MAX_VALUE）作为线程池的工作队列会对线程池带来如下影响 ：**

- 当线程池中的线程数达到 `corePoolSize` 后，新任务将在无界队列中等待，因此线程池中的线程数不会超过 corePoolSize；
- 由于使用无界队列时 `maximumPoolSize` 将是一个无效参数，因为不可能存在任务队列满的情况。所以，通过创建 `FixedThreadPool`的源码可以看出创建的 `FixedThreadPool` 的 `corePoolSize` 和 `maximumPoolSize` 被设置为同一个值。
- 由于 1 和 2，使用无界队列时 `keepAliveTime` 将是一个无效参数；
- 运行中的 `FixedThreadPool`（未执行 `shutdown()`或 `shutdownNow()`）不会拒绝任务，在任务比较多的时候会导致 OOM（内存溢出）。

#### SingleThreadExecutor
```java
/**
 *返回只有一个线程的线程池
 */
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>(),
                                threadFactory));
}
```

和上面一个差不多，只不过core和max都被设置为1

#### CachedThreadPool
```java
/**
 * 创建一个线程池，根据需要创建新线程，但会在先前构建的线程可用时重用它。
 */
public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>(),
                                  threadFactory);
}
```

`CachedThreadPool` 的` corePoolSize` 被设置为空（0），`maximumPoolSize `被设置为 Integer.MAX.VALUE，即它是无界的，这也就意味着如果主线程提交任务的速度高于 `maximumPool` 中线程处理任务的速度时，`CachedThreadPool` 会不断创建新的线程。极端情况下，这样会导致耗尽 cpu 和内存资源。

- 首先执行 `SynchronousQueue.offer(Runnable task)` 提交任务到任务队列。如果当前 `maximumPool` 中有闲线程正在执行 `SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)`，那么主线程执行 offer 操作与空闲线程执行的 `poll` 操作配对成功，主线程把任务交给空闲线程执行，`execute()`方法执行完成，否则执行下面的步骤 2；
- 当初始 `maximumPool` 为空，或者 `maximumPool` 中没有空闲线程时，将没有线程执行 `SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)`。这种情况下，步骤 1 将失败，此时 `CachedThreadPool` 会创建新线程执行任务，execute 方法执行完成；

#### ThreadPoolExecutor
- corePoolSize：核心线程数线程数定义了最小可以同时运行的线程数量
- maximumPoolSize：当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数
- keepAliveTime：当线程数大于核心线程数时，多余的空闲线程存活的最长时间
- TimeUnit：时间单位
- BlockingQueue<Runnable>：当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中
- ThreadFactory：线程工厂，用来创建线程，一般默认即可
- RejectedExecutionHandler：拒绝策略

##### RejectedExecutionHandler
- AbortPolicy：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- CallerRunsPolicy：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。
- DiscardPolicy：不处理新任务，直接丢弃掉。
- DiscardOldestPolicy：此策略将丢弃最早的未处理的任务请求。

![线程池各个参数的关系](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/线程池各个参数的关系.jpg)

### 线程池的线程数量怎么确定
1. 一般来说，如果是CPU密集型应用，则线程池大小设置为N+1。
2. 一般来说，如果是IO密集型应用，则线程池大小设置为2N+1。
3. 在IO优化中，线程等待时间所占比例越高，需要越多线程，线程CPU时间所占比例越高，需要越少线程。这样的估算公式可能更适合：最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目

### 多线程题
#### 一个多线程的问题，用三个线程，顺序打印字母A-Z，输出结果是1A 2B 3C 1D 2E…打印完毕最后输出一个Ok。
```java
public class Test {
    private static char c = 'A';
    private static int i = 0;

    public static void main(String[] args) {
        Runnable r = new Runnable() {
            @Override
            public void run() {
                synchronized (this) {
                    try {
                        int id = Integer.parseInt(Thread.currentThread().getName());
                        while (i < 26) {
                            if (i % 3 == id - 1) {
                                System.out.println("线程id：" + id + " " + (char) c++);
                                i++;
                                notifyAll();
                            } else {
                                wait();
                            }
                        }
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            }
        };
        new Thread(r, "1").start();
        new Thread(r, "2").start();
        new Thread(r, "3").start();
    }
}
```

#### 如何让线程顺序执行
[https://blog.csdn.net/Evankaka/article/details/80800081](https://blog.csdn.net/Evankaka/article/details/80800081)


## JVM

### 类文件结构
```java
ClassFile {
    u4             magic; //Class 文件的标志
    u2             minor_version;//Class 的小版本号
    u2             major_version;//Class 的大版本号
    u2             constant_pool_count;//常量池的数量
    cp_info        constant_pool[constant_pool_count-1];//常量池
    u2             access_flags;//Class 的访问标记
    u2             this_class;//当前类
    u2             super_class;//父类
    u2             interfaces_count;//接口
    u2             interfaces[interfaces_count];//一个类可以实现多个接口
    u2             fields_count;//Class 文件的字段属性
    field_info     fields[fields_count];//一个类会可以有个字段
    u2             methods_count;//Class 文件的方法数量
    method_info    methods[methods_count];//一个类可以有个多个方法
    u2             attributes_count;//此类的属性表中的属性数
    attribute_info attributes[attributes_count];//属性表集合
}
```



#### 静态常量池
- 字面量
- 符号引用
    - 类和接口的全限定名
    - 字段的名称和描述符
    - 方法的名称和描述符
- 好处：**常量池是为了避免频繁的创建和销毁对象而影响系统性能，其实现了对象的共享**。

#### 运行时常量池
当Class文件被加载完成后，java虚拟机会将静态常量池里的内容转移到运行时常量池里，在静态常量池的**符号引用有一部分是会被转变为直接引用**的，比如说类的**静态方法或私有方法，实例构造方法，父类方法**，这是因为这些方法不能被重写其他版本，所以能在加载的时候就可以将符号引用转变为直接引用，而其他的**一些方法是在这个方法被第一次调用的时候才会将符号引用转变为直接引用的**。


#### 字符串常量池
字符串常量池的存在使JVM提高了性能和减少了内存开销。

- 每当我们使用字面量（String s=“1”;）创建字符串常量时，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么就将此字符串对象的地址赋值给引用s（引用s在Java栈。如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中，并将此字符串对象的地址赋值给引用s（引用s在Java栈中）。
- 每当我们使用关键字new（String s=new String(”1”);）创建字符串常量时，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么不再在字符串常量池创建该字符串对象，而直接堆中创建该对象的副本，然后将堆中对象的地址赋值给引用s，如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中，然后在堆中创建该对象的副本，然后将堆中对象的地址赋值给引用s。

#### 版本关系

##### 1.6
- 静态常量池在Class文件中。

- 运行时常量池在Perm Gen区(也就是方法区)中。

- 字符串常量池在运行时常量池中。

##### 1.7
- 静态常量池在Class文件中。
- 运行时常量池依然在Perm Gen区(也就是方法区)中。在JDK7版本中，永久代的转移工作就已经开始了，将譬如符号引用转移到了native heap；字面量转移到了java heap；类的静态变量转移到了java heap。但是运行时常量池依然还存在，只是很多内容被转移，其只存着这些被转移的引用。
- 字符串常量池被分配到了Java堆的主要部分。也就是字符串常量池从运行时常量池分离出来了。

##### 1.8
- 静态常量池在Class文件中。
- JVM已经将运行时常量池从方法区中移了出来，在Java 堆（Heap）中开辟了一块区域存放运行时常量池。同时永久代被移除，以元空间代替。元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。其主要用于存放一些元数据。
- 字符串常量池存在于Java堆中。

### 类加载过程
#### 加载
类加载过程的第一步，主要完成下面3件事情：

- 通过全类名获取定义此类的二进制字节流
- 将字节流所代表的静态存储结构转换为方法区的运行时数据结构
- 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口

**加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了**。

#### 验证
- 文件格式验证：主要验证Class文件是否规范等。
- 元数据验证：对字节码描述的信息语义分析等。
- 字节码验证：确保语义是ok的。
- 符号引用验证：确保解析动作能执行。

#### 准备
**准备阶段是正式为类变量分配内存并设置类变量初始值的阶段**，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：

- 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。
- 这里所设置的初始值"通常情况"下是数据类型默认的零值（如0、0L、null、false等），比如我们定义了`public static int value=111` ，那么 value 变量在准备阶段的初始值就是 0 而不是111（初始化阶段才会复制）。特殊情况：比如给 value 变量加上了 fianl 关键字`public static final int value=111` ，那么准备阶段 value 的值就被复制为 111。

#### 解析
解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。

#### 初始化
初始化是类加载的最后一步，也是真正执行类中定义的 Java 程序代码(字节码)，初始化阶段是执行类构造器 `<clinit> ()`方法的过程。

#### 类加载器
- BootstrapClassLoader(启动类加载器)：最顶层的加载类，由C++实现，负责加载 `%JAVA_HOME%/lib`目录下的jar包和类或者或被 `-Xbootclasspath`参数指定的路径中的所有类。
- ExtensionClassLoader(扩展类加载器)：主要负责加载目录 `%JRE_HOME%/lib/ext` 目录下的jar包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的jar包。
- AppClassLoader(应用程序类加载器)

#### 双亲委派
每一个类都有一个对应它的类加载器。系统中的 ClassLoder 在协同工作的时候会默认使用 **双亲委派模型** 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派该父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为null时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器。

![ClassLoader](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/classloader_WPS图片.png)

#### 好处
双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载，也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。

#### 什么情况下需要开始类加载过程的第一个阶段加载
1. 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：
2. 使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。
3. 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。
4. 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。
5. 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。

### JVM内存
#### 线程计数器
- 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
- 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

**注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。**

#### 虚拟机栈
与程序计数器一样，Java 虚拟机栈也是线程**私有**的，它的生命周期和线程相同，描述的是 Java **方法执行的内存模型**，每次方法调用的数据都是通过栈传递的。

**Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。** 

- 局部变量表
    - 8大基本类型
    - 对象引用：可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置
- 操作数栈
- 动态链接
- 方法出口

- StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 异常。
- OutOfMemoryError：若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 异常。

#### 本地方法栈
和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 其他和Java虚拟机差不多的

#### 方法区
方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 **Non-Heap（非堆）**，目的应该是与 Java 堆区分开来。

JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。

#### 堆
Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。**


- 分为四区，分别为eden区、s0("From)区、s1("To")和tentired
- 在初始阶段，新创建的对象被分配到Eden区，survivor的两块空间都为空。
- 当Eden区满了的时候，minor GC触发
- 经过扫描与标记，存活的对象被复制到S0，不存活的对象被回收
- 在下一次的Minor GC中，Eden区的情况和上面一致，没有引用的对象被回收，存活的对象被复制到survivor区。然而在survivor区，S0的所有的数据都被复制到S1，需要注意的是，在上次minor GC过程中移动到S0中的相同存活的对象在复制到S1后其年龄要加1。此时Eden区S0区被清空，所有存活的数据都复制到了S1区，并且S1区存在着年龄不一样的对象（重点）
- 再下一次MinorGC则重复这个过程，这一次survivor的两个区对换，存活的对象被复制到S0，存活的对象年龄加1，Eden区和另一个survivor区被清空。

注意：逃逸分析
[https://zhuanlan.zhihu.com/p/69136675](https://zhuanlan.zhihu.com/p/69136675)

#### 元空间

#### 直接内存
直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。

#### 对象创建
![对象创建的过程](http://media.dreamcat.ink/uPic/Java创建对象的过程.png)

##### 类加载检查
虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

##### 分配内存
在**类加载检查**通过后，接下来虚拟机将为新生对象**分配内存**。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。**分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种，**选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**。

- 指针碰撞
    - 堆规整（没有内存碎片）
    - 复制算法
    - GC：Serial、ParNew
- 空闲列表
    - 堆内存不规整的情况下
    - 虚拟机会维护一个列表，该列表会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块来划分给对象实例，最后更新列表激励
    - GC：CMS
- 并发问题
    - **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
    - **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

##### 初始化零值
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

##### 设置对象头
初始化零值完成之后，**虚拟机要对对象进行必要的设置**，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 **这些信息存放在对象头中。** 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

##### 指向init方法
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，`` 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 `` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

#### 内存布局
##### 对象头
**Hotspot 虚拟机的对象头包括两部分信息**，**第一部分用于存储对象自身的自身运行时数据**（哈希码、GC 分代年龄、锁状态标志等等），**另一部分是类型指针**，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。

##### 实例数据
**实例数据部分是对象真正存储的有效信息**，也是在程序中所定义的各种类型的字段内容。

##### 对齐填充
**对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。** 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。

##### 对象的访问方式
使用句柄

如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了**对象实例数据**与**类型数据**各自的具体地址信息；

![](https://imgkr.cn-bj.ufileos.com/c4580bee-7ce3-43f8-991b-c28aed9b84c6.png)

直接指针

如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。

![](https://imgkr.cn-bj.ufileos.com/75abc5ff-0eec-403a-b7ff-3dd25c7fd6e5.png)

总结

这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是**稳定**的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 **reference 本身不需要修改**。使用直接指针访问方式最大的好处就是**速度快**，它节省了一次指针定位的时间开销。

### 垃圾回收
#### 对象优先在Eden区分配
大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.下面我们来进行实际测试以下。


- **新生代 GC（Minor GC）**:指发生新生代的的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快。
- **老年代 GC（Major GC/Full GC）**:指发生在老年代的 GC，出现了 Major GC 经常会伴随至少一次的 Minor GC（并非绝对），Major GC 的速度一般会比 Minor GC 的慢 10 倍以上。

#### Minor GC和Full GC触发条件
- Minor GC触发条件：当Eden区满时，触发Minor GC。
- Full GC触发条件：
  1. 调用System.gc时，系统建议执行Full GC，但是不必然执行
  2. 老年代空间不足
  3. **方法区**空间不足
  4. 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
  5. 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小

#### 大对象直接进入老年代
大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。

**为什么要这样呢？**为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

#### 长期存活的对象进入老年代
如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置。

#### 如何判断对象死亡

##### 引用计数法
给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。

**这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。** 

##### 可达性分析
这个算法的基本思想就是通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。


哪些可以作为GC Roots的根

- 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中应用的对象。
- 本地方法栈中JNI（native方法）引用的对象
- 方法区中的类静态属性引用的对象
- 方法区中常量引用的对象

[内存泄露](http://www.ityouknow.com/java/2019/05/23/memory-leak.html)

#### 四大引用
##### 强引用
以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。

##### 软引用
如果一个对象只具有软引用。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

##### 弱引用
弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。


##### 虚引用
"虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。

**虚引用主要用来跟踪对象被垃圾回收的活动**。

#### 如何判断一个常量是废弃常量
运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？

假如在常量池中存在字符串 "abc"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 "abc" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，"abc" 就会被系统清理出常量池。

#### 如何判断一个类是无用的类
判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 **“无用的类”** ：

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的 ClassLoader 已经被回收。
- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。

#### 垃圾回收算法

##### 标记-清除算法
该算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：

- 效率问题
- 空间问题（标记清除后会产生大量不连续的碎片）


##### 标记-整理算法

根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。


##### 复制算法

为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。


##### 分代收集
**比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**

#### 垃圾收集器
##### Serial收集器
它的 **“单线程”** 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。

**新生代采用复制算法，老年代采用标记-整理算法。**

虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。

但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它**简单而高效（与其他收集器的单线程相比）**。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。

##### ParNew收集器
**ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。**

 **新生代采用复制算法，老年代采用标记-整理算法。**


它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。

**并行和并发概念补充：**

- **并行（Parallel）** ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
- **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。

##### Parallel Scavenge收集器

Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。

**Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。** Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。

**新生代采用复制算法，老年代采用标记-整理算法。**

##### Serial Old 收集器

**Serial 收集器的老年代版本**，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。


##### Parallel Old 收集器

**Parallel Scavenge 收集器的老年代版本**。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。

##### CMS收集器
**CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。**

**CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。**

从名字中的**Mark Sweep**这两个词可以看出，CMS 收集器是一种 **“标记-清除”算法**实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：


- 初始标记：暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
- 并发标记：同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- 重新标记：重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- 并发清除：开启用户线程，同时 GC 线程开始对为标记的区域做清扫。

从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：**并发收集、低停顿**。但是它有下面三个明显的缺点：

- **对 CPU 资源敏感；**
- **无法处理浮动垃圾；**
- **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**

##### G1收集器
- 并行与并发： G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU来缩短 Stop-The-World 停顿时间。
- 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
- 空间整合：G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。
- 可预测停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型。

过程：
- 初始标记
- 并发标记
- 最终标记
- 筛选回收

##### G1和CMS的比较
1. CMS收集器是**获取最短回收停顿时间**为目标的收集器，因为CMS工作时，GC工作线程与用户线程可以并发执行，以此来达到降低收集停顿时间的目的（只有初始标记和重新标记会STW）。但是CMS收集器对CPU资源非常敏感。在并发阶段，虽然不会导致用户线程停顿，但是会占用CPU资源而导致引用程序变慢，总吞吐量下降。
2. CMS仅作用于老年代，是基于标记清除算法，所以清理的过程中会有大量的空间碎片。
3. CMS收集器无法处理浮动垃圾，由于CMS并发清理阶段用户线程还在运行，伴随程序的运行自然会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理它们，只好留在下一次GC时将其清理掉。
4. G1是一款面向服务端应用的垃圾收集器，适用于多核处理器、大内存容量的服务端系统。G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU或核心来缩短STW的停顿时间，它满足短时间停顿的同时达到一个高的吞吐量。
5. 从JDK 9开始，G1成为默认的垃圾回收器。当应用有以下任何一种特性时非常适合用G1：Full GC持续时间太长或者太频繁；对象的创建速率和存活率变动很大；应用不希望停顿时间长(长于0.5s甚至1s)。
6. G1将空间划分成很多块（Region），然后他们各自进行回收。堆比较大的时候可以采用，采用复制算法，碎片化问题不严重。整体上看属于标记整理算法,局部(region之间)属于复制算法。
7. G1 需要记忆集 (具体来说是卡表)来记录新生代和老年代之间的引用关系，这种数据结构在 G1 中需要占用大量的内存，可能达到整个堆内存容量的 20% 甚至更多。而且 G1 中维护记忆集的成本较高，带来了更高的执行负载，影响效率。所以 CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6GB到8GB。


### JVM锁优化和膨胀过程
1. 自旋锁：自旋锁其实就是在拿锁时发现已经有线程拿了锁，自己如果去拿会阻塞自己，这个时候会选择进行一次忙循环尝试。也就是不停循环看是否能等到上个线程自己释放锁。自适应自旋锁指的是例如第一次设置最多自旋10次，结果在自旋的过程中成功获得了锁，那么下一次就可以设置成最多自旋20次。
2. 锁粗化：虚拟机通过适当扩大加锁的范围以避免频繁的拿锁释放锁的过程。
3. 锁消除：通过逃逸分析发现其实根本就没有别的线程产生竞争的可能（别的线程没有临界量的引用），或者同步块内进行的是原子操作，而“自作多情”地给自己加上了锁。有可能虚拟机会直接去掉这个锁。
4. 偏向锁：在大多数的情况下，锁不仅不存在多线程的竞争，而且总是由同一个线程获得。因此为了让线程获得锁的代价更低引入了偏向锁的概念。偏向锁的意思是如果一个线程获得了一个偏向锁，如果在接下来的一段时间中没有其他线程来竞争锁，那么持有偏向锁的线程再次进入或者退出同一个同步代码块，不需要再次进行抢占锁和释放锁的操作。
5. 轻量级锁：当存在超过一个线程在竞争同一个同步代码块时，会发生偏向锁的撤销。当前线程会尝试使用CAS来获取锁，当自旋超过指定次数(可以自定义)时仍然无法获得锁，此时锁会膨胀升级为重量级锁。
6. 重量级锁：重量级锁依赖对象内部的monitor锁来实现，而monitor又依赖操作系统的MutexLock（互斥锁）。当系统检查到是重量级锁之后，会把等待想要获取锁的线程阻塞，被阻塞的线程不会消耗CPU，但是阻塞或者唤醒一个线程，都需要通过操作系统来实现。


### GC参数
![解释](http://media.dreamcat.ink/uPic/iShot2020-05-26上午09.58.16.png)


## Spring
### 什么是Spring框架
Spring 框架是有很多模块的集合，使用这些模块可以很方便地协助我们进行开发。

### 列举一些重要的Spring模块
- **Spring Core：** 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注入功能。
- **Spring AOP** ：提供了面向切面的编程实现。
- **Spring JDBC** : Java数据库连接。
- **Spring Web** : 为创建Web应用程序提供支持。
- **Spring Test** : 提供了对 JUnit 和 TestNG 测试的支持。


### IoC
IoC（Inverse of Control:控制反转）是一种**设计思想**，就是 **将原本在程序中手动创建对象的控制权，交由Spring框架来管理。IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。**

将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 **IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。** 

#### 初始化流程
- Resource资源定位：这个Resouce指的是BeanDefinition的资源定位。这个过程就是容器找数据的过程，就像水桶装水需要先找到水一样。
- BeanDefinition的载入和解析：这个载入过程是把用户定义好的Bean表示成Ioc容器内部的数据结构，而这个容器内部的数据结构就是BeanDefition。
- BeanDefinition注册
    - prepareRefresh()：预备一下， 标记启动时间，上下文环境，我要的材料（beanDefinition）准备好了嘛？
    - obtainFreshBeanFactory()：
        - 如果已经有了BeanFactory就销毁它里面的单例Bean并关闭这个BeanFactory。
        - 创建一个新的BeanFactory。
        - 对这个BeanFactory进行定制（customize),如allowBeanDefinitionOverriding等参数
        - 转载BeanDefinitions(读取配置文件，将xml转换成对应得BeanDefinition)
        - 检查是否同时启动了两个BeanFactory。
    - prepareBeanFactory(beanFactory)：设置beanFactory的类加载器，材料（BeanDefinition）解析器等
    - postProcessBeanFactory(beanFactory)：
        - 设置beanFactory的后置处理器
        - 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事
    - invokeBeanFactoryPostProcessors(beanFactory)：
        - 调用beanFactory的后置处理器（BeanDefinitionRegisterPostProcessor和BeanFactoryPostProcessor）
        - 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法
    - registerBeanPostProcessors(beanFactory)：
        - 注册 BeanPostProcessor 的实现类（bean的后置处理器）
        - 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化
    - initMessageSource()：对上下文中的消息源进行初始化
    - initApplicationEventMulticaster()：初始化上下文的事件广播器
    - onRefresh()：- 模版方法，具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）
    - registerListeners()：注册事件监听器
    - finishBeanFactoryInitialization(beanFactory)：初始化所有的 singleton beans
    - finishRefresh()：最后，广播事件，ApplicationContext 初始化完成

### AOP
AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。

- **Spring AOP就是基于动态代理的**
- 如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，
- 而对于没有实现接口的对象，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理。


![](https://user-gold-cdn.xitu.io/2018/9/14/165d631e56799a5c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### 初始化流程
registerAspectJAnnotationAutoProxyCreatorIfNecessary

- 第一句，注册一个AnnotationAwareAspectJAutoProxyCreator（称它为自动代理器），这个Creator是AOP的操作核心，也是扫描Bean，代理Bean的操作所在。
- 第二句，解析配置元素，决定代理的模式。其中有JDK动态代理，还有CGLIB代理，这部分后续会再细讲。
- 第三句，作为系统组件，把Creator这个Bean，放到Spring容器中。让Spring实例化，启动这个Creator。

总结：
- Spring加载自动代理器AnnotationAwareAspectJAutoProxyCreator，当作一个系统组件。
- 当一个bean加载到Spring中时，会触发自动代理器中的bean后置处理，然后会先扫描bean中所有的Advisor
- 然后用这些Adviosr和其他参数构建ProxyFactory
- ProxyFactory会根据配置和目标对象的类型寻找代理的方式（JDK动态代理或CGLIG代理）
- 然后代理出来的对象放回context中，完成Spring AOP代理

### bean

#### bean的作用域
- singleton 作用域：表示在 Spring 容器中只有一个 Bean 实例，以单例的形式存在，是默认的 Bean 作用域。
- prototype 作用域：原型作用域，每次调用 Bean 时都会创建一个新实例，也就是说每次调用 getBean() 方法时，相当于执行了 new Bean()。
- request 作用域：每次 Http 请求时都会创建一个新的 Bean，该作用域仅适应于 WebApplicationContext 环境。
- session 作用域：同一个 Http Session 共享一个 Bean 对象，不同的 Session 拥有不同的 Bean 对象，仅适用于 WebApplicationContext 环境。
- application 作用域：全局的 Web 作用域，类似于 Servlet 中的 Application。


#### 什么是三级缓存
1. 第一级缓存：单例缓存池singletonObjects。
2. 第二级缓存：早期提前暴露的对象缓存earlySingletonObjects。（属性还没有值对象也没有被初始化）
3. 第三级缓存：singletonFactories单例对象工厂缓存。

#### 创建Bean的整个过程
1. 首先finishBeanFactoryInitialization->preInstantiateSingletons->getBean->doGetBean;
2. 在doGetBean中，transformedBeanName:主要负责判断一下有木有别名；getSingleton：从一级缓存singletonObjects拿bean，在getSingleton方法中，有一个判断条件就是isSingletonCurrentlyInCreation，判断为false，因为他是第一次进来，并且还没有正在创建该bean；dependsOn：依赖，暂时先不说他。
3. 再来一次getSingleton：再一次的从singketonObjects缓存拿，依然没有的。接着有个重点beforeSingletonCreation：它把bean添加到临时的singletonsCurrentlyInCreation，这就意味着，下次再碰见它，那可就是true了。接着singletonFactory.getObject()，这里getObject调用的是传递的接口createBean方法。
4. 在createBean方法中：有个doCreateBean->createBeanInstance方法：它就是直接实例化，实际上构造器有反应了（区分JVM创建对象和Spring创建对象），但是没有赋值（初始化）；earlySingletonExposure：提前暴漏该bean。但要知道三个变量，为什么他是true：isSingleton()，是否单例，那肯定是哦；（这里解释了这里是单例才能提前曝漏，意味着才能存三级缓存）allowCircularReferences，默认变量为true，写死了；isSingletonCurrentlyInCreation，这里可就为true了，因为步骤3，已经将它设置为true了。那么会进来这个方法：addSingletonFactory
5. addSingletonFactory在这个方法中：将该bean放入到三级缓存singletonFactories中。（解决循环依赖）
6. 接下来，就是它了，populateBean：实际上就是属性赋值。（如果这里要有A依赖B，又发现三级缓存中没有B，那么它就会再次执行一次（递归开始）getBean->doGetBean->createBeanInstance(把B给实例化一下)，同样的道理，这里会将B也会放入三级缓存中，B开始populateBean，那么它发现B依赖A，此时三级缓存中有A(精髓，牛逼)，然后把A放到二级缓存中，同时从三级缓存中移除，接着得到A之后直接赋值，最后完成了初始化，然后来到addSingleton，将B仍到了一级缓存，同时将B从三级缓存仍出去）返回B，递归结束，得到B之后将B的赋值给A了。
7. 最后将二级缓存的A删除，仍到一级缓存中。


#### Spring的单例有线程安全问题吗
大部分时候我们并没有在系统中使用多线程，所以很少有人会关注这个问题。单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。

常见的有两种解决办法：

- 在Bean对象中尽量避免定义可变的成员变量（不太现实）。
- 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。


#### bean的生命周期
![bean周期](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-17/5496407.jpg)

- Bean 容器找到配置文件中 Spring Bean 的定义。
- Bean 容器利用 Java Reflection API 创建一个Bean的实例。
- 如果涉及到一些属性值 利用 `set()`方法设置一些属性值。
- 如果 Bean 实现了 `BeanNameAware` 接口，调用 `setBeanName()`方法，传入Bean的名字。
- 如果 Bean 实现了 `BeanClassLoaderAware` 接口，调用 `setBeanClassLoader()`方法，传入 `ClassLoader`对象的实例。
- 与上面的类似，如果实现了其他 `*.Aware`接口，就调用相应的方法。
- 如果有和加载这个 Bean 的 Spring 容器相关的 `BeanPostProcessor` 对象，执行`postProcessBeforeInitialization()` 方法
- 如果Bean实现了`InitializingBean`接口，执行`afterPropertiesSet()`方法。
- 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。
- 如果有和加载这个 Bean的 Spring 容器相关的 `BeanPostProcessor` 对象，执行`postProcessAfterInitialization()` 方法
- 当要销毁 Bean 的时候，如果 Bean 实现了 `DisposableBean` 接口，执行 `destroy()` 方法。
- 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。

### SpringMVC
![springmvc工作原理](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-11/49790288.jpg)

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler`来调用真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）

### 用到了哪些设计模式
- **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。
- **代理设计模式** : Spring AOP 功能的实现。
- **单例设计模式** : Spring 中的 Bean 默认都是单例的。
- **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
- **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。
- **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。
- **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。
- ......


### Spring如何解决循环依赖问题
Spring使用了三级缓存解决了循环依赖的问题。在populateBean()给属性赋值阶段里面Spring会解析你的属性，并且赋值，当发现，A对象里面依赖了B，此时又会走getBean方法，但这个时候，你去缓存中是可以拿的到的。因为我们在对createBeanInstance对象创建完成以后已经放入了缓存当中，所以创建B的时候发现依赖A，直接就从缓存中去拿，此时B创建完，A也创建完，一共执行了4次。至此Bean的创建完成，最后将创建好的Bean放入单例缓存池中。

### BeanFactory和ApplicationContext的区别
1. BeanFactory是Spring里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能。
2. ApplicationContext应用上下文，继承BeanFactory接口，它是Spring的一各更高级的容器，提供了更多的有用的功能。如国际化，访问资源，载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，消息发送、响应机制，AOP等。
3. BeanFactory在启动的时候不会去实例化Bean，中有从容器中拿Bean的时候才会去实例化。ApplicationContext在启动的时候就把所有的Bean全部实例化了。它还可以为Bean配置lazy-init=true来让Bean延迟实例化

### Spring的后置处理器
1. BeanPostProcessor：Bean的后置处理器，主要在bean初始化前后工作。
2. InstantiationAwareBeanPostProcessor：继承于BeanPostProcessor，主要在实例化bean前后工作； AOP创建代理对象就是通过该接口实现。
3. BeanFactoryPostProcessor：Bean工厂的后置处理器，在bean定义(bean definitions)加载完成后，bean尚未初始化前执行。
4. BeanDefinitionRegistryPostProcessor：继承于BeanFactoryPostProcessor。其自定义的方法postProcessBeanDefinitionRegistry会在bean定义(bean definitions)将要加载，bean尚未初始化前真执行，即在BeanFactoryPostProcessor的postProcessBeanFactory方法前被调用。

### Spring事务
#### 隔离级别
- **TransactionDefinition.ISOLATION_DEFAULT:** 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
- **TransactionDefinition.ISOLATION_READ_UNCOMMITTED:** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**
- **TransactionDefinition.ISOLATION_READ_COMMITTED:** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**
- **TransactionDefinition.ISOLATION_REPEATABLE_READ:** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**
- **TransactionDefinition.ISOLATION_SERIALIZABLE:** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

#### @Transactional(rollbackFor = Exception.class)注解了解吗
1. @Transactional注解只能应用到public修饰符上，其它修饰符不起作用，但不报错。
2. 默认情况下此注解会对unchecked异常进行回滚，对checked异常不回滚。

> checked异常：表示无效，不是程序中可以预测的。比如无效的用户输入，文件不存在，网络或者数据库链接错误。这些都是外在的原因，都不是程序内部可以控制的。unchecked异常：表示错误，程序的逻辑错误。是RuntimeException的子类，比如IllegalArgumentException, NullPointerException和IllegalStateException。

不回滚解决方案：
1. 检查方法是不是public
2. 检查异常是不是unchecked异常
3. 如果是checked异常也想回滚的话，注解上写明异常类型即可@Transactional(rollbackFor=Exception.class)

事务失效的8大原因：
1. 数据库引擎不支持事务
2. 没有被 Spring 管理
3. 方法不是 public 的
4. 自身调用问题
5. 数据源没有配置事务管理器
6. 不支持事务（传播机制）
7. 异常被吃了（捕获异常）
8. 异常类型错误（checked异常失效）


#### Spring的的事务传播机制
1. **required**（默认）：支持使用当前事务，如果当前事务不存在，创建一个新事务。
2. **requires_new**：创建一个新事务，如果当前事务存在，把当前事务挂起。
3. **supports**：支持使用当前事务，如果当前事务不存在，则不使用事务。
4. **not_supported**：无事务执行，如果当前事务存在，把当前事务挂起。
5. **mandatory**：强制，支持使用当前事务，如果当前事务不存在，则抛出Exception。
6. **never**：无事务执行，如果当前有事务则抛出Exception。
7. **nested**：嵌套事务，如果当前事务存在，那么在嵌套的事务中执行。如果当前事务不存在，则表现跟REQUIRED一样。

#### 事务源码
- 开启@EnableTransactionManagement
- 利用TransactionManagementConfigurationSelector给容器中会导入组件
    - AutoProxyRegistrar
        - 给容器中注册一个 InfrastructureAdvisorAutoProxyCreator 组件
        - 利用后置处理器机制在对象创建以后，包装对象，返回一个代理对象（增强器），代理对象执行方法利用拦截器链进行调用；
    - ProxyTransactionManagementConfiguration（给容器中注册事务增强器）
        - 事务增强器要用事务注解的信息，AnnotationTransactionAttributeSource解析事务注解
        - 事务拦截器

### Springboot
#### SpringBootApplication的注解
[https://www.jianshu.com/p/943650ab7dfd](https://www.jianshu.com/p/943650ab7dfd)

- @SpringBootConfiguration:允许在上下文中注册额外的bean或导入其他配置类
- @EnableAutoConfiguration:启用 SpringBoot 的自动配置机制
- @ComponentScan: 扫描常用的注解

其中 @EnableAutoConfiguration 是实现自动配置的入口，该注解又通过 @Import 注解导入了AutoConfigurationImportSelector，在该类中加载 META-INF/spring.factories 的配置信息。然后筛选出以 EnableAutoConfiguration 为 key 的数据，加载到 IOC 容器中，实现自动配置功能！

#### 源码过程
- 创建计时器StopWatch
- 获取SpringApplicationRunListeners并启动
- 创建ApplicationArguments
- 创建并初始化ConfigurableEnvironment
- 打印Banner
- 创建ConfigurableApplicationContext
- 准备ConfigurableApplicationContext
- 刷新ConfigurableApplicationContext，**这个refreshContext()加载了bean，还启动了内置web容器，需要细细的去看看**
- 容器刷新后动作，啥都没做
- 计时器停止计时

**总结：run() 方法主要调用了spring容器启动方法扫描配置，加载bean到spring容器中；启动的内置Web容器**


# 数据库

## MySQL

### SQL执行顺序
SQL的执行顺序：from---where--group by---having---select---order by

### MySQL是如何执行一条SQL的
![执行过程图](http://media.dreamcat.ink/uPic/SQL%E6%89%A7%E8%A1%8C%E7%9A%84%E5%85%A8%E9%83%A8%E8%BF%87%E7%A8%8B.png)

**MySQL内部可以分为服务层和存储引擎层两部分：**

1. **服务层包括连接器、查询缓存、分析器、优化器、执行器等**，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
2. **存储引擎层负责数据的存储和提取**，其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认的存储引擎。

**Server层按顺序执行sql的步骤为**：
客户端请求:
- **连接器**（验证用户身份，给予权限） 
- **查询缓存**（存在缓存则直接返回，不存在则执行后续操作）
- **分析器**（对SQL进行词法分析和语法分析操作） 
- **优化器**（主要对执行的sql优化选择最优的执行方案方法） 
- **执行器**（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）
- **去引擎层获取数据返回**（如果开启查询缓存则会缓存查询结果）

### 数据库引Innodb与MyISAM的区别
#### Innodb
- 是 MySQL 默认的**事务型存储引擎**，只有在需要它不支持的特性时，才考虑使用其它存储引擎。
- 实现了四个标准的隔离级别，默认级别是**可重复读(REPEATABLE READ)**。在可重复读隔离级别下，通过**多版本并发控制**(MVCC)+ (Next-Key Locking)**防止幻影读**。
- 主索引是**聚簇索引**，在**索引中保存了数据**，从而避免直接读取磁盘，因此对查询性能有很大的提升。
- 内部做了很多优化，包括从磁盘读取数据时采用的**可预测性读**、能够加快读操作并且自动创建的**自适应哈希索引**、能够加速插入操作的**插入缓冲区**等。
- 支持真正的在**线热备份**。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

#### MyISAM
- 设计简单，数据以**紧密格式存储**。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
- 提供了大量的特性，包括**压缩表、空间数据索引**等。
- **不支持事务**。
- **不支持行级锁，只能对整张表加锁**，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。

#### 简单对比
- **事务**: InnoDB 是事务型的，可以使用 `Commit` 和 `Rollback` 语句。
- **并发**: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- **外键**: InnoDB 支持外键。
- **备份**: InnoDB 支持在线热备份。
- **崩溃恢复**: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- **其它特性**: MyISAM 支持压缩表和空间数据索引。


#### MySQL的ACID原理
##### 原子性(Atomicity)
根据定义，原子性是指一个事务是一个不可分割的工作单位，**其中的操作要么都做，要么都不做**。即要么转账成功，要么转账失败，是不存在中间的状态！

**如果无法保证原子性会怎么样？**

OK，就会出现数据不一致的情形，A账户减去50元，而B账户增加50元操作失败。系统将无故丢失50元~

##### 一致性(Consistency)
根据定义，一致性是指事务执行前后，数据处于一种合法的状态，这种状态是语义上的而不是语法上的。 那什么是合法的数据状态呢？ oK，这个状态是满足预定的约束就叫做合法的状态，再通俗一点，这状态是由你自己来定义的。**满足这个状态，数据就是一致的，不满足这个状态，数据就是不一致的！**

---
**如果无法保证一致性会怎么样？**

- 例一:A账户有200元，转账300元出去，此时A账户余额为-100元。你自然就发现了此时数据是不一致的，为什么呢？因为你定义了一个状态，余额这列必须大于0。
- 例二:A账户200元，转账50元给B账户，A账户的钱扣了，但是B账户因为各种意外，余额并没有增加。你也知道此时数据是不一致的，为什么呢？因为你定义了一个状态，要求A+B的余额必须不变。

##### 隔离性(Isolation)
根据定义，隔离性是指**多个事务并发执行的时候，事务内部的操作与其他事务是隔离的**，并发执行的各个事务之间不能互相干扰。

**如果无法保证隔离性会怎么样？**

OK，假设A账户有200元，B账户0元。A账户往B账户转账两次，金额为50元，分别在两个事务中执行。如果无法保证隔离性，会出现下面的情形

##### 持久性(Durability)
根据定义，**持久性是指事务一旦提交，它对数据库的改变就应该是永久性的**。接下来的其他操作或故障不应该对其有任何影响。

**如果无法保证持久性会怎么样？**

在MySQL中，为了解决CPU和磁盘速度不一致问题，MySQL是将磁盘上的数据加载到内存，对内存进行操作，然后再回写磁盘。好，假设此时宕机了，在内存中修改的数据全部丢失了，持久性就无法保证。

设想一下，系统提示你转账成功。但是你发现金额没有发生任何改变，此时数据出现了不合法的数据状态，我们将这种状态认为是**数据不一致**的情形。

##### 保证一致性
OK，这个问题分为两个层面来说。 

- **从数据库层面**，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。**数据库必须要实现AID三大特性，才有可能实现一致性**。例如，原子性无法保证，显然一致性也无法保证。
- **从应用层面**，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！


##### 保证原子性
OK，是利用Innodb的**undo log**。 **undo log**名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。 例如

- 当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据
- 当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作
- 当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操作

**undo log**记录了这些回滚需要的信息，当事务执行失败或调用了**rollback**，导致事务需要回滚，便可以利用**undo log**中的信息将数据回滚到修改之前的样子。


##### 保证持久性
OK，是利用Innodb的**redo log**。 正如之前说的，MySQL是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。 怎么解决这个问题？ 简单啊，事务提交前直接把数据写入磁盘就行啊。 这么做有什么问题？

- 只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面16kb大小，你只改其中一点点东西，就要将16kb的内容刷入磁盘，听着也不合理。
- 毕竟一个事务里的SQL可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机IO。显然操作随机IO，速度会比较慢。

于是，决定采用**redo log**解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在**redo log**中记录这次操作。当事务提交的时候，会将**redo log**日志进行刷盘(**redo log**一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据**undo log**和**binlog**内容决定回滚数据还是提交数据。

**采用redo log的好处？**

其实好处就是将**redo log**进行刷盘比对数据页刷盘效率高，具体表现如下：

- **redo log**体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。
- **redo log**是一直往末尾进行追加，属于顺序IO。效率显然比随机IO来的快。

##### 保证隔离性
**利用的是锁和MVCC机制。**

### 并发事务带来的问题
#### 脏读

第一个事务首先读取var变量为50，接着准备更新为100的时，并未提交，第二个事务已经读取var为100，此时第一个事务做了回滚。最终第二个事务读取的var和数据库的var不一样。


#### 丢弃修改

T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。例如：事务1读取某表中的数据A=50，事务2也读取A=50，事务1修改A=A+50，事务2也修改A=A+50，最终结果A=100，事务1的修改被丢失。


#### 不可重复读

T2 读取一个数据，T1 对该数据做了修改并提交。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

#### 幻读

T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。


#### 不可重复读和幻读
**不可重复读的重点是修改，幻读的重点在于新增或者删除。**

- 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导致A再读自己的工资时工资变为 2000；这就是不可重复读。
- 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记 录就变为了5条，这样就导致了幻读。

### 数据库的隔离级别
MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ**（可重读）

**这里需要注意的是**：与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别 下使用的是**Next-Key Lock 锁**算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以 说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要 求，即达到了 SQL标准的SERIALIZABLE(可串行化)隔离级别。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内 容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）并不会有任何性能损失**。

InnoDB 存储引擎在分布式事务 的情况下一般会用到SERIALIZABLE(可串行化)隔离级别。

#### 未提交读
事务中发生了修改，即使没有提交，其他事务也是可见的，比如对于一个数A原来50修改为100，但是我还没有提交修改，另一个事务看到这个修改，而这个时候原事务发生了回滚，这时候A还是50，但是另一个事务看到的A是100.**可能会导致脏读、幻读或不可重复读**

#### 提交读
对于一个事务从开始直到提交之前，所做的任何修改是其他事务不可见的，举例就是对于一个数A原来是50，然后提交修改成100，这个时候另一个事务在A提交修改之前，读取的A是50，刚读取完，A就被修改成100，这个时候另一个事务再进行读取发现A就突然变成100了；**可以阻止脏读，但是幻读或不可重复读仍有可能发生**

#### 可重复读
就是对一个记录读取多次的记录是相同的，比如对于一个数A读取的话一直是A，前后两次读取的A是一致的；**可以阻止脏读和不可重复读，但幻读仍有可能发生**

#### 可串行读
在并发情况下，和串行化的读取的结果是一致的，没有什么不同，比如不会发生脏读和幻读；**该级别可以防止脏读、不可重复读以及幻读**


### 索引
#### 索引类型
- FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。
- HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。 HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。
- BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。
- RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。 相对于BTREE，RTREE的优势在于范围查找。


#### 索引种类
- 普通索引：仅加速查询
- 唯一索引：加速查询 + 列值唯一（可以有null）
- 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个
- 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
- 全文索引：对文本的内容进行分词，进行搜索
- 索引合并：使用多个单列索引组合搜索
- 覆盖索引：select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖
- 聚簇索引：表数据是和主键一起存储的，主键索引的叶结点存储行数据(包含了主键值)，二级索引的叶结点存储行的主键值。使用的是B+树作为索引的存储结构，非叶子节点都是索引关键字，但非叶子节点中的关键字中不存储对应记录的具体内容或内容地址。叶子节点上的数据是主键与具体记录(数据内容)

#### 查询在什么时候不走（预期中的）索引
1. 模糊查询 %like
2. 索引列参与计算,使用了函数
3. 非最左前缀顺序
4. where对null判断
5. where不等于
6. or操作有至少一个字段没有索引
7. 需要回表的查询结果集过大（超过配置的范围）
8. - **将打算加索引的列设置为NOT NULL，否则将导致引擎放弃使用索引而进行全表扫描**

#### 索引结构
**MyISAM**：
1. MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址，同样使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址
2. 在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复
3. MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录

**InnoDB**：
1. InnoDB的数据文件本身就是索引文件，这棵树的叶节点data域保存了完整的数据记录（聚集索引）
2. InnoDB的辅助索引data域存储相应记录主键的值而不是地址
3. 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

#### 索引最左原则
**举例子**：
如果索引列分别为A，B，C，顺序也是A，B，C：

- 那么查询的时候，如果查询【A】【A，B】 【A，B，C】，那么可以通过索引查询
- 如果查询的时候，采用【A，C】，那么C这个虽然是索引，但是由于中间缺失了B，因此C这个索引是用不到的，只能用到A索引
- 如果查询的时候，采用【B】 【B，C】 【C】，由于没有用到第一列索引，不是最左前缀，那么后面的索引也是用不到了
- 如果查询的时候，采用范围查询，并且是最左前缀，也就是第一列索引，那么可以用到索引，但是范围后面的列无法用到索引

#### 为什么使用索引
- 通过创建唯一性索引，可以保证数据库表中每一行数据的**唯一性**。
- 可以大大加快数据的**检索速度**，这也是创建索引的最主要的原因。
- 帮助服务器**避免排序和临时表**。
- 将**随机IO变为顺序IO**。
- 可以**加速表和表之间的连接**，特别是在实现数据的参考完整性方面特别有意义。

缺点

- 当对表中的数据进行增加、删除和修改的时候，**索引也要动态的维护**，这样就降低了数据的维护速度。
- 索引需要**占物理空间**，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立簇索引，那么需要的空间就会更大。
- **创建索引和维护索引要耗费时间**，这种时间随着数据量的增加而增加


#### 注意事项(优化)
- 在经常使用在where子句中的列上面创建索引，加快条件的判断速度。
- 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间
- 在中到大型表索引都是非常有效的，但是特大型表的维护开销会很大，不适合建索引
- 在经常用到连续的列上，这些列主要是由一些外键，可以加快连接的速度
- 避免where子句中对字段施加函数，这会造成无法命中索引
- 在使用InnoDB时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。
- **将打算加索引的列设置为NOT NULL，否则将导致引擎放弃使用索引而进行全表扫描**
- 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗
- 在使用limit offset查询缓存时，可以借助索引来提高性能。

### 慢查询优化
1. 先运行看看是否真的很慢，注意设置SQL_NO_CACHE
2. where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
3. explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
4. order by limit 形式的sql语句让排序的表优先查
5. 了解业务方使用场景
6. 加索引时参照建索引的几大原则
7. 观察结果，不符合预期继续从0分析

### 聊聊Explain
> 常常用到explain这个命令来查看一个这些SQL语句的执行计划，查看该SQL语句有没有使用上了索引，有没有做全表扫描，这都可以通过explain命令来查看

1. id : 表示SQL执行的顺序的标识,SQL从大到小的执行
2. select_type：表示查询中每个select子句的类型
3. table：显示这一行的数据是关于哪张表的，有时不是真实的表名字
4. type：表示MySQL在表中找到所需行的方式，又称“访问类型”。常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）
5. possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用
6. Key：key列显示MySQL实际决定使用的键（索引），如果没有选择索引，键是NULL。
7. key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）
8. ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
9. rows： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数，理论上行数越少，查询性能越好
10. Extra：该列包含MySQL解决查询的详细信息

> 结合项目的SQL语句优化讲解会更好

#### (SQL调优)Explain

> 分别对应：
>
> id  select_type  table  type  possible_keys  key  key_len  ref  rows  Extra
>
> 参考：[https://juejin.im/post/5ec4e4a5e51d45786973b357](https://juejin.im/post/5ec4e4a5e51d45786973b357)

##### checkUsername

```sql
SELECT
	*
FROM
	sb_user su
WHERE
	user_name = 'mai';
```

- 不加索引

```sql
1	"SIMPLE"	"su"	"ALL"	NULL	NULL	NULL	NULL	11	"Using where"
```

- 唯一索引

```sql
1	"SIMPLE"	"su"	"const"	"user_name"	"user_name"	"152"	"const"	1	""
```

- 普通索引

```sql
1	"SIMPLE"	"su"	"ref"	"user_name"	"user_name"	"152"	"const"	1	"Using index condition"
```

##### getCount

```sql
SELECT
	sc.uuid,
	sc.begin_date,
	sc.begin_time,
	sc.bus_id,
	sc.bus_status,
	sc.seat_status
FROM
	sb_count sc
WHERE
    sc.bus_status = '1'
	AND sc.begin_date = '2020-06-03'
	AND sc.begin_time >= '14:00';
```

- 不加索引

```sql
1	"SIMPLE"	"sc"	"ALL"	NULL	NULL	NULL	NULL	1293	"Using where"
```

- 给bus_status加普通索引

```sql
1	"SIMPLE"	"sc"	"ref"	"bus_status"	"bus_status"	"152"	"const"	639	"Using index condition; Using where"
```

- 给begin_date加普通索引

```sql
1	"SIMPLE"	"sc"	"ref"	"bus_status,begin_date"	"begin_date"	"402"	"const"	17	"Using index condition; Using where"
```

- 给bus_status,begin_date加联合索引
```sql
1	"SIMPLE"	"sc"	"ref"	"bus_status_date"	"bus_status,begin_date"	"554"	"const,const"	8	"Using index condition; Using where"
```

- 给bus_status,begin_date,begin_time加联合索引

```sql
1	"SIMPLE"	"sc"	"range"	"bus_status_date_time"	"bus_status,begin_date,bgin_time"	"706"	NULL	4	"Using index condition"
```


##### getNoTakeOrdersById

```sql
SELECT
	so.uuid,
	so.bus_status,
	so.seats_ids,
	so.order_user,
	so.order_status,
	so.order_time,
	sc.bus_id,
	CONCAT(sc.begin_date, ' ', sc.begin_time) begin_time
FROM
	sb_order so
	LEFT JOIN sb_count sc ON so.count_id = sc.uuid
WHERE
	so.user_id = '4'
	AND so.order_status = '1'
	AND sc.begin_date >= '2020-06-03'
	AND sc.begin_time >= '15:00';
```

- 不加普通索引

```
1	"SIMPLE"	"so"	"ALL"	NULL	NULL	NULL	NULL	59	"Using where"
1	"SIMPLE"	"sc"	"eq_ref"	"PRIMARY"	"PRIMARY"	"8"	"school_bus.so.count_id"	1	"Using where"
```

- user_id+order_status加联合索引

```
1	"SIMPLE"	"so"	"ref"	"user_id_order_status"	"user_id,order_status"	"160"	"const,const"	10	"Using index condition"
1	"SIMPLE"	"sc"	"eq_ref"	"PRIMARY"	"PRIMARY"	"8"	"school_bus.so.count_id"	1	"Using where"
```

### 数据库结构优化

- 范式优化：比如消除冗余（节省空间。。）
- 反范式优化：比如适当加冗余等（减少join）
- 限定数据的范围：务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。
- 读/写分离：经典的数据库拆分方案，主库负责写，从库负责读；
- 拆分表：分区将数据在物理上分隔开，不同分区的数据可以制定保存在处于不同磁盘上的数据文件里。这样，当对这个表进行查询时，只需要在表分区中进行扫描，而不必进行全表扫描，明显缩短了查询时间，另外处于不同磁盘的分区也将对这个表的数据传输分散在不同的磁盘I/O，一个精心设置的分区可以将数据传输对磁盘I/O竞争均匀地分散开。对数据量大的时时表可采取此方法。可按月自动建表分区。

案例：
- 案例： 简单购物系统暂设涉及如下表：
- 1.产品表（数据量10w，稳定）
- 2.订单表（数据量200w，且有增长趋势）
- 3.用户表 （数据量100w，且有增长趋势）
- 以mysql为例讲述下水平拆分和垂直拆分，mysql能容忍的数量级在百万静态数据可以到千万

垂直拆分：

- 解决问题：表与表之间的io竞争
- 不解决问题：单表中数据量增长出现的压力
- 方案： 把产品表和用户表放到一个server上 订单表单独放到一个server上

水平拆分：

- 解决问题：单表中数据量增长出现的压力
- 不解决问题：表与表之间的io争夺

总结：

方案：**用户表** 通过性别拆分为男用户表和女用户表，**订单表** 通过已完成和完成中拆分为已完成订单和未完成订单，**产品表** 未完成订单放一个server上，已完成订单表盒男用户表放一个server上，女用户表放一个server上(女的爱购物 哈哈)。


### 三范式
#### 第一范式
所谓第一范式是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，**第一范式就是无重复的列**。

#### 第二范式
第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。简而言之，**第二范式就是非主属性非部分依赖于主关键字**。

#### 第三范式
简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。例如，**存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。**简而言之，第三范式就是属性不依赖于其它非主属性。（我的理解是消除冗余）

### 读写分离原理
主库（master）将变更写**binlog**日志，然后从库（slave）连接到主库之后，从库有一个**IO线程**，将主库的binlog日志**拷贝到自己本地**，写入一个中继日志中。接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。

这里有一个非常重要的一点，就是从库同步主库数据的过程是**串行化**的，也就是说**主库上并行**的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。

所以mysql实际上在这一块有两个机制，一个是**半同步复制**，用来解决主库数据丢失问题；一个是**并行复制**，用来解决主从同步延时问题。

所谓并行复制，指的是从库**开启多个线程，并行读取relay log中不同库的日志**，然后并行重放不同库的日志，这是库级别的并行。


![](https://static01.imgkr.com/temp/11238363926347a680ce5f7ef6ecbacf.png)


### MVCC
#### 快照读
一个是行的创建版本，一个是行的删除（过期）版本。具体的版本号（trx_id）存在 information_schema.INNODB_TRX 表中。版本号（trx_id）随着每次事务的开启自增。

事务每次取数据的时候都会取创建版本小于当前事务版本的数据，以及过期版本大于当前版本的数据。


**普通的 select 就是快照读**。

InnoDB的实现

1. 事务以**排他锁**的形式修改原始数据
2. 把修改前的数据存放于**undo log**，通过回滚指针与主数据关联
3. 修改成功（commit），数据放到**redo log**中，失败则恢复**undo log**中的数据（rollback）

在RR级别下，快照读是通过MVVC(多版本控制)和undo log来实现的，当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的。
innodb在快照读的情况下并没有真正的避免幻读, 但是在当前读的情况下避免了不可重复读和幻读!!!

#### 当前读

- select ... lock in share mode
- select ... for update
- insert
- update
- delete

next-key 锁包含两部分：

- 记录锁（行锁）
- 间隙锁

记录锁是加在索引上的锁，间隙锁是加在索引之间的。

原理：将当前数据行与上一条数据和下一条数据之间的间隙锁定，保证此范围内读取的数据是一致的。


#### 缺点
MVCC在大多数情况下代替了行锁，实现了对读的非阻塞，读不加锁，读写不冲突。缺点是每行记录都需要额外的存储空间，需要做更多的行维护和检查工作。 要知道的，MVCC机制下，会在更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本。 而undo log这个关键的东西，记载的内容是串行化的结果，记录了多个事务的过程，不属于多版本共存。 这么一看，似乎mysql的mvcc也并没有所谓的多版本共存


### 红黑树、b和b+
- Hash索引：Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描
- 二叉查找树：解决了排序的基本问题，但是由于无法保证平衡，可能退化为链表。
- 平衡二叉树：通过旋转解决了平衡的问题，但是旋转操作效率太低。
- 红黑树：通过舍弃严格的平衡和引入红黑节点，解决了 AVL旋转效率过低的问题，但是在磁盘等场景下，树仍然太高，IO次数太多。
- B+树：在B树的基础上，将非叶节点改造为不存储数据纯索引节点，进一步降低了树的高度；此外将叶节点使用指针连接成链表，范围查询更加高效。

#### 红黑树(补充)
- 每个结点要么是红的要么是黑的。（红或黑）
- 根结点是黑的。 （根黑）
- 每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。 （叶黑）
- 如果一个结点是红的，那么它的两个儿子都是黑的。 （红子黑）
- 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。（路径下黑相同）

#### b(补充)
B树（英语: B-tree）是一种自平衡的树，能够保持数据有序。这种数据结构能够让**查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成**。B树，概括来说是一个**一般化的二叉查找树**（binary search tree），可以拥有最多2个子节点。与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。其中，概念较为复杂，给个简单的图理解：


- 关键字集合分布在整颗树中；
- 任何一个关键字出现且只出现在一个结点中；
- 搜索有可能在非叶子结点结束；
- 其搜索性能等价于在关键字全集内做一次二分查找；

#### b+(补充)

- 在B树基础上，为**叶子结点增加链表指针**（B树+叶子有序链表），所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。
- B+树的**非叶子节点不保存数据**，只保存**子树的临界值**（最大或者最小），所以同样大小的节点，**B+树相对于B树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少**。

### 持久性
OK，是利用Innodb的**redo log**。 正如之前说的，MySQL是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。 怎么解决这个问题？ 简单啊，事务提交前直接把数据写入磁盘就行啊。 这么做有什么问题？

- 只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面16kb大小，你只改其中一点点东西，就要将16kb的内容刷入磁盘，听着也不合理。
- 毕竟一个事务里的SQL可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机IO。显然操作随机IO，速度会比较慢。

于是，决定采用**redo log**解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在**redo log**中记录这次操作。当事务提交的时候，会将**redo log**日志进行刷盘(**redo log**一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据**undo log**和**binlog**内容决定回滚数据还是提交数据。

**采用redo log的好处？**

其实好处就是将**redo log**进行刷盘比对数据页刷盘效率高，具体表现如下：

- **redo log**体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。
- **redo log**是一直往末尾进行追加，属于顺序IO。效率显然比随机IO来的快。

### MVCC,redolog,undolog,binlog
- undoLog 也就是我们常说的**回滚日志文件** 主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现,是逻辑日志,记录数据修改被修改前的值,比如"把id='B' 修改为id = 'B2' ，那么undo日志就会用来存放id ='B'的记录”。当一条数据需要更新前,会先把修改前的记录存储在undolog中,如果这个修改出现异常,,则会使用undo日志来实现回滚操作,保证事务的一致性。当事务提交之后，undo log并不能立马被删除,而是会被放到待清理链表中,待判断没有事务用到该版本的信息时才可以清理相应undolog。它保存了事务发生之前的数据的一个版本，用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
- redoLog 是重做日志文件是记录数据修改之后的值，用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。由引擎层的InnoDB引擎实现,是物理日志,记录的是物理数据页修改的信息,比如“某个数据页上内容发生了哪些改动”。当一条数据需要更新时,InnoDB会先将数据更新，然后记录redoLog 在内存中，然后找个时间将redoLog的操作执行到磁盘上的文件上。不管是否提交成功我都记录，你要是回滚了，那我连回滚的修改也记录。它确保了事务的持久性。
- MVCC多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于读已提交和可重复读取隔离级别的实现。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行数据的事务ID，指向该行（undolog表中）回滚段的指针。Read View判断行的可见性，创建一个新事务时，copy一份当前系统中的活跃事务列表。意思是，当前不应该被本事务看到的其他事务id列表。
- binlog由Mysql的Server层实现,是逻辑日志,记录的是sql语句的原始逻辑，比如"把id='B' 修改为id = ‘B2’。binlog会写入指定大小的物理文件中,是追加写入的,当前文件写满则会创建新的文件写入。 产生:事务提交的时候,一次性将事务中的sql语句,按照一定的格式记录到binlog中。用于复制和恢复在主从复制中，从库利用主库上的binlog进行重播(执行日志中记录的修改逻辑),实现主从同步。业务数据不一致或者错了，用binlog恢复。

#### binlog和redolog的区别
1. redolog是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层服务层产生的。
2. 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，其记录是对应的SQL语句。而innodb存储引擎层面的重做日志是物理日志。
3. 两种日志与记录写入磁盘的时间点不同，binlog日志只在事务提交完成后进行一次写入。而innodb存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
4. binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redolog是循环使用。
5. binlog可以作为恢复数据使用，主从复制搭建，redolog作为异常宕机或者介质故障后的数据恢复使用。


### left join right join inner join
- left join（左联接）：返回左表中的所有记录以及和右表中的联接字段相等的记录。
- right join（右联接）：返回右表中的所有记录以及和左表中的联接字段相等的记录。
- inner join（等值联接）：只返回两个表中联接字段相等的记录。

### MySQl各种锁
[https://blog.csdn.net/Jack__Frost/article/details/73347688](https://blog.csdn.net/Jack__Frost/article/details/73347688)

## Redis

### Redis是什么
简单来说redis就是一个**数据库**，不过与传统数据库不同的是redis的数据库是存在**内存**中，所以**读写速度非常快**，因此redis被广泛应用于**缓存**方向。另外，redis也经常用来做**分布式锁**，redis提供了多种数据类型来支持不同的业务场景。除此之外，**redis 支持事务** 、**持久化**、**LUA脚本**、**LRU驱动事件**、**多种集群**方案。

### 为什么要用Redis？
1. 缓存
2. 共享Session
3. 消息队列系统
4. 分布式锁


### 单线程的Redis为什么这么快
1. 纯内存操作
2. 单线程操作，避免了**频繁的上下文切换**
3. 合理高效的数据结构
4. 采用了**非阻塞I/O多路复用**机制


### 为什么要用Redis而不用map/guava做缓存

- 缓存分为**本地缓存**和**分布式缓存**。以 Java 为例，使用自带的 **map 或者 guava 实现的是本地缓存**，最主要的特点是**轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。**

- 使用 **Redis 或 Memcached 之类的称为分布式缓存**，在多实例的情况下，各实例共用一份缓存数据，**缓存具有一致 性**。缺点是需要保持 **Redis 或 Memcached服务的高可用**，整个程序架构上较为复杂。


### Redis相比Memcached有哪些优势

1. 存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。
2. 数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，，而redis支持五种数据类型。
3. 用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
4. value的大小：redis可以达到1GB，而memcache只有1MB。

### Redis的线程模型
redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是**单线程**的，所以 redis 才叫做**单线程的模型**。它采用 **IO 多路复用机制**同时监听多个 socket，根据 socket 上的事件来**选择对应的事件处理器**进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会**并发产生不同的操作**，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的**事件放入队列中排队**，事件分派器每次从队列中取出一个事件，把该事件交给对应的**事件处理器**进行处理。

### Redis的LRU具体实现
- 传统的LRU是使用栈的形式，每次都将最新使用的移入栈顶，但是用栈的形式会导致执行select的时候大量非热点数据占领头部数据，所以需要改进。
- Redis每次按key获取一个值的时候，都会更新value中的lru字段为当前秒级别的时间戳。
- Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。
- 在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的key，lru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的（最近被访问）一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。

### Redis常见数据结构以及使用场景分析

#### String
String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key-value缓存应用； 常规计数：微博数，粉丝数等。

#### Hash
Hash 是一个 string 类型的 ﬁeld 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以Hash数据结构来存储用户信息，商品信息等等。

#### List
list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表， 消息列表等功能都可以用Redis的 list 结构来实现。

Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。

#### Set
set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。

当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在 一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常 方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：`sinterstore key1 key2 key3`将交集存在key1内


#### Zset
和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。

举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 SortedSet 结构进行存储。

### Redis设置过期时间
定期删除+惰性删除

- 定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
- 惰性删除 ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！

如果定期删除漏掉了很多过期 key，然后你也没及时去查， 也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？

**redis 内存淘汰机制。**

### Mysql有2000万数据，redis只存20万，如何保证redis中的数据都是热点数据
redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：

- volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
- volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
- allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
- no-enviction（驱逐）：禁止驱逐数据

### 持久化
#### RDB
**RDB**是一种**快照存储持久化**方式，具体就是将`Redis`某一时刻的内存数据保存到硬盘的文件当中，默认保存的文件名为`dump.rdb`，而在`Redis`服务器启动时，会重新加载`dump.rdb`文件的数据到内存当中恢复数据。

特点：
1. RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据
2. SAVE命令有服务器进程直接执行保存操作，所以该命令会阻塞服务器
3. BGSAVE命令由子进程执行保存操作，所有该命令不会阻塞服务器
4. RDB文件是一个经过压缩的二进制文件

![](https://static01.imgkr.com/temp/26e5e31351b44a0a8222014c3a6549de.png)

#### AOF（append-only file）
**AOF**：把所有的**对Redis的服务器进行修改的命令都存到一个文件里，命令的集合**。 使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 Redis默认是快照RDB的持久化方式。对于主从同步来说，主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

特点：
1. AOF文件通过保存所有修改数据库的写命令请求来记录服务器的数据库状态
2. 命令请求会先保存到AOF缓存区里面，之后再定期写入并同步到AOF文件
3. 在执行bg rewrite aof命令的时候，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。


![](https://static01.imgkr.com/temp/dd82cf8b9bba4a75900931618b07a75a.png)


### Redis的事务
MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务的基础。

事务可以一次执行多个命令， 并且带有以下两个重要的保证：
- 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
- 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。


#### 为什么 Redis 不支持回滚（roll back）
- Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。
- 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

### Redis的同步机制了解吗？
- 第一次同步时，**主节点做一次bgsave**，并同时将后续修改操作记录到**内存buffer**，待完成后**将rdb文件全量同步到复制节点**，复制节点接受完成后**将rdb镜像加载到内存**。
- 加载完成后，再通知主节点**将期间修改的操作记录同步到复制节点进行重放**就完成了同步过程。

### Redis的集群
- Redis Sentinel着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。

- Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

### 缓存穿透
一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量 请求而崩掉。

1. 在接口做校验
2. 存null值（缓存击穿加锁）
3. 布隆过滤器拦截： 将所有可能的查询key 先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，如果不存在，则直接返回。布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素在，可能会被误判。布隆过滤器说某个元素不在，那么一定不在。

### 缓存雪崩
缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

1. 使用 Redis 高可用架构：使用 Redis 集群来保证 Redis 服务不会挂掉
2. 缓存时间不一致，给缓存的失效时间，加上一个随机值，避免集体失效
3. 限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务

### 深究Redis的底层结构
#### 字符串SDS
- 获取字符串长度的复杂度为O(1)。
- 杜绝缓冲区溢出。
- 减少修改字符串长度时所需要的内存重分配次数。
- 二进制安全。
- 兼容部分C字符串函数。

#### 链表list
- 链表被广泛用于实现Redis的各种功能，比如列表建、发布与订阅、慢查询、监视器等。
- 每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis的链表实现是双端链表。
- 每个链表使用一个list结构表示，这个结构带有表头节点指针、表尾节点指针，以及链表长度等信息。
- 因为链表表头的前置节点和表尾节点的后置节点都指向NULL，所以Redis的链表实现是无环链表。
- 通过为链表设置不同的类型特定函数，Redis的链表可以用于保存各种不同类型的值。

#### 字典hash
- 字典被广泛用于实现Redis的各种功能，其中包括数据库和哈希键。
- Redis中的字典使用哈希表作为底层结构实现，每个字典带有两个哈希表，一个平时使用，另一个仅在进行rehash时使用。
- Redis使用MurmurHash2算法来计算键的哈希值。
- 哈希表使用链地址法来解决键冲突。

注意：这里和Java的HashMap不同的rehash过程
1. Redis的rehash过程是扩展和收缩，而且还是渐进式的rehash
2. Redis的字典有两个哈希表ht[0]和ht[1]
3. 为字典的ht[1]哈希表分配空间，如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used *2的2^n；如果执行的是收缩操作，那么ht[1]的大小第一个大于等于ht[0].used的2^n。（举个例子，ht[0]的长度为10，那么扩展就是2^5的32，如果是压缩的话2^4=16）
4. 如果ht[0]的键值非常多的话，一次性转移过去，是一个非常耗时的操作哦，因此并非一次性，采取渐进式rehash转移。

#### 跳跃表
- 跳跃表是有序集合的底层实现之一
- Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点
- 每个跳跃表节点的层高都是1至32之间的随机数
- 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。
- 跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。

---
![](https://imgkr.cn-bj.ufileos.com/70696936-10cd-43af-aa86-39dc6fdeda18.png)

![](https://imgkr.cn-bj.ufileos.com/932b42df-35a4-4e19-bf08-5200daeb3f38.png)

#### 压缩列表
一看名字，就是为了节省内存造的列表结构。压缩列表(ziplist)是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。

### Redis并发竞争key的解决方案
1. 分布式锁+时间戳
2. 利用消息队列

### Redis与MySQL双写一致性方案
先更新数据库，再删缓存。数据库的读操作的速度远快于写操作的，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。
[https://www.cnblogs.com/rjzheng/p/9041659.html](https://www.cnblogs.com/rjzheng/p/9041659.html)

### Redis分布式锁
- [Redis锁的实现](https://juejin.im/post/5cc165816fb9a03202221dd5#heading-4)
- [补充-Zookeeper锁的实现](https://juejin.im/post/5c01532ef265da61362232ed)

### Redis的管道pipeline
对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。在 sync() 方法执行操作，每次请求放在队列里面，解析响应包。

### 项目哪里用到
- 缓存，那肯定没得说，要说就说亮点。
- Redis绑定Token，达到SSO的目的。（SSO：用户只需要登录一次，就可以访问其他子服务，比如订单服务，支付服务等）
- Redis作为延迟队列
    1. 定时主动轮询Redis的延迟队列（底层原理）去修改场次状态变化（沙河->清水河四种状态）；这里可以提一下之前用的Spring定时器。（为什么用Redis的延迟队列，为什么不用Spring定时器），后面再说。
    2. 定时主动轮询Redis的延迟队列去修改自动取消订单业务；可以提一下之前用的Redis的key键过期事件（带上底层原理）。什么场景需要用Redis的延迟队列，什么场景需要用Redis的key过期事件。
- 幂等性：作为保证RocketMQ消费的幂等性的判断。
- 分布式锁：下订单的时候，要争抢座位。第二套：zookeeper

### Redis绑定Token
第一种情况：第一次登录

- 获取用户的账号和密码 
- 登录获取用户id
- 针对以userId生成token
- 以userId为key，value为token存进Redis中-将token返回给前端

第二种情况：前端token过期

说明：Redis存入token的有效期为1小时

- 判断前端是否携带token，若没有，直接返回给前端，请前端去登录；
- 若携带，则通过JWT解析出其中加密的信息，其实就是userId，带着userId去Redis中找是否存在该id，若不存在，说明已经过期了，直接返回给前端，请前端去登录；

第三种情况：前端token和Redis的token不一致

接着上面第二种情况
- 若存在，判断携带的Token是否和Redis中的token是否一致。
- 若不一致，说明其他终端正在登录该用户使用子业务，要么改密码，要么请前端重新去登录挤下去。
- 若一致，说明符合Redis中的token正好是该用户

> 可以聊聊ThreadLocal和Token的配合

#### 为什么用JWT？
1. HTTP协议是**无状态的**
2. Cookie是服务器发送到用户浏览器并保存在**本地的一小块数据**，数据不能太大，并且明文容易被盗取。
3. Session不能作为分布式系统，会出现session复制，影响效率。
4. Token是在服务端将用户信息经过Base64Url编码过后传给在客户端。每次用户请求的时候都会带上这一段信息，因此服务端拿到此信息进行解密后就知道此用户是谁了。
5. JWT三部分：header（什么算法）、payload（主题）和signature（对前两者加密）

### 延迟队列
#### 更新场次状态
##### Spring定时器
- 首先取出当天，其次取出开始时间或者结束时间符合当前时间
- 最后遍历所有符合当天场次，如果是0，则更改为2，如果是1，则更改为3，如果是2，则更改为1，如果是3，则更为0
- 要记得删除缓存每隔30分钟轮询

##### 使用Redis的延迟队列
- 在用定时器添加场次的时候，可以将这些场次存入Redis的zset的队列中，元素为场次ID，元素对应的score是出发时间，这样就有17个（定时器每天凌晨添加17个）
- 还是用定时器轮询，采用每隔半小时轮询一次，我们取出队列中当前时间大于队列中权重的时间的场次ID，开始进行业务逻辑判断（更改场次状态）
- 更改过后，如果是发车时间，则删除队列中的场次id和score，重新添加队列中场次的id和结束时间score，或者直接修改score
- 如果是结束时间，则删除队列中的场次id和score

#### 订单自动取消（无效订单）
##### Redis的key键过期事件
- 下单的时候，会在redis存该id的key
- 当该key过期的时候，Redis的监听事件会监听到该key，于是分析该key做相应的子业务
- 回退座位和更新订单状态

##### Redis的延迟队列
- 下单之后，将该id和订单过期时间存到Redis的Zset的数据结构，key为订单id，score为过期时间的时间戳
- 开启一个线程池或者Spring的定时器定时轮询该延迟队列，将当前时间大于score的，取出来
- 遍历去执行回退座位和更新订单状态

### 幂等性
> 我们知道，作为可靠消息的分布式事务场景，在消费者消费的时候要保证不能重复消费，也就是不能重复执行相应的业务逻辑，其实就是保证幂等性，那么可以采用Redis来保证。

- 题外话，这里可以借助数据库表，来保证，但是这里就要消耗MySQL的性能了，不断进行和磁盘交互，则为不妥。
- Redis的key为xx_场次id，过期时间随机5-10s，每次拿到消息进行判断Redis是否存在该key，如果存在，说明已经消费，避免重复消费，如果没有，则开始执行相应的业务逻辑，并写入Redis。

### 分布式锁
> 我们知道，我们在下订单的时候，需要判断座位是否存在，是吧？当然，不存在则进行绑定座位，但是，如果此时T1事务判断座位不重复，挂起了，T2也判断不重复，也挂起了，T1开始绑定座位，那么，T2也能绑定座位，这样就会出现两个订单同样的座位。因此，这里要用分布式锁，为什么不用JVM的？这是分布式系统哇，像Synchronized等同步锁，只存在JVM单个实例中，所以这里用两种方案：Redis和zookeeper

#### 分布式锁的条件
- 互斥性：在任意时刻，只有一个客户端能持有锁 其他尝试获取锁的客户端都将失败而返回或阻塞等待
- 健壮性：一个客户端持有锁的期间崩溃而没有主动释放锁，也需要保证后续其他客户端能够加锁成功
- 唯一性：加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给释放了，自己持有的锁也不能被其他客户端释放
- 高可用：不必依赖于全部Redis节点正常工作，只要大部分的Redis节点正常运行，客户端就可以进行加锁和解锁操作

#### Redis分布式锁的实现
> 毕竟判断和绑定座位（或者下单）非原子性，为了降低锁的粒度，可以将判断和绑定座位锁在一个事务里。集群：Redisson

- Key为xx_座位号，过期时间为随机1-5s（用setex的命令，该命令是key和过期时间是原子性的）
- 每次先Redis中判断该key存在不存在，如果存在，要么阻塞，要么就返回给用户，座位已被选择。
- 如果不存在，先上锁，然后再判断和绑定座位（或者下单）。其实这里有个隐藏的问题。如果绑定座位非常耗时，超过了过期时间1-5s，就凉凉了。其实这里设置过期时间，就是防止一直因为某种原因阻塞而不释放锁
- 前三步，少了个签证value，如果不设置，那么当锁过期了，业务逻辑才走完，准备删除的时候，B客户端获取到了该锁，但是A把B的key锁删除了，然而B还不知道。
- 因此，要解决这个问题，可以设置value签证，结束的时候判断一次，该value是不是自己的value，这样就不会误删。

#### RedLock算法流程

首先有这样的问题：
1. 客户端 A 从 Master 上获取锁。
2. 在锁未被复制到某 Slave 节点的时候，Master 节点 Down 掉了。
3. 某 Slave 节点成为新的 Master。
4. 客户端 B 可从新 Master 上获取锁。

假设有5个实例

1. 比如过期时间为TTL：10min
2. 记录当前时间：比如T1 = 12:00
3. 客户端分别向5个实例获取锁，比如申请锁的时间依次为：12:01...12:05,最后获取实例的锁为T2:12:05（获取锁的超时时间要远远小于过期时间，防止死等。）
4. 如果获取锁的实例大于3个（过半机制），那么就相当于获取到锁了，该锁的真正的有效时间为TTL-(T2-T1) = 5min
5. 如果客户端由于某些原因获取锁失败，便会开始解锁所有redis实例；因为可能已经获取了小于3个锁，必须释放，否则影响其他client获取锁



#### zookeeper分布式锁的实现
> 我们知道，zookeeper中有一个临时顺序节点，根据这一个特点，来实现分布式锁。每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

- 多个事务进来该方法，都会按照顺序生成临时节点，那么获取锁的时候，当前事务会获取一堆该节点的临时顺时节点，他就判断自己的临时节点是否是排在第一个，因为多个事务发起，都会按照顺序生成，比如1，2，3，4，5.
- 如果自己是第一个，那么就获取这把锁，如果自己不是第一个，那么他就会在他上一个顺序节点加把监听器，一旦上个节点不见了，就会通知自己获取这把锁。
- 走完业务逻辑，删除自己的临时节点即可。




# 计算机网络
## 网络模型

![分层模型](http://media.dreamcat.ink/uPic/分层模型.png)

### 简要概括

- 物理层：底层数据传输，如网线；网卡标准。 

- 数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。

- 网络层：定义IP编址，定义路由功能；如不同设备的数据转发。

- 传输层：端到端传输数据的基本功能；如 TCP、UDP。

- 会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。

- 标识层：数据格式标识，基本压缩加密功能。

- 应用层：各种应用软件，包括 Web 应用。

### 流程

比如，计算机 A 和 计算机 B 要进行信息交互，比如 A 上开发了一个网页，需要 B 去访问。B 发出一个请求给 A，那么请求数据从 B 的 **应用层开始向下传到表示层、再从表示层传到会话层直到物理层，通过物理层传递到 A，A 的物理层接到请求后将请求向上传递到自己的应用层，应用层再将要请求的数据向自己的物理层方向传递然后 B 接到数据传递数据到自己的应用层**。

说明：

- 在四层，既传输层数据被称作**段**（Segments）；
- 三层网络层数据被称做**包**（Packages）；
- 二层数据链路层时数据被称为**帧**（Frames）；
- 一层物理层时数据被称为**比特流**（Bits）。

### 常见的端口号和协议号

![协议端口号](http://media.dreamcat.ink/uPic/EuHz2s.png)

### 总结

- 网络七层模型是一个标准，而非实现。
- 网络四层模型是一个实现的应用模型。
- 网络四层模型由七层模型简化合并而来。

### ping命令基于哪一层协议的原理是什么？

ping命令基于网络层的命令，是基于ICMP协议工作的。

### ARP
ARP是一种解决地址问题的协议。以目标IP地址为线索，用来定位下一个应该接收数据分包的网络设备对应的MAC地址。
起初要通过广播发送一个ARP请求包，这个包里存放了其MAC地址的主机IP地址，由于广播的包可以被同一个链路上所有的主机或路由器接收，因此ARP的请求包也就会被这同一个链路上所有的主机和路由器进行解析。如果ARP请求包中的目标IP地址与自己的IP地址与自己的IP地址一直，那么这个节点就将自己的MAC地址塞入ARP响应包返回给主机A。


## DNS

### DNS是什么

**官方解释**：DNS（Domain Name System，域名系统），因特网上作为**域名和IP地址相互映射**的一个**分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。

**通俗的讲**，我们更习惯于记住一个网站的名字，比如www.baidu.com,而不是记住它的ip地址，比如：167.23.10.2。

### 谈谈DNS解析过程
![DNS解析过程](http://media.dreamcat.ink/uPic/DNS解析过程.png)

- 请求一旦发起，若是chrome浏览器，先在浏览器找之前**有没有缓存过的域名所对应的ip地址**，有的话，直接跳过dns解析了，若是没有，就会**找硬盘的hosts文件**，看看有没有，有的话，直接找到hosts文件里面的ip

[字节问了修改hosts，浏览器会变吗？](https://blog.csdn.net/woshizhangliang999/article/details/51457864)

- 如果本地的hosts文件没有能的到对应的ip地址，浏览器会发出一个**dns请求到本地dns服务器**，**本地dns服务器一般都是你的网络接入服务器商提供**，比如中国电信，中国移动等。
- 查询你输入的网址的DNS请求到达本地DNS服务器之后，**本地DNS服务器会首先查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归的方式进行查询**。如果没有，本地DNS服务器还要向**DNS根服务器**进行查询。
- 本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。
- 最后，本地DNS服务器向**域名的解析服务器**发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。

### DNS查询方式

#### 递归解析

当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式。**局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询**。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

#### 迭代解析

当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS服务器不是自己向其他DNS服务器进行查询，**而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序**，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：baidu.com的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。

### DNS负载均衡

当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会蹦掉。处理办法就是用DNS负载均衡技术，它的原理是在**DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器**,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

### 为什么域名解析用UDP协议？

因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手。但是UDP协议传输内容不能超过512字节。不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

### 为什么区域传送用TCP协议？

因为TCP协议可靠性好啊！你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512字节的UDP协议？万一同步的数据大于512字节，你怎么办？

## HTTP

### GET和POST的区别？

1. GET使用URL或Cookie传参，而POST将数据放在BODY中
2. GET方式提交的数据有长度限制，则POST的数据则可以非常大
3. POST比GET安全，因为数据在地址栏上不可见，没毛病
4. **本质区别**：GET请求是幂等性的，POST请求不是。

> 这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。

正因为它们有这样的区别，所以不应该且**不能用get请求做数据的增删改这些有副作用的操作**。因为get请求是幂等的，**在网络不好的隧道中会尝试重试**。如果用get请求增数据，会有**重复操作**的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

#### 1xx 信息

**100 Continue** ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

#### 2xx 成功

- **200 OK**
- **204 No Content** ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
- **206 Partial Content** ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

#### 3xx 重定向

- **301 Moved Permanently** ：永久性重定向
- **302 Found** ：临时性重定向
- **303 See Other** ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。
- **304 Not Modified** ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
- **307 Temporary Redirect** ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

#### 4xx 客户端错误

- **400 Bad Request** ：请求报文中存在语法错误。
- **401 Unauthorized** ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
- **403 Forbidden** ：请求被拒绝。
- **404 Not Found**：路由不存在，或者没找到

#### 5xx 服务器错误

- **500 Internal Server Error** ：服务器正在执行请求时发生错误。
- **503 Service Unavailable** ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

### HTTP首部

> 这块有点多，可参考[http首部](https://github.com/DreamCats/JavaBooks/blob/master/Interview/network/计算机网络原理-http那些事儿.md#http首部)

### Cookies

HTTP 协议是**无状态**的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。

Cookie 是**服务器发送到用户浏览器并保存在本地的一小块数据**，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。

用途

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

### Session

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

### Cookie和Session的选择

- Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
- Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

### JWT

JWT(json web token)是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。

cookie+session这种模式通常是保存在**内存**中，而且服务从单服务到多服务会面临的session共享问题，随着用户量的增多，开销就会越大。而JWT不是这样的，**只需要服务端生成token，客户端保存这个token，每次请求携带这个token，服务端认证解析就可**。

**JWT的构成**：

第一部分我们称它为头部（header),第二部分我们称其为载荷（payload)，第三部分是签证（signature)。详情请见[官网](https://jwt.io/introduction/)

**JWT总结**：

1. 因为json的通用性，所以JWT是可以进行跨语言支持的，像JAVA,JavaScript,NodeJS,PHP等很多语言都可以使用。
2. payload部分，JWT可以在自身存储一些其他业务逻辑所必要的非敏感信息。
3. 便于传输，jwt的构成非常简单，字节占用很小，所以它是非常便于传输的。它不需要在服务端保存会话信息, 所以它易于应用的扩展。

### 浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？

在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，**某些服务器对 Connection: keep-alive 的 Header 进行了支持**。

**持久连接**：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。


### 一个TCP连接可以对应几个HTTP请求？

如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

### 一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？

HTTP/1.1 存在一个问题，单个 TCP 连接在同一时刻只能处理一个请求，意思是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。

在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。

那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

- 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。
- 和服务器建立多个 TCP 连接。

### 为什么有的时候刷新页面不需要重新建立 SSL 连接？

TCP 连接有的时候会被浏览器和服务端维持一段时间。TCP 不需要重新建立，SSL 自然也会用之前的。

### 浏览器对同一 Host 建立 TCP 连接到数量有没有限制？

**有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。**


### 在浏览器中输入url地址后显示主页的过程?

> - 根据域名，进行DNS域名解析；
> - 拿到解析的IP地址，建立TCP连接；
> - 向IP地址，发送HTTP请求；
> - 服务器处理请求；
> - 返回响应结果；
> - 关闭TCP连接；
> - 浏览器解析HTML；
> - 浏览器布局渲染；

### HTTP1.x的缺点
1. HTTP/1.0 一次只允许在一个TCP连接上发起一个请求，HTTP/1.1使用的流水线技术也只能部分处理请求分析，仍然会存在队列头阻塞问题，因此客户端在需要发起多次请求时，通常会采用建立多连接来减少延迟
2. 单向请求，只能由客户端发起
3. 请求报文与响应报文首部信息冗余量大。
4. 数据未压缩，导致数据的传输量大。

### HTTP2.0有哪些改动
1. 多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。
2. 二进制分帧：应用层（HTTP/2）和传输层（TCP or UDP）之间增加一个二进制分帧层。
3. 首部压缩（Header Compression）
4. 服务端推送（Server Push）

## HTTPS

### HTTPS是什么

HTTPS 并不是新协议，而是让 **HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信**。通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

### HTTP的缺点

- 使用明文进行通信，内容可能会被窃听；
- 不验证通信方的身份，通信方的身份有可能遭遇伪装；
- 无法证明报文的完整性，报文有可能遭篡改。

### 对称密钥加密

对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。

- 优点：运算速度快
- 缺点：无法安全地将密钥传输给通信方

### 非对称密钥加密

非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。

公开密钥所有人都可以获得，**通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密**，**接收方收到通信内容后使用私有密钥解密**。

非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。

- 优点：可以更安全地将公开密钥传输给通信发送方；
- 缺点：运算速度慢。

### HTTPS采用的加密方式

HTTPS 采用混合的加密机制，使用**非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。

![rsa原理](http://media.dreamcat.ink/uPic/rsa原理.png)

确保传输安全过程（其实就是rsa原理）：

1. Client给出**协议版本号**、一个客户端生成的**随机数**（Client random），以及客户端支持的**加密方法**。
2. Server确认双方使用的**加密方法**，并给出**数字证书**、以及一个服务器生成的**随机数**（Server random）。
3. Client确认**数字证书有效**，然后生成一个新的**随机数**（Premaster secret），并使用**数字证书中的公钥，加密这个随机数**，发给Server。
4. Server使用自己的**私钥，获取Client发来的随机数**（Premaster secret）。
5. Client和Server根据约定的加密方法，使用前面的**三个随机数，生成”对话密钥”**（session key），用来加密接下来的整个对话过程。

### 认证

通过使用 **证书** 来对通信方进行认证。

数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。

服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

[加密全套流程](https://www.cnblogs.com/handsomeBoys/p/6556336.html)

[https://www.cnblogs.com/xdyixia/p/11610102.html](https://www.cnblogs.com/xdyixia/p/11610102.html)

### HTTPS的缺点

- 因为需要进行加密解密等过程，因此速度会更慢；
- 需要支付证书授权的高额费用。

## TCP/UDP

### TCP

#### TCP是什么？

`TCP（Transmission Control Protocol 传输控制协议）`是一种面向连接的、可靠的、基于字节流的传输层通信协议。

#### TCP头部报文

##### source port 和 destination port

> 两者分别为「源端口号」和「目的端口号」。源端口号就是指本地端口，目的端口就是远程端口。

可以这么理解，我们有很多软件，每个软件都对应一个端口，假如，你想和我数据交互，咱们得互相知道你我的端口号。

再来一个很官方的：

> 扩展：应用程序的端口号和应用程序所在主机的 IP 地址统称为 socket（套接字），IP:端口号, 在互联网上 socket 唯一标识每一个应用程序，源端口+源IP+目的端口+目的IP称为”套接字对“，一对套接字就是一个连接，一个客户端与服务器之间的连接。

##### Sequence Number

> 称为「序列号」。用于 TCP 通信过程中某一传输方向上字节流的每个字节的编号，为了确保数据通信的有序性，避免网络中乱序的问题。接收端根据这个编号进行确认，保证分割的数据段在原始数据包的位置。初始序列号由自己定，而后绪的序列号由对端的 ACK 决定：SN_x = ACK_y (x 的序列号 = y 发给 x 的 ACK)。

说白了，类似于身份证一样，而且还得发送此时此刻的所在的位置，就相当于身份证上的地址一样。

##### Acknowledge Number

> 称为「确认序列号」。确认序列号是接收确认端所期望收到的下一序列号。确认序号应当是上次已成功收到数据字节序号加1，只有当标志位中的 ACK 标志为 1 时该确认序列号的字段才有效。主要用来解决不丢包的问题。

##### TCP Flag

`TCP` 首部中有 6 个标志比特，它们中的多个可同时被设置为 `1`，主要是用于操控 `TCP` 的状态机的，依次为`URG，ACK，PSH，RST，SYN，FIN`。

当然只介绍三个：

1. **ACK**：这个标识可以理解为发送端发送数据到接收端，发送的时候 ACK 为 0，标识接收端还未应答，一旦接收端接收数据之后，就将 ACK 置为 1，发送端接收到之后，就知道了接收端已经接收了数据。
2. **SYN**：表示「同步序列号」，是 TCP 握手的发送的第一个数据包。用来建立 TCP 的连接。SYN 标志位和 ACK 标志位搭配使用，当连接请求的时候，SYN=1，ACK=0连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有 SYN 的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口。
3. **FIN**：表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的 TCP 数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。发送端只剩最后的一段数据了，同时要告诉接收端后边没有数据可以接受了，所以用FIN标识一下，接收端看到这个FIN之后，哦！这是接受的最后的数据，接受完就关闭了；**TCP四次分手必然问**。

##### Window size

> 称为滑动窗口大小。所说的滑动窗口，用来进行流量控制。

### TCP三次握手

![TCP三次握手](http://media.dreamcat.ink/uPic/TCP三次握手.svg)

- **初始状态**：客户端处于 `closed(关闭)`状态，服务器处于 `listen(监听)` 状态。
- **第一次握手**：客户端发送请求报文将 `SYN = 1`同步序列号和初始化序列号`seq = x`发送给服务端，发送完之后客户端处于`SYN_Send`状态。
- **第二次握手**：服务端收到 `SYN` 请求报文之后，如果同意连接，会以自己的同步序列号`SYN(服务端) = 1`、初始化序列号 `seq = y`和确认序列号（期望下次收到的数据包）`ack = x + 1` 以及确认号`ACK = 1`报文作为应答，服务器为`SYN_Receive`状态。（问题来了，两次握手之后，所以老哥，你需要给我三次握手来传个话告诉我一声。你要是不告诉我，万一我认为你跑了，然后我可能出于安全性的考虑继续给你发一次，看看你回不回我。）
- **第三次握手**： 客户端接收到服务端的 `SYN + ACK`之后，知道可以下次可以发送了下一序列的数据包了，然后发送同步序列号 `ack = y + 1`和数据包的序列号 `seq = x + 1`以及确认号`ACK = 1`确认包作为应答，客户端转为`established`状态。（分别站在双方的角度上思考，各自ok）

1. 你吃饭了嘛？（seq=x），收到请回答（SYN=1）
2. 收到（ACK=1），吃饭了（ack=x+1），你吃饭了吗？（seq=y），收到请回答（SYN=1）
3. 收到（ACK=1），吃饭了（ack=y+1），那么我们聊一下接下里的事情（established）

### TCP四次分手

![TCP四次分手](http://media.dreamcat.ink/uPic/TCP四次分手.png)

- **初始化状态**：客户端和服务端都在连接状态，接下来开始进行四次分手断开连接操作。
- **第一次分手**：第一次分手无论是客户端还是服务端都可以发起，因为 TCP 是全双工的。

> 假如客户端发送的数据已经发送完毕，发送FIN = 1 **告诉服务端，客户端所有数据已经全发完了**，**服务端你可以关闭接收了**，但是如果你们服务端有数据要发给客户端，客户端照样可以接收的。此时客户端处于FIN = 1等待服务端确认释放连接状态。

- **第二次分手**：服务端接收到客户端的释放请求连接之后，**知道客户端没有数据要发给自己了**，**然后服务端发送ACK = 1告诉客户端收到你发给我的信息**，此时服务端处于 CLOSE_WAIT 等待关闭状态。（服务端先回应给客户端一声，我知道了，但服务端的发送数据能力即将等待关闭，于是接下来第三次就来了。）
- **第三次分手**：此时服务端向客户端把所有的数据发送完了，然后发送一个FIN = 1，**用于告诉客户端，服务端的所有数据发送完毕**，**客户端你也可以关闭接收数据连接了**。此时服务端状态处于LAST_ACK状态，来等待确认客户端是否收到了自己的请求。（服务端等客户端回复是否收到呢，不收到的话，服务端不知道客户端是不是挂掉了还是咋回事呢）
- **第四次分手**：此时如果客户端收到了服务端发送完的信息之后，就发送ACK = 1，告诉服务端，客户端已经收到了你的信息。**有一个 2 MSL 的延迟等待**。

#### 为什么要有2MSL等待延迟？

对应这样一种情况，最后客户端发送的ACK = 1给服务端的**过程中丢失**了，服务端没收到，服务端怎么认为的？我已经发送完数据了，怎么客户端没回应我？是不是中途丢失了？然后服务端再次发起断开连接的请求，一个来回就是2MSL。

客户端给服务端发送的ACK = 1丢失，**服务端等待 1MSL没收到**，**然后重新发送消息需要1MSL**。如果再次接收到服务端的消息，则**重启2MSL计时器**，**发送确认请求**。客户端只需等待2MSL，如果没有再次收到服务端的消息，就说明服务端已经接收到自己确认消息；此时双方都关闭的连接，TCP 四次分手完毕

#### 为什么四次分手？

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

### TCP粘包

**TCP粘包**是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。


个人觉得：应用层的报文在以流的形式传输时，每一个报文的报头紧接着上一个报文的报文尾部，这就是所谓的“粘包”问题。

- 由TCP**连接复用**造成的粘包问题。
- 因为TCP默认会使用**Nagle算法**，此算法会导致粘包问题。
  - 只有上一个分组得到确认，才会发送下一个分组；
  - 收集多个小分组，在一个确认到来时一起发送。
- **数据包过大**造成的粘包问题。
- 流量控制，**拥塞控制**也可能导致粘包。
- **接收方不及时接收缓冲区的包，造成多个包接收**

**解决**：

1. **Nagle算法**问题导致的，需要结合应用场景适当关闭该算法
2. 尾部标记序列。通过特殊标识符表示数据包的边界，例如\n\r，\t，或者一些隐藏字符。
3. 头部标记分步接收。在TCP报文的头部加上表示数据长度。
4. 应用层发送数据时**定长**发送。

[https://blog.csdn.net/xp178171640/article/details/104746379/](https://blog.csdn.net/xp178171640/article/details/104746379/)

[https://blog.csdn.net/songchuwang1868/article/details/87707127](https://blog.csdn.net/songchuwang1868/article/details/87707127)

### TCP 协议如何保证可靠传输？

- **确认和重传**：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
- **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。
- **数据合理分片和排序**：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
- **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。
- **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

### TCP 利用滑动窗口实现流量控制的机制？

>  流量控制是为了控制发送方发送速率，保证接收方来得及接收。TCP 利用滑动窗口实现流量控制。

TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着**接收方还有多大的缓冲区可以用于接收数据**。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据。

> 例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

### TCP拥塞控制的机制以及算法？

> 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。

TCP 发送方要维持一个 **拥塞窗口(cwnd) 的状态变量**。拥塞控制窗口的大小**取决于网络的拥塞程度**，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。TCP的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

### TCP的长连接和短连接
[https://www.cnblogs.com/chinaops/p/9303041.html](https://www.cnblogs.com/chinaops/p/9303041.html)

### UDP

提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。

#### UDP的特点

- UDP是**无连接的**；
- UDP使用**尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
- UDP是**面向报文**的；
- UDP**没有拥塞控制**，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；
- UDP**支持一对一、一对多、多对一和多对多**的交互通信；
- UDP的**首部开销小**，只有8个字节，比TCP的20个字节的首部要短。

那么，再说一次TCP的特点：

- **TCP是面向连接的**。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；
- 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（**一对一**）；
- TCP**提供可靠交付的服务**。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
- TCP**提供全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
- **面向字节流**。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。



# 补充Mybatis

## MyBatis与Hibernate有哪些不同？

 1. Mybatis和hibernate不同，它不完全是一个ORM框架，因为**MyBatis需要程序员自己编写Sql语句**。
 2. Mybatis直接编写原生态sql，可以严格控制sql执行性能，**灵活度高**，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套sql映射文件，工作量大。
 3. Hibernate对象/关系映射能力强，**数据库无关性好**，对于关系模型要求高的软件，如果用hibernate开发可以**节省很多代码，提高效率**。

 ## Mybatis的一级、二级缓存

 - 一级缓存: 基于 **PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session**，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存。
 - 二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 **Mapper(Namespace)，并且可自定义存储源**，如 Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口(可用来保存对象的状态)；
 - 对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。

## #{}和${}的区别是什么？
 1. `#{}` 是预编译处理，`${}`是字符串替换。
 2. Mybatis在处理`#{}`时，会将sql中的`#{}`替换为?号，调用PreparedStatement的set方法来赋值；
 3. Mybatis在处理`${}`时，就是把`${}`替换成变量的值。
 4. 使用`#{}`可以有效的防止SQL注入，提高系统安全性。

## mybatis是如何防止SQL注入的？

 **sql注入**：

 **SQL注入**，大家都不陌生，是一种常见的攻击方式。**攻击者**在界面的表单信息或URL上输入一些奇怪的SQL片段（例如“or ‘1’=’1’”这样的语句），有可能入侵**参数检验不足**的应用程序。所以，在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性要求很高的应用中（比如银行软件），经常使用将**SQL语句**全部替换为**存储过程**这样的方式，来防止SQL注入。这当然是**一种很安全的方式**，但我们平时开发中，可能不需要这种死板的方式。

 **mybatis是如何做到防止sql注入的**

 MyBatis框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“**输入+输出**”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用#的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的：

 ```sql
 select id, username, password, role from user where username=? and password=?
 ```

 不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。

 [底层实现原理]MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。

 ```java
 // 安全，预编译
 String sql = "select id, username, password, role from user where id=?"; //执行sql前会预编译号该条语句
 PreparedStatement pstmt = conn.prepareStatement(sql); 
 pstmt.setString(1, id); 

 // 不安全
 String sql = "select id,username,password,role from user where id=" + id;
 //当id参数为"3;drop table user;"时，执行的sql语句如下:
 //select id,username,password,role from user where id=3; drop table user;  
 PreparedStatement pstmt =  conn.prepareStatement(sql);
 ```

 **结论**：

 **\#{}**：相当于JDBC中的PreparedStatement

 **${}**：是输出变量的值

 简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。


# Dubbo
## 集群、分布式和微服务的概念
微服务是一种架构风格，一个大型复杂软件应用由**一个或多个微服务组成**。系统中的**各个微服务可被独立部署，各个微服务之间是松耦合的**。**每个微服务仅关注于完成一件任务并很好地完成该任务**。在所有情况下，每个任务代表着一个小的业务能力。

- 分布式将一个大的系统划分为多个业务模块，**业务模块分别部署到不同的机器上**，各个业务模块之间通过接口进行数据交互。区别**分布式的方式是根据不同机器不同业务**。
- 集群模式是不**同服务器部署同一套服务对外访问，实现服务的负载均衡**。区别集群的方式是根据部署多台服务器业务是否相同。
- 微服务的设计是为了不因为某个模块的升级和BUG影响现有的系统业务。微服务与分布式的细微差别是，**微服务的应用不一定是分散在多个服务器上，他也可以是同一个服务器**。

## 什么是RPC？
RPC（RemoteProcedureCall）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务A、B部署在两台不同的机器上，那么服务A如果想要调用服务B中的某个方法该怎么办呢？使用HTTP请求当然可以，但是可能会比较慢而且一些优化做的并不好。RPC的出现就是为了解决这个问题。
gRPC
[https://blog.csdn.net/fly910905/article/details/104130202](https://blog.csdn.net/fly910905/article/details/104130202)


## 为什么要用分布式?
从开发角度来讲**单体应用的代码都集中在一起**，而**分布式系统的代码根据业务被拆分**。所以，每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加便于维护和扩展。-系统拆分成分布式之后不光便于系统扩展和维护，更能提高整个系统的性能。把整个系统拆分成不同的服务/系统，然后每个服务/系统单独部署在一台服务器上，是不是很大程度上提高了系统性能呢？

## Dubbo是什么？

Dubbo是一款**高性能**、**轻量级**的开源JavaRPC框架，它提供了三大核心能力：**面向接口的远程方法调用**，**智能容错和负载均衡**，以及**服务自动注册和发现**。简单来说Dubbo是一个**分布式服务框架**，致力于提供**高性能和透明化的RPC远程服务调用方案**，以及**SOA服务治理方案。**

- **负载均衡**——同一个服务部署在不同的机器时该调用那一台机器上的服务。
- **服务调用链路生成**——随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo可以为我们解决服务之间互相是如何调用的。
- **服务访问压力以及时长统计、资源调度和治理**——基于访问压力实时管理集群容量，提高集群利用率。
- **服务降级**——某个服务挂掉之后调用备用服务。另外，Dubbo除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于SpringCloud在微服务中应用更加广泛，所以，我觉得一般我们提Dubbo的话，大部分是分布式系统的情况。

## Dubbo的图解？
![dubbo架构图解](http://media.dreamcat.ink/uPic/dubbo架构图解.png)

- **Provider：**暴露服务的服务提供方
- **Consumer：**调用远程服务的服务消费方
- **Registry：**服务注册与发现的注册中心
- **Monitor：**统计服务的调用次数和调用时间的监控中心
- **Container：**服务运行容器

**调用关系说明**：

- 服务容器负责启动，加载，运行服务提供者。
- 服务提供者在启动时，向注册中心注册自己提供的服务。
- 服务消费者在启动时，向注册中心订阅自己所需的服务。
- 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
- 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
- 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。

**各个组件总结**：

- **注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小**
- **监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示**
- **注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外**
- **注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者**
- **注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表**
- **注册中心和监控中心都是可选的，服务消费者可以直连服务提供者**
- **服务提供者无状态，任意一台宕掉后，不影响使用**
- **服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复**

## Dubbo和SpringCloud的区别？
- **底层**：`Dubbo`底层是使用Netty的NIO框架，基于TCP协议传输，使用Hession序列化完成RPC通信；`SpringCloud`是基于HTTP协议+REST接口调用远程过程的通信，HTTP请求会有更大的报文，占的带宽也会更多。但是REST相比RPC更为灵活，不存在代码级别的强依赖。
- **集成**：springcloud相关组件多，有自己的注册中心网关等，集成方便，Dubbo需要自己额外去集成。-**定位**：Dubbo是SOA时代的产物，它的关注点主要在于**服务的调用，流量分发、流量监控和熔断**。而SpringCloud诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了Spirng、SpringBoot的优势之上，两个框架在开始目标就不一致，Dubbo定位服务治理、SpirngCloud是一个生态。因此可以大胆地判断，Dubbo未来会在服务治理方面更为出色，而SpringCloud在微服务治理上面无人能敌。

## Dubbo的容错机制
1. 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数
2. 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
3. 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。
4. 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
5. 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
6. 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息

## Dubbo的限流是怎么实现的？
Dubbo默认时候的是**令牌桶**算法实现限流。在某段时间内，桶里面只能放n个令牌，然后来一个请求就减少一个令牌，如果桶内的令牌没有了，则不能继续执行请求。

限流主要是通过TPSLimitFilter实现。

## 常见的限流算法有哪些？
- 计数算法
- 滑动窗口，解决计数算法同一时刻进入很多请求
- 令牌桶算法
- 漏桶算法

## 什么是dubbo服务降级？
- dubbo在服务调用时，可能由于服务器宕机、网络超时、并发数太高等，导致调用失败。**服务降级**就是指在非业务异常导致的服务不可用时，可以返回默认值，避免影响主业务的处理。
- dubbo可以通过mock配置实现服务降级。

## Dubbo的注册中心挂了，还可以继续通信吗？
可以。因为在开始初试化的时候，消费者会将提供者的地址等信息拉取到**本地缓存**中。

## 负载均衡
个人理解：
> 比如我们的系统中的某个服务的**访问量特别大**，我们将这个服务部署在了**多台服务器**上，当客户端发起请求的时候，**多台服务器都可以处理这个请求**。那么，如何正确选择处理该请求的服务器就很关键。假如，你就要一台服务器来处理该服务的请求，那该服务部署在多台服务器的意义就不复存在了。负载均衡就是为了避免单个服务器响应同一请求，容易造成服务器宕机、崩溃等问题，我们从负载均衡的这四个字就能明显感受到它的意义。

1. RandomLoadBalance:随机负载均衡。随机的选择一个。是Dubbo的默认负载均衡策略。
2. RoundRobinLoadBalance:轮询负载均衡。轮询选择一个。
3. LeastActiveLoadBalance:最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。
4. ConsistentHashLoadBalance:一致性哈希负载均衡。相同参数的请求总是落在同一台机器上。

[http://dubbo.apache.org/zh-cn/blog/dubbo-loadbalance.html](http://dubbo.apache.org/zh-cn/blog/dubbo-loadbalance.html)

## 为什么使用zk当dubbo的注册中心
Zookeeper的数据模型很简单，有一系列被称为ZNode的数据节点组成，与传统的磁盘文件系统不同的是，zk将全量数据存储在内存中，可谓是高性能，而且支持集群，可谓高可用，另外支持事件监听。这些特点决定了zk特别适合作为注册中心(数据发布/订阅)。不过要注意网络闪断引发的节点摘除问题。

## 几个服务注册与发现的对比
[https://zhuanlan.zhihu.com/p/145296163](https://zhuanlan.zhihu.com/p/145296163)


## SPI源码(过程)
先说一下Java的SPI机制
Java的SPI机制利用ServiceLoader的load方法传递个接口，就会得到该接口的所有的实现类
要在指定的META-INF的services下
但是有一说一，只能通过iterator来遍历判断想要的实现类
而Dubbo和Spring的SPI比Java的灵活一些，可以通过key来获取对用的实例

直接说Dubbo的SPI源码过程
先说一下Dubbo的SPI机制，不仅支持有着Java的SPI，还有着AOP的功能，包装了一下，同时有着DI功能，依赖注入
1. 通过getExtensionLoader得到该接口的load，不过获取之间会对一些type检查，同时有缓存机制。
2. 然后通过load调用getExtension，也是一系列检查和缓存，最关键的就是createExtension
3. 其中getExtensionClasses，这个方法返回对应name的接口的实例对象，接着来到injectExtension注入属性
4. 如果有wrapper包装，就是通过接口的实例类有木有构造器，如果有，最后injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));无限遍历AOP，也就是构造器注入，最后返回带包装的接口的实例对象。
5. 以上是没有讲依赖注入的过程，官网上有。

## 服务导出与暴漏(源码流程)
源码省略，针对于面试就说源码流程即可
总结一波吧：
1. 当我们看源码知道，导出和暴漏在IoC初始化的最后一步的finishRefresh中的ServiceBean中。
2. 其中在onApplicationEvent执行export->doExport，在doExport中首先检查provider呀，register呀，monitor呀等，最后来到关键的一步doExportUrls();
3. 在这一步当中，实际上，就是对注册的url和导出的url拼接，并且将导出的url远程注册到注册中心，最后暴漏一下自己的url，具体的话就第四步。
4. doExportUrlsFor1Protocol其中就是刚才第三步说的那一些，然后后面的逻辑就是exportLocal，默认本地导出，关键是远程导出：proxyFactory.getInvoker，然后得到wrapperInvoker，最后就是这个关键了protocol.export(wrapperInvoker)，然后会有个子流程去构造buildInvokerChain，调用链。这个是服务调用链路
5. 实际上找Protocol.class接口的实例代理类，默认是dubbo协议，因此调用的dubbo的实例代理类的export方法，继续使用dubbo协议的url，一步一步绑定nettyClient客户端，最后导出自己的调用链。


## 服务引入与目录(源码过程)

肯定是ReferenceBean

1. 当我们看源码知道，首先进来的ReferenceBean的get方法->ReferenceConfig的init方法内部
2. checkDefault检查消费端的全局配置，接着通过SPI获取消费服务的实现类，经过一些列检查又进入了HashMap的缓存当中
3. init方法中的最后一步createProxy中，这个方法就是将要引入订阅注册中心的服务端的目录，首先是refprotocol.refer方法从注册中心引入和订阅，该方法是核心。
4. 首先通过RegistryProtocol的refer中，如果是zk协议，那么就启动zk客户端去连接，接着进入doRefer方法中，先在注册中心，注册消费端服务，接着开始通过subscribe订阅注册中心的目录，category、providers、configurators和routers，然后进入notify，调用listener.notify(categoryList)，通知categoryList
5. 这时候来到了协议Dubbo的refer中，开始构造路由链，首先buildInvokerChain调用链，Dubbo启动的是netty客户端哦，debug时候看出来的，获取的是netty的client，最后构建成功就返回。
6. 最后将所有的目录添加到cluster中，并返回invoker，其实该invoker是MockClusterInvoker，ref是它的代理实现类最后初始化完毕。

总感觉处处invoker(执行)类似于发送请求一样。

## 服务调用、服务降级和集群容错
先说一下invorker，在服务引入那里最终返回的是MockClusterInvoker的代理实现类，意思就是说，首先进入Java的动态代理，InvokerInvocationHandler，然后调用invork，进入MockClusterInvoker，然后调用invoke进入默认的FailoverClusterInvoker的invoker。每个invoker就是InvokerDelegate委托实现类
1. 根据我上面说的，其实从服务目录获取所有的提供者Invokers，在经过MockClusterInvoker的时候，如果配置了服务降级，服务降级就是通过mock机制而已，那么如果调用失败，先走Mock的服务降级策略，如果没有配置，然后开始初始化负载均衡策略，
2. 就进入了容错策略的Invoker类，然后通过负载均衡选择一个invoker，开始调用过滤链，最后才会执行我们的Dubbo协议上的客户端，应该是netty吧，去执行invoker
3. 服务那边开始被触发事件之后，也会执行自己的过滤链，然后最后执行自己的InvokerDelegate服务实现委托类，将结果先返回给自己，然后在通过负责处理请求的控制器传给消费端。
4. 以上是一次调用过程粗略的经过。


# RocketMQ
> 项目用到了它来保证事务的最终一致性，当然，也得知道消息队列其他应用场景。

![](https://static01.imgkr.com/temp/c93d0564a0724be98a995757c40ddb15.png)

结合项目分析该分布式事务消息的原理：
> 项目是怎么用的？举个例子，1. 下单的时候，通知绑定座位 2. 支付，通知扣钱 3. 退款


想了想，mq也可以
1. 先给Brock发送一条消息：我要下单了，注意哈
2. Brock给本地事务回馈消息：ack，好的，我知道了（半投递状态，消费端看不到）
3. 本地事务开始执行业务逻辑，这里首先（校验场次id的座位是否重复，如果没有，直接执行下单：这两个业务非原子，上个锁，要不然可能会出现同样的座位）。下单成功，则返回commit给Brock。消费者此时就可以看到这条消息了。
4. 如果下单不成功，则返回rollback，Brock一般三天自动删除该无效的消息，消费者也看不到。
5. 消费者看到了这条消息，调用绑定座位服务，如果失败了，则重试。（消费端不能失败，要不然不能保持一致，如果还是一直失败，则人工处理。） 注意：幂等性


支付，通知扣钱，更改状态

1. 先给Brock发送一条消息：我要扣钱了，注意哈
2. Brock给本地事务回馈消息：ack，好的，我知道了（半投递状态，消费端看不到）
3. 本地事务校验参数问题，执行commit给Brock
4. 用户服务执行扣钱服务，订单服务执行更改订单状态服务，注意幂等

退款：省略

## CAP
- C(一致性):对某个指定的客户端来说，读操作能返回最新的写操作。对于数据分布在不同节点上的数据上来说，如果在某个节点更新了数据，那么在其他节点如果都能读取到这个最新的数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。
- A(可用性)：非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。合理的时间指的是请求不能无限被阻塞，应该在合理的时间给出返回。合理的响应指的是系统应该明确返回结果并且结果是正确的，这里的正确指的是比如应该返回50，而不是返回40。
- P(分区容错性):当出现网络分区后，系统能够继续工作。打个比方，这里个集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。

- CP：对于CP来说，放弃可用性，追求一致性和分区容错性，我们的zookeeper其实就是追求的强一致。
- AP：对于AP来说，放弃一致性(这里说的一致性是强一致性)，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的BASE也是根据AP来扩展。

## BASE
BASE是BasicallyAvailable(基本可用)、Softstate(软状态)和Eventuallyconsistent(最终一致性)三个短语的缩写。是对CAP中AP的一个扩展-基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。
- 软状态:允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是CAP中的不一致。
- 最终一致:**最终一致是指经过一段时间后，所有节点数据都将会达到一致**。BASE解决了CAP中理论没有网络延迟，在BASE中用软状态和最终一致，保证了延迟后的一致性。BASE和ACID是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。

## 2PC
![](https://img2018.cnblogs.com/blog/1090617/201907/1090617-20190710222443794-591603727.jpg)

---
第一阶段：
- 协调者 向所有的 参与者 发送事务预处理请求，称之为Prepare，并开始等待各 参与者 的响应。
- 各个 参与者 节点执行本地事务操作,但在执行完成后并不会真正提交数据库本地事务，而是先向 协调者 报告说：“我这边可以处理了/我这边不能处理”。.
- 如果 参与者 成功执行了事务操作,那么就反馈给协调者 Yes 响应,表示事务可以执行,如果没有 参与者 成功执行事务,那么就反馈给协调者 No 响应,表示事务不可以执行。

图就不放了，很简单
第二阶段：成功
-  协调者 向 所有参与者 节点发出Commit请求.
-  参与者 收到Commit请求之后,就会正式执行本地事务Commit操作,并在完成提交之后释放整个事务执行期间占用的事务资源。

第二阶段：失败
任何一个 参与者 向 协调者 反馈了 No 响应,或者等待超时之后,协调者尚未收到所有参与者的反馈响应。
- 协调者 向所有参与者节点发出 RoollBack 请求.
- 参与者 接收到RoollBack请求后,会回滚本地事务。

缺点：
- 性能问题：无论是在第一阶段的过程中,还是在第二阶段,所有的参与者资源和协调者资源都是被锁住的,只有当所有节点准备完毕，事务 协调者 才会通知进行全局提交，参与者 进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。
- 单节点故障：由于协调者的重要性，一旦 协调者 发生故障。参与者 会一直阻塞下去。尤其在第二阶段，协调者 发生故障，那么所有的 参与者 还都处于锁定事务资源的状态中，而无法继续完成事务操作。（虽然协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

2PC出现单点问题的三种情况：
- 协调者正常,参与者宕机：由于 协调者 无法收集到所有 参与者 的反馈，会陷入阻塞情况。解决方案:引入超时机制,如果协调者在超过指定的时间还没有收到参与者的反馈,事务就失败,向所有节点发送终止事务请求。
- 协调者宕机,参与者正常：无论处于哪个阶段，由于协调者宕机，无法发送提交请求，所有处于执行了操作但是未提交状态的参与者都会陷入阻塞情况.解决方案:引入协调者备份,同时协调者需记录操作日志.当检测到协调者宕机一段时间后，协调者备份取代协调者，并读取操作日志，向所有参与者询问状态。
- 协调者和参与者都宕机


## 3PC
对2pc的优化

- 引入超时机制
- 在第一阶段和第二阶段中插入一个准备阶段，尝试获取数据库锁。如果可以就yes

## TCC
Try-Confirm-Cancel
- 先是服务调用链路依次执行 Try 逻辑。
- 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。
- 如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。

这就是所谓的 TCC 分布式事务。TCC 分布式事务的核心思想，说白了，就是当遇到下面这些情况时：
- 某个服务的数据库宕机了。
- 某个服务自己挂了。
- 那个服务的 Redis、Elasticsearch、MQ 等基础设施故障了。
- 某些资源不足了，比如说库存不够这些。


先来 Try 一下，不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结我需要的资源。

如果 Try 都 OK，也就是说，底层的数据库、Redis、Elasticsearch、MQ 都是可以写入数据的，并且你保留好了需要使用的一些资源（比如冻结了一部分库存）。

接着，再执行各个服务的 Confirm 逻辑，基本上 Confirm 就可以很大概率保证一个分布式事务的完成了。

那如果 Try 阶段某个服务就失败了，比如说底层的数据库挂了，或者 Redis 挂了，等等。

此时就自动执行各个服务的 Cancel 逻辑，把之前的 Try 逻辑都回滚，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。

等一等，你有没有想到一个问题？如果有一些意外的情况发生了，比如说订单服务突然挂了，然后再次重启，TCC 分布式事务框架是如何保证之前没执行完的分布式事务继续执行的呢？

所以，TCC 事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。

问题还没完，万一某个服务的 Cancel 或者 Confirm 逻辑执行一直失败怎么办呢？

那也很简单，TCC 事务框架会通过活动日志记录各个服务的状态。举个例子，比如发现某个服务的 Cancel 或者 Confirm 一直没成功，会不停的重试调用它的 Cancel 或者 Confirm 逻辑，务必要它成功！

当然了，如果你的代码没有写什么 Bug，有充足的测试，而且 Try 阶段都基本尝试了一下，那么其实一般 Confirm、Cancel 都是可以成功的！

## 可靠消息最终一致性
在上面的通用方案设计里，完全依赖可靠消息服务的各种自检机制来确保：

- 如果上游服务的数据库操作没成功，下游服务是不会收到任何通知。
- 如果上游服务的数据库操作成功了，**可靠消息服务死活都会确保将一个调用消息投递给下游服务，而且一定会确保下游服务务必成功处理这条消息**。

通过这套机制，保证了基于 MQ 的异步调用/通知的服务间的分布式事务保障。其实阿里开源的 RocketMQ，就实现了可靠消息服务的所有功能，核心思想跟上面类似。

## 为什么选择RocketMQ作消息队列
- ActiveMQ 的社区算是比较成熟，但是较目前来说，**ActiveMQ 的性能比较差，而且版本迭代很慢**，不推荐使用。
- RabbitMQ 在**吞吐量方面虽然稍逊于 Kafka 和 RocketMQ** ，但是由于它基于 erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 erlang 开发，所以国内很少有公司有实力做erlang源码级别的研究和定制。如果**业务场景对并发量要求不是太高（十万级、百万级），那这四种消息队列中，RabbitMQ 一定是你的首选**。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。
- RocketMQ 阿里出品，**Java 系开源项目**，源代码我们可以直接阅读，然后可以**定制自己公司的MQ**，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。其次具有分布式事务消息的功能，可以达到消息的最终一致性。
- kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。**kafka 唯一的一点劣势是有可能消息重复消费**，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。

## RocketMQ组件
- Producer:消息发布的角色，主要负责把消息发送到Broker，支持分布式集群方式部署。
- Consumer:消息消费者的角色，主要负责从Broker订阅消息消费，支持分布式集群方式部署。
- Broker:消息存储的角色，主要负责消息的存储、投递和查询，以及服务高可用的保证，支持分布式集群方式部署。
- NameServer:是一个非常简单的Topic路由注册中心，其角色类似于Dubbo中依赖的Zookeeper，支持Broker动态注册和发现。
    - 服务注册：NameServer接收Broker集群注册的信息，保存下来作为路由信息的基本数据，并提供心跳检测检测机制，检查Broker是否存活。
    - 路由信息管理：NameServer保存了Broker集群的路由信息，用于提供给客户端查询Broker的队列信息。Producer和Consumer通过NameServer可以知道Broker集群的理由信息，从而进行消息的投递和消费。

## MQ在高并发情况下，假设队列满了如何防止消息丢失？
- 生产者可以采用重试机制。因为消费者会不停的消费消息，可以重试将消息放入队列。
- 死信队列，可以理解为备胎(推荐)
   - 即在消息过期，队列满了，消息被拒绝的时候，都可以扔给死信队列。
   - 如果出现死信队列和普通队列都满的情况，此时考虑消费者消费能力不足，可以对消费者开多线程进行处理。

## 谈谈死信队列
**死信队列用于处理无法被正常消费的消息，即死信消息**。

当一条消息初次消费失败，**消息队列 RocketMQ 版会自动进行消息重试**；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 版不会立刻将消息丢弃，而是将其发送到该**消费者对应的特殊队列中**，该特殊队列称为**死信队列**。

**死信消息的特点**：

- 不会再被消费者正常消费。
- 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。

**死信队列的特点**：

- 一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。
- 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 版不会为其创建相应的死信队列。
- 一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。

消息队列 RocketMQ 版控制台提供对死信消息的查询、导出和重发的功能。

## 使用异步消息时如何保证数据的一致性

- **借助数据库的事务**：这需要在数据库中创建一个**本地消息表**，这样可以通过**一个事务来控制本地业务逻辑更新**和**本地消息表的写入在同一个事务中**，一旦消息落库失败，则直接全部回滚。如果消息落库成功，后续就可以根据情况基于本地数据库中的消息数据对消息进行重投了。关于本地消息表和消息队列中状态如何保持一致，可以采用 2PC 的方式。在发消息之前落库，然后发消息，在得到同步结果或者消息回调的时候更新本地数据库表中消息状态。然后只需要通过**定时轮询**的方式对状态未已记录但是未发送的消息重新投递就行了。但是这种方案有个前提，就是要求消息的消费者**做好幂等控制**，这个其实异步消息的消费者一般都需要考虑的。
- 除了使用数据库以外，还可以使用 **Redis** 等缓存。这样就是无法利用关系型数据库自带的事务回滚了。

## RockMQ不适用Zookeeper作为注册中心的原因，以及自制的NameServer优缺点？
- ZooKeeper 作为支持**顺序一致性**的中间件，在某些情况下，它为了满足一致性，会丢失一定时间内的**可用性**，RocketMQ 需要注册中心只是为了**发现组件地址**，在某些情况下，RocketMQ 的注册中心可以出现数据不一致性，这同时也是 **NameServer 的缺点，因为 NameServer 集群间互不通信，它们之间的注册信息可能会不一致**。
- 另外，当有新的服务器加入时，**NameServer 并不会立马通知到 Produer**，而是由 **Produer 定时去请求 NameServer 获取最新的 Broker/Consumer 信息**（这种情况是通过 Producer 发送消息时，负载均衡解决）
- 包括组件通信间使用 Netty 的自定义协议
- 消息重试负载均衡策略（具体参考 Dubbo 负载均衡策略）
- 消息过滤器（Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤）
- Broker 同步双写和异步双写中 Master 和 Slave 的交互


## 实现延迟队列
rocketmq发送延时消息时先把消息按照延迟时间段发送到指定的队列中(rocketmq把每种延迟时间段的消息都存放到同一个队列中)然后通过一个定时器进行轮训这些队列，查看消息是否到期，如果到期就把这个消息发送到指定topic的队列中，这样的好处是同一队列中的消息延时时间是一致的，还有一个好处是这个队列中的消息时按照消息到期时间进行递增排序的，说的简单直白就是队列中消息越靠前的到期时间越早

缺点：定时器采用了timer，timer是单线程运行，如果延迟消息数量很大的情况下，可能单线程处理不过来，造成消息到期后也没有发送出去的情况

改进点：可以在每个延迟队列上各采用一个timer，或者使用timer进行扫描，加一个线程池对消息进行处理，这样可以提供效率


## 消息队列如何保证顺序消费
生产者中把 orderId 进行取模，把相同模的数据放到 messagequeue 里面，消费者消费同一个 messagequeue，只要消费者这边有序消费，那么可以保证数据被顺序消费。

RocketMQ：顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费。并并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列，在Broker端会存储消息消费队列的锁占用情况。
[https://blog.csdn.net/AAA821/article/details/86650471](https://blog.csdn.net/AAA821/article/details/86650471)

## 消息存储
### 存储过程
1. 消息生产者发送消息
2. MQ收到消息，将消息进行持久化，在存储中新增一条记录
3. 返回ACK给生产者
4. MQ push 消息给对应的消费者，然后等待消费者返回ACK
5. 如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤
6. MQ删除消息

想说一点，activeMQ的存储介质DB，这就影响了存储效率，其他几位MQ采用的文件系统，并且依照顺序写，极大跟随了SSD的步伐。

### 零拷贝
都知道内核和用户态了，不必多说了
1. 从磁盘复制数据到内核态内存；
2. 从内核态内存复制到用户态内存；
3. 然后从用户态内存复制到网络驱动的内核态内存；
4. 最后是从网络驱动的内核态内存复制到网卡中进行传输。

但，通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的(零拷贝)

### 存储结构
RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。

- CommitLog：存储消息的元数据
- ConsumerQueue：存储消息在CommitLog的索引
- IndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程

## 刷盘机制
**同步机制**：在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。
1. 封装刷盘请求
2. 提交刷盘请求
3. 线程阻塞5秒，等待刷盘结束

服务那边：
1. 加锁
2. 遍历requestsRead
3. 刷盘
4. 唤醒发送消息客户端
5. 更新刷盘监测点


**异步机制**：在返回写成功状态时，消息**可能**只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。

在消息追加到内存后，立即返回给消息发送端。如果开启transientStorePoolEnable，RocketMQ会单独申请一个与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存将使用内存锁定，确保不会被置换到虚拟内存中去，消息首先追加到堆外内存，然后提交到物理文件的内存映射中，然后刷写到磁盘。如果未开启transientStorePoolEnable，消息直接追加到物理文件直接映射文件中，然后刷写到磁盘中。

开启transientStorePoolEnable后异步刷盘步骤:

1. 将消息直接追加到ByteBuffer（堆外内存）
2. CommitRealTimeService线程每隔200ms将ByteBuffer新追加内容提交到MappedByteBuffer中
3. MappedByteBuffer在内存中追加提交的内容，wrotePosition指针向后移动
4. commit操作成功返回，将committedPosition位置恢复
5. FlushRealTimeService线程默认每500ms将MappedByteBuffer中新追加的内存刷写到磁盘

## NameServer启动流程
1. 解析配置文件，填充NameServerConfig、NettyServerConfig属性值，并创建NamesrvController
2. 根据启动属性创建NamesrvController实例，并初始化该实例。NameServerController实例为NameServer核心控制器
    1. 创建NettyServer网络处理对象
    2. 开启定时任务:每隔10s扫描一次Broker,移除不活跃的Broker
    3. 开启定时任务:每隔10min打印一次KV配置
3. 在JVM进程关闭之前，先将线程池关闭，及时释放资源

## 路由管理
### 心跳机制
- RocketMQ路由注册是通过Broker与NameServer的心跳功能实现的。
- Broker启动时向集群中所有的NameServer发送心跳信息，每隔30s向集群中所有NameServer发送心跳包，NameServer收到心跳包时会更新brokerLiveTable缓存中BrokerLiveInfo的lastUpdataTimeStamp信息，然后NameServer每隔10s扫描brokerLiveTable，如果连续120S没有收到心跳包，NameServer将移除Broker的路由信息同时关闭Socket连接。

### 删除路由
- `Broker`每隔30s向`NameServer`发送一个心跳包，心跳包包含`BrokerId`，`Broker`地址，`Broker`名称，`Broker`所属集群名称、`Broker`关联的`FilterServer`列表。但是如果`Broker`宕机，`NameServer`无法收到心跳包，此时`NameServer`如何来剔除这些失效的`Broker`呢？
- `NameServer`会每隔10s扫描`brokerLiveTable`状态表，如果`BrokerLive`的**lastUpdateTimestamp**的时间戳距当前时间超过120s，则认为`Broker`失效，移除该`Broker`，关闭与`Broker`连接，同时更新`topicQueueTable`、`brokerAddrTable`、`brokerLiveTable`、`filterServerTable`。

### 路由发现
RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取主题最新的路由。

其实就是一张图
![](https://imgkr.cn-bj.ufileos.com/6ac077ee-bc03-4785-9200-426457563858.png)

## 消息发送流程
1. 验证消息
2. 查找路由
    1. 从缓存中获得主题的路由信息
    2. 路由信息为空,则从NameServer获取路由
    3. 如果未找到当前主题的路由信息,则用默认主题继续查找
3. 选择队列(默认不启用Broker故障延迟机制)
    1. 第一次选择队列
        1. sendWhichQueue自增
        2. 对队列大小取模
        3. 返回对应的队列
    2. sendWhichQueue
    3. 遍历消息队列集合
    4. sendWhichQueue自增后取模
    5. 规避上次Broker队列
4. 发送消息
    1. 获得broker网络地址信息
    2. 没有找到从NameServer更新broker网络地址信息
    3. 为消息分类唯一ID
    4. 消息大小超过4K,启用消息压缩
    5. 如果是事务消息,设置消息标记MessageSysFlag.TRANSACTION_PREPARED_TYPE
    6. 如果注册了消息发送钩子函数,在执行消息发送前的增强逻辑
    7. 同步或异步发送
    8. 如果有钩子，发送完执行钩子

## 消费消息流程
就不那么详细了
1. 客户端发起拉取请求
2. 消息服务端Broker组装信息
3. 消息拉取客户端处理消息

这里有一点：
拉取长轮询分析：源码上实际上还是个监听器
- RocketMQ未真正实现消息推模式，而是消费者主动向消息服务器拉取消息，RocketMQ推模式是循环向消息服务端发起消息拉取请求，如果消息消费者向RocketMQ拉取消息时，消息未到达消费队列时，如果不启用长轮询机制，则会在服务端等待shortPollingTimeMills时间后（挂起）再去判断消息是否已经到达指定消息队列，如果消息仍未到达则提示拉取消息客户端PULL—NOT—FOUND（消息不存在）；
- 如果开启长轮询模式，RocketMQ一方面会每隔5s轮询检查一次消息是否可达，同时一有消息达到后立马通知挂起线程再次验证消息是否是自己感兴趣的消息，如果是则从CommitLog文件中提取消息返回给消息拉取客户端，否则直到挂起超时，超时时间由消息拉取方在消息拉取是封装在请求参数中，PUSH模式为15s，PULL模式通过DefaultMQPullConsumer#setBrokerSuspendMaxTimeMillis设置。RocketMQ通过在Broker客户端配置longPollingEnable为true来开启长轮询模式。


# zookeeper
## 什么是Zookeeper？
ZooKeeper 是一个开源的分布式协调服务

## Zookeeper使用场景？
1. 数据发布/订阅、
2. 负载均衡、
3. 命名服务、
4. 分布式协调/通知、
5. 集群管理、
6. Master 选举、
7. 分布式锁和分布式队列等功能。

## Zookeeper的特点
- 顺序一致性： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
- 原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
- 单一系统映像 ： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
- 可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

## Zookeeper的原理？
ZAB 协议&Paxos算法
ZAB协议包括两种基本的模式：**崩溃恢复**和**消息广播**。当整个 Zookeeper 集群刚刚启动或**者Leader服务器宕机**、**重启**或者网络故障导致**少于过半的服务器与 Leader 服务器保持正常通信**时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。当集群中超过**半数机器与该 Leader 服务器完成数据同步**之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。

## 选择算法和流程
目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：

1. 服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。
2. 服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
3. 服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。
4. 服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。
5. 服务器5启动，后面的逻辑同服务器4成为follower。

[https://www.cnblogs.com/wuzhenzhao/p/9983231.html](https://www.cnblogs.com/wuzhenzhao/p/9983231.html)

## 客户端源码
- ZooKeeper实例 ：客户端入口
- ClientWatcherManager ：客户端Watcher管理器
- HostProvider：客户端地址列表管理器
- ClientCnxn：客户端核心线程。包含两个线程，即SendThread和EventThread。前者是一个I/O线程，主要负责ZooKeeper客户端和服务端之间的网络I/O通信，后者是一个事件线程，主要负责对服务端事件进行处理。
[http://www.guobingwei.tech/articles/2019/03/15/1552608908888.html](http://www.guobingwei.tech/articles/2019/03/15/1552608908888.html)

## 服务端源码
[http://www.guobingwei.tech/articles/2019/03/19/1552949363416.html](http://www.guobingwei.tech/articles/2019/03/19/1552949363416.html)
[http://www.guobingwei.tech/articles/2019/03/23/1553295398628.html](http://www.guobingwei.tech/articles/2019/03/23/1553295398628.html)

## 选举源码
[http://www.guobingwei.tech/articles/2019/03/29/1553815655905.html](http://www.guobingwei.tech/articles/2019/03/29/1553815655905.html)

## 常见面试题
[https://www.cnblogs.com/ibigboy/p/11356221.html](https://www.cnblogs.com/ibigboy/p/11356221.html)


# 限流
## 为什么选择Sentinel？
Sentinel是一个面试分布式架构的轻量级服务保护框架，主要以流量控制、熔断降级、系统负载保护等多个维度。

隔离策略：信号量隔离（并发线程数限流）

熔断策略：
1. 基于响应时间
2. 异常比率
3. 异常数

限流：基于QPS限流

控制台：查看秒级监控、机器发现等。

## 服务限流
当**系统资源不够，不足以应对大量请求**，对系统按照预设的规则进行流量限制或功能限制

## 服务熔断
当**调用目标服务的请求和调用大量超时或失败，服务调用方为避免造成长时间的阻塞造成影响其他服务**，后续对该服务接口的调用不再经过进行请求，直接执行本地的默认方法

## 服务降级
**为了保证核心业务在大量请求下能正常运行，根据实际业务情况及流量，对部分服务降低优先级**，有策略的不处理或用简单的方式处理

## 为什么熔断降级
系统承载的访问量是有限的，如果不做流量控制，会导致系统资源占满，服务超时，从而所有用户无法使用，通过服务限流控制请求的量，服务降级省掉非核心业务对系统资源的占用，最大化利用系统资源，尽可能服务更多用户

## 和Hystrix对比
![](https://imgkr.cn-bj.ufileos.com/8f2cf909-4c41-47c3-89d9-d6eb2676a519.png)

**值得补充的是**：相比 Hystrix 基于线程池隔离进行限流，这种方案**虽然隔离性比较好，但是代价就是线程数目太多，线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响**。

Sentinel 并发线程数限流不负责创建和管理线程池，而是**简单统计当前请求上下文的线程数目，如果超出阈值，新的请求会被立即拒绝，效果类似于信号量隔离**。

[官网补充](http://dubbo.apache.org/zh-cn/blog/sentinel-introduction-for-dubbo.html)


# 常问的算法
## paxos算法
> 要讲这个算法，还要先扯背景：在常见的分布式系统中，总会发生诸如机器宕机或网络异常（等情况。Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。

> 其实在整个提议和投票过程当中，主要的角色就是“提议者”和“接受者”

该算法大致流程：其实分为两个阶段

1. 因为存在多个“提议者”Proposer，如果都提意见，那么“接受者”Acceptor不就炸掉了嘛？到底接受谁啊？所以，要先明确哪个“提议者”是领袖，最厉害的那个，先把这个给挑出来。尽早的让意见统一，并且早点形成多数派。
2. 由上阶段选出的意见领袖提出提议，“接受者”反馈意见。如果多数“接受者”接受了一个提议，那么这个提议就通过了。

[例子](https://ocavue.com/paxos.html#%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C%E7%9A%84%E4%BE%8B%E5%AD%90)


## ZAB
- ZAB协议包括两种基本的模式：**崩溃恢复**和**消息广播**。
- 当整个 Zookeeper 集群刚刚启动或**者Leader服务器宕机**、**重启**或者网络故障导致**少于过半的服务器与 Leader 服务器保持正常通信**时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。
- 当集群中超过**半数机器与该 Leader 服务器完成数据同步**之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。

## zk的leader选举算法和流程
目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：

1. 服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。
2. 服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
3. 服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。
4. 服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。
5. 服务器5启动，后面的逻辑同服务器4成为follower。

[https://www.cnblogs.com/wuzhenzhao/p/9983231.html](https://www.cnblogs.com/wuzhenzhao/p/9983231.html)

## raft

[https://zhuanlan.zhihu.com/p/66441389](https://zhuanlan.zhihu.com/p/66441389)

## Redlock

假设有5个实例

1. 比如过期时间为TTL：10min
2. 记录当前时间：比如T1 = 12:00
3. 客户端分别向5个实例获取锁，比如申请锁的时间依次为：12:01...12:05,最后获取实例的锁为T2:12:05（获取锁的超时时间要远远小于过期时间，防止死等。）
4. 如果获取锁的实例大于3个（过半机制），那么就相当于获取到锁了，该锁的真正的有效时间为TTL-(T2-T1) = 5min
5. 如果客户端由于某些原因获取锁失败，便会开始解锁所有redis实例；因为可能已经获取了小于3个锁，必须释放，否则影响其他client获取锁

## 布隆过滤器原理
- 布隆过滤器可以检查值是 “可能在集合中” 还是 “绝对不在集合中”。
- 布隆过滤器（Bloom Filter）本质上是由长度为 m 的位向量或位列表（仅包含 0 或 1 位值的列表）组成，最初所有的值均设置为 0
- 为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”

总结：当我们搜索一个值的时候，若该值经过 K 个哈希函数运算后的任何一个索引位为 ”0“，那么该值肯定不在集合中。但如果所有哈希索引值均为 ”1“，则只能说该搜索的值可能存在集合中。
[5分钟搞懂布隆过滤器，亿级数据过滤算法你值得拥有！](https://juejin.im/post/5de1e37c5188256e8e43adfc)

## JWT
[JWT的优缺点](https://snailclimb.gitee.io/javaguide/#/docs/system-design/authority-certification/JWT-advantages-and-disadvantages)

## 限流算法
[https://zhuanlan.zhihu.com/p/95066428](https://zhuanlan.zhihu.com/p/95066428)

# 项目
## 微服务在线班车预约平台

### 项目描述
该平台是针对电子科技大学班车预约平台利用最新的技术进行重构。其中主要提供沙河和清水河的班车场次的功能、下单功能、支付功能、退款功能等，并且按照学生需求增加相应的功能，比如未支付订单列表，未支付订单超时自动取消等。

### 设计技术
> 1. 采用Dubbo的架构开发，整个项目分为用户、班车、订单、支付四个服务，达到易维护的效果
> 2. 基于 JWT 的 SSO 单点登录，并依携带的 Token 可以访问系统中其他服务，采用 Redis 缓存绑定用户，达到用户登录一次处处能访问各个系统。
> 3. 采用 Redis 的 list 数据结构缓存班车场次列表，并基于 Spring 定时器优化班车场次到点更新班车 状态的业务，最后配合阿里巴巴开源的 Sentinel 中间件进行接口限流达到高并发、高可用的效果。
> 4. 下单和支付服务均采用基于阿里巴巴开源的 RocketMQ 消息中间件保持数据的最终一致性，并且 采用 Redis 缓存维持 RocketMQ 消息的幂等性，接着采用 RocketMQ 和 Sentinel 进行接口限流维护系统的稳定性，最后采用 Redis 的监听 key 键过期事件保证未支付订单超时自动取消业务，达到高 并发、高可用的效果。
> 5. 采用 Dubbo 的负载均衡机制将班车服务、订单服务分配到不同的服务器上，达到高性能的效果。

#### 显示场次列表的业务逻辑

逻辑：
- 找出符合当前天(比如，5.30)（说明，只有当天的车次）
- 找出大于等于当前时间的场次（比如，数据库8点有一场，目前时间为7点，它就符合）
- 找出状态为getBusStatus的场次，一般是还未发车的场次，（比如0，1）（0:沙河，1:清水河）

#### 判断座位是否已重复业务逻辑

- 根据场次id查找当前数据库中的该场次的座位
- 使用HashSet的集合判断当前座位和数据库中的座位是否重复

#### 回退座位的业务逻辑
- 根据场次id查找当前数据库中的该场次的座位
- 使用HashSet的集合判断当前座位和数据库中的座位是否重复
- 重复则移除


### 下单和支付
#### 下单逻辑

- 判断座位，如果重复，直接退出，否则下一步
- 更新座位，如果没有异常，这是写操作
- 计算总金额，如果没有异常
- 添加订单

#### 支付逻辑

- 先核对支付密码是否正确，若不对，则返回
- 核对余额是否够，若不够，则返回 
- 更改订单状态（->依支付）

#### 退款逻辑

- 退回金额，读取用户金额，计算金额，更新
- 退回座位
- 更改订单状态(->已退款)



### 上线bug

> 项目上线之后，大概将近一个月，我点击车次列表页面，突然什么都没有了，于是就开始找哪个不顺眼的家伙搞的鬼。

#### 起因

访问主页[http://47.104.22.225:8080/home](http://47.104.22.225:8080/home)


一直加载中，于是我看一下响应信息。

#### 查看一下gateway的日志
- 终端显示不长，于是我将日志用vscode打开看

```log
org.apache.dubbo.rpc.RpcException: No provider available from registry 39.108.93.119:2181 for service com.stylefeng.guns.rest.bus.IBusService on consumer 192.168.31.221 use dubbo version 2.7.4.1, please check status of providers(disabled, not registered or in blacklist).
```

类似于这样的信息，说我们的bus服务没有注册。

> 注意：出事之前，几个服务都在的呀，怎么今天bus突然不在了。于是，我不相信，我就去dubbo后台看了一下...


**此时，还真没有bus服务**
![](https://imgkr.cn-bj.ufileos.com/3eb38910-64b5-439c-8437-c155d50857d2.png)


**于是乎，俺又不想重新启动服务，毕竟你看**

- 终端输入`ps -ef | grep guns-bus`
- 我们看到了惊人的一幕
```shell
pch      2003942       1  0 4月16 ?       06:10:54 java -jar guns-bus-0.0.1.jar
```

#### 猜测

##### DubboAdmin展示？
好像没问题吧？这样的话，其他三个也应该不存在的啊

##### 注册中心，bus节点丢了

- 查看日志，当天出现zk出现了大量的超时，原因是当天的zk**主节点**宕机了。

##### 找原因

**问题是否出现在了dubbo对zk重连恢复数据这块，开始查源码。注册中心源码ZookeeperRegistry。**

1. 连接注册zk：通过zkclient添加zk状态监听。并且继承了FailbackRegistry各种失败重试。
2. zk客户端：默认使用CuratorZookeeperClient实现
3. 重试任务：注册重新失败重连任务FailbackRegistry中的DubboRegistryFailedRetryTimer，默认5秒检查一次是否需要失败恢复


#### 总结一波
通过三部分的代码我们可以推断，如果zk状态监听与恢复部分出现问题可能会导致数据丢失问题。于是查看相关的api并且尝试查看dubbo社区的问题与bug，果然发现了类似问题的修改与原因分析：[https://github.com/apache/dubbo/pull/5135](https://github.com/apache/dubbo/pull/5135)

原因：
> 如果ZNode数据已经存在，在会话超时期间，此时我们将重建一个数据节点，这个重复的异常原因可能是由于zk server中老的超时会话依然持有节点导致该节点的delete删除事件延迟，并且zk server还没有来得及去执行删除，可能由这种场景引起。在这个情景下，我们可以本地删除节点后再创建恢复节点数据。

其实说白了：
> 如果会话断开连接又重新连接成功。断开连接发出的删除节点事件，**因为延迟原因走在了重新连接恢复节点事件的后面**。**导致重新连接后没能成功恢复节点**。也就是说，即使恢复了，又被删除了，也就是我么见到的，provider有三个节点服务正常，但是zk注册中心中的提供者节点数据丢失，导致出现该节点对其他订阅者不可见的现象

```java
    protected void createEphemeral(String path, String data) {
        byte[] dataBytes = data.getBytes(CHARSET);

        try {
            ((ACLBackgroundPathAndBytesable)this.client.create().withMode(CreateMode.EPHEMERAL)).forPath(path, dataBytes);
        } catch (NodeExistsException var5) {
            logger.warn("ZNode " + path + " already exists, since we will only try to recreate a node on a session expiration, this duplication might be caused by a delete delay from the zk server, which means the old expired session may still holds this ZNode and the server just hasn't got time to do the deletion. In this case, we can just try to delete and create again.", var5);
            this.deletePath(path);
            this.createEphemeral(path, data);
        } catch (Exception var6) {
            throw new IllegalStateException(var6.getMessage(), var6);
        }

    }
```

**人家源码的warn写的是真清楚**...

#### 定位cpu过高的线程或者位置

> 这里要用到几个命令了，比如top，jstack等。

##### 查看一波
- 终端输入`top -H`

![](https://imgkr.cn-bj.ufileos.com/e69d6335-c260-4d69-9f4d-840b7427cce5.png)
- 类似于长这样，但是有些含义就不解释了，请上互联网
- 我就挑它吧`1227027`
- 终端输入`top -Hp 1227027`
![](https://imgkr.cn-bj.ufileos.com/d703c8ae-a3a8-4eed-ad57-6c3440dd4ea7.png)
- 这里我也就不介绍了，找一个`1227029`
- `printf "%x\n" 1227029`结果是：`12b915`
- `jstack -l 1227027| grep 0x12b915 -A 10`

```shell
"DestroyJavaVM" #84 prio=5 os_prio=0 tid=0x00007f69f800b7c0 nid=0x12b915 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"BrokerFastFailureScheduledThread1" #83 prio=5 os_prio=0 tid=0x00007f69f8b29050 nid=0x12ba0a runnable [0x00007f68b6bec000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x0000000080594a60> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
```
**以上就是举个例子** ...

## 面向多源藏汉信息采集、融合和分析系统平台

### 项目描述
该平台是面向藏汉多源信息的采集和挖掘，主要提供的功能为自动采集相关多源数据、搜索引擎和数据分析等功能。

### 设计技术
- 采用 Python 开发的 Scrapy 爬虫组件，其利用 URL 设计布隆过滤器，达到了数据去重的效果。
- 将采集的信息存入 MongoDB，达到了将非关系数据存储和稳定提供给分析平台的效果。

### 有可能聊计算机网络的知识

### Scrapy是什么？
Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。只需要编写很少的代码就能实现抓取功能，另外由于它底层用了twisted，性能也非常优越。使用Scrapy框架编写的抓取代码，可读性很强，非常利于维护，是现在最流行的抓取框架。

- Scrapy Engine(引擎)：负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。
- Scheduler(调度器)：它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。
- Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，
- Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，
- Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.
- Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。
- Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）

### 布隆过滤器原理
- 布隆过滤器可以检查值是 “可能在集合中” 还是 “绝对不在集合中”。
- 布隆过滤器（Bloom Filter）本质上是由长度为 m 的位向量或位列表（仅包含 0 或 1 位值的列表）组成，最初所有的值均设置为 0
- 为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”

总结：当我们搜索一个值的时候，若该值经过 K 个哈希函数运算后的任何一个索引位为 ”0“，那么该值肯定不在集合中。但如果所有哈希索引值均为 ”1“，则只能说该搜索的值可能存在集合中。
[5分钟搞懂布隆过滤器，亿级数据过滤算法你值得拥有！](https://juejin.im/post/5de1e37c5188256e8e43adfc)


### MongoDB是什么？
MongoDB 是一种NoSQL 数据库，存储的数据对象由键值对组成。MongoDB 所有存储在集合中的数据都是 BSON 格式。BSON 是一种类似 JSON 的二进制形式的存储格式，是 Binary JSON 的简称。

#### 和Redis的区别是什么？
- MongoDB 更类似 MySQL，支持**字段索引、游标操作**，其优势在于查询功能比较强大，**擅长查询 JSON 数据**，能存储海量数据，但是不支持事务。

- Redis 是一个开源（BSD许可）的，**内存中的数据结构存储系统**，它可以用作数据库、缓存和消息中间件。
- Redis 数据**全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU 算法删除数据**。
- Mongodb的所有数据实际上是**存放在硬盘的**，所有要操作的数据通过mmap的方式映射到内存某个区域内。
- Redis所有数据都是放在内存中的，持久化是使用RDB方式或者aof方式。

#### MongoDB为什么采用B树
- B+树查询时间复杂度固定是logn，B-树查询复杂度最好是 O(1)。
- B+树更适合外部存储，也就是磁盘存储。由于内节点无 data 域，每个节点能索引的范围更大更精确。

在聊mongodb是什么
MongoDB 是文档型的数据库，是一种 nosql，它使用类 Json 格式保存数据。
MongoDB使用B-树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于Mysql。

再说说MySQL
Mysql作为一个关系型数据库，数据的**关联性**是非常强的，**区间访问**是常见的一种情况，B+树由于**数据全部存储在叶子节点，并且通过指针串在一起，这样就很容易的进行区间遍历甚至全部遍历**。

## 基于 BP 神经网络个性化搜索引擎软件

### 项目描述
该平台是面向某大学的新闻官网提供个性化搜索服务如，用户查询、管理员管理 BP 神经网络算法。 其中管理员管理 BP 神经网络算法是该平台“个性化”的功能体现。

### 设计技术
- 采用 Vue 和 Flask 搭建前后端分离，达到了结构简单、业务分工且易维护等效果。
- 采用 BP 神经网络搭建文章个性化排序模型，并针对于某大学通过爬虫组件采集文章制作数据集。
- 采用 Elasticsearch 分布式、开源的搜索数据分析引擎建立模型，达到存储（所有基本类型）、分 析、查询、汇总、聚合等效果。


### 为什么使用Vue？
- 简单
- 易用
- 数据双向绑定
- 渐进式JavaScript
- 可以在谈一谈和react的区别

### 为什么使用flask？
- 简单
- 易用
- 纯python

### 为什么使用BP神经网络？
- 它可以通过不断的训练，使得让网络更加智能。
- 它可以模拟并很友好的支持非线性问题
- 简单：三层（输入，隐藏，输出）
- 可以举个例子最好。。。

### 为什么采用ElasticSearch？
- Elasticsearch **分布式、开源的搜索数据分析引擎**建立模型，达到存储（所有基本类型）、分析、查询、汇总、聚合等效果。
- **精确匹配和相关性匹配**（比如我搜「莎士比亚」，我要的肯定不只是精精确确包含「莎士比亚」的文稿，我可能还要搜「莎翁」、「Shakespeare」、「哈姆雷特」、「罗密欧和朱丽叶」、「威尼斯的商人」…   又比如我输错了，输成「莎士笔亚」，「相关性匹配」可以智能的帮我优化为「莎士比亚」，返回对应的搜索结果。）
- 搜索和分析，不只是搜索，还有分析
- Mysql基于B+树索引，来实现快速检索，ES则基于倒排索引，对于文档搜索来说，倒排索引在性能和空间上都有更加明显的优势。

### BP和ES怎么结合的？
- 先说BP吧，以文章的标题，内容，词频建立模型
- 首先ES检索出文章，其次使用BP进行预测文章的权值
- 最后按照权值进行排序，将结果返回给用户

## 基于数据爬虫与图像识别的大学一卡通业务交易平台

### 项目描述
该平台是面向大学的一卡通管理，其中包括用户登陆、查询剩余金额、查询消费记录、查询宿舍电费 和缴纳宿舍电费插 5 个功能。

### 设计技术
- 采用 PyQT5 组件库搭建用户界面，并设计用户登录、查询剩余金额、查询消费记录、查询宿舍电 费和缴纳宿舍电费 5 个功能，达到了跨平台的效果。
- 采用 CNN 搭建解决学校网站登录验证码的自动识别模型，其中针对于某大学通过爬虫组件不断采 集登录验证码制作数据集，正确率接近为 94%。

### 为什么使用CNN？
良好的容错能力，可处理环境信息复杂，背景知识不清楚，推理规则不明确情况下的问题，允许样品有较大的缺损，运行速度快，自适应性能好，具有较高的分辨率。 **它是通过结构重组和减少权值将特征抽取功能融合进多层感知器，省略识别前复杂的图像特征抽取过程**。


# 设计模式
## 懒汉(双重校验)
```java
class Singleton {
    private static volatile Singleton instance = null;

    private Singleton() {
    }

    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

## 工厂
> 定一个面条抽象类

```java
abstract class INoodles {
    /**
     * 描述每种面条长什么样的...
     */
    public abstract void desc();
}

```
> 兰州拉面

```java
class LzNoodles extends INoodles {

    @Override
    public void desc() {
        System.out.println("兰州拉面,成都的好贵 家里的才5-6块钱一碗");
    }
}
```
> 泡面

```java
class PaoNoodles extends INoodles {

    @Override
    public void desc() {
        System.out.println("泡面可还行...");
    }
}
```

> 工厂(面馆)

```java
class SimpleNoodlesFactory {
    public static final int TYPE_LZ = 1; // 兰州拉面
    public static final int TYPE_PAO = 2; // 泡面撒
    // 提供静态方法
    public static INoodles createNoodles(int type) {
        switch (type) {
            case TYPE_LZ:return new LzNoodles();
            case TYPE_PAO:return new PaoNoodles();
            default:return new ZaNoodles();
        }
    }
}
```

> 测试

```java
public class FactoryMode {
    public static void main(String[] args) {
        INoodles noodles = SimpleNoodlesFactory.createNoodles(SimpleNoodlesFactory.TYPE_PAO);
        noodles.desc();
    }
}
```

## 代理
> 所谓代理模式是指客户端并不直接调用实际的对象，而是通过调用代理，来间接的调用实际的对象。 一般是因为客户端不想直接访问实际的对象，或者访问实际的对象存在困难，因此通过一个代理对象来完成间接的访问。

### 静态
> 主题

```java
interface Subject {
    void visit();
}
```
> 实现Subject的目标对象类

```java
class RealSubject implements Subject {
    private String name = "dreamcat";
    @Override
    public void visit() {
        System.out.println(name);
    }
}
```

> 目标对象的代理类也得实现该接口

```java
class ProxySubject implements Subject {

    private Subject subject;

    public ProxySubject(Subject subject) {
        this.subject = subject;
    }

    @Override
    public void visit() {
        subject.visit();
    }
}
```

### 动态
```java
class DynamicProxy {

    private Object target;

    DynamicProxy (Object target) {
        this.target = target;
    }

    public Object getProxyInstance() {
        return Proxy.newProxyInstance(
            target.getClass().getClassLoader(), 
            target.getClass().getInterfaces(), 
            (proxy, method, args) -> {
                System.out.println("我是动态代理，兄弟...");
                Object value = method.invoke(target, args);
                System.out.println("代理结束了，兄弟...");
                return value;
            });
    }

}

```

### CGlib
```java
class RealSubject2 {
    void visit() {
        System.out.println("cat visit Dream");
    }
}

class CgLibProxy implements MethodInterceptor {
    private Object target;

    CgLibProxy(Object target) {
        this.target = target;
    }

    public Object getProxyInstance() {
        // 1. 创建一个工具类
        Enhance en = new Enhance();
        // 2. 设置父类
        en.setSuperClass(target.getClass());
        // 3. 设置回调函数
        en.setCallback(this);
        // 4. 创建子类对象，代理对象
        return en.create();
 
    }

    public Object intercept(Object arg0, Method method, Object[] args, MethodProxy arg3) Throwable{
        System.out.println("Cglib代理...");
        Object value = method.invoke(target, args);
        System.out.println("结束");
        return value;
    }
}
```

> 测试

```java
public class ProxyMode {
    public static void main(String[] args) {
        // 静态代理
        ProxySubject proxySubject = new ProxySubject(new RealSubject());
        proxySubject.visit();

        // 动态代理
        Subject proxyInstance = (Subject)new DynamicProxy(new RealSubject()).getProxyInstance();
        proxyInstance.visit();

        // CG
        RealSubject2 subject2 = (RealSubject2)new CgLibProxy(new RealSubject2()).getProxyInstance();
        subject2.visit();
    }
}

```

[https://www.cnblogs.com/carpenterlee/p/8241042.html](https://www.cnblogs.com/carpenterlee/p/8241042.html)




# 大数据和空间限制与系统设计
## 100亿黑名单URL，每个64B,判断一个URL是否在黑名单中
[布隆过滤器...](https://juejin.im/post/5c959ff8e51d45509e2ccf84)

## 2GB内存在20亿整数中找到出现次数最多的数
[哈希多个文件](https://blog.csdn.net/u013246898/article/details/52033937)

## 40亿个非负整数中找到没有出现的数
[分区加位图](https://blog.csdn.net/u010456903/article/details/48806947)

## 找到100亿个URL中重复的URL/海量搜索词汇，找到最热TOP100词汇的方法
[哈希分流](https://blog.csdn.net/weixin_41362649/article/details/94601249)

## 40亿个无符号整数，1GB内存，找到所有出现两次的数/10MB内存，找到40亿整数的中位数
[位图](https://blog.csdn.net/liyutaogege/article/details/104394790)

## 设计短域名系统，将长URL转化成短的URL.
利用放号器，初始值为0，对于每一个短链接生成请求，都递增放号器的值，再将此值转换为62进制（a-zA-Z0-9），比如第一次请求时放号器的值为0，对应62进制为a，第二次请求时放号器的值为1，对应62进制为b，第10001次请求时放号器的值为10000，对应62进制为sBc。
[发号器](https://blog.csdn.net/u010870518/article/details/80026452)

# 智力题
- 赛马找最快<腾讯高频>
- 砝码称轻重
- 绳子两头烧
- 犯人猜颜色
- 猴子搬香蕉
- 高楼扔鸡蛋<谷歌>
- 轮流拿石子<头条>
- 蚂蚁走树枝
- 海盗分金币<不常见>
- 三个火枪手
- 囚犯拿豆子
- 学生猜生日<笔试高频>

- [分硬币](https://blog.csdn.net/we_are_the_world_123/article/details/78012100)

[答案解析](https://www.nowcoder.com/discuss/262595)

# 操作系统
## 进程和线程的区别

- 进程是程序的⼀次执⾏过程，是系统运⾏程序的基本单位，因此进程是动态的。系统运⾏⼀个程序即是 ⼀个进程从创建，运⾏到消亡的过程。
- 线程是⼀个⽐进程更⼩的执⾏单位
- ⼀个进程在其执⾏的过程中可以产⽣多个线程
- 与进程不同的是同类的多个线程共享进程的堆和⽅法区资源，但每个线程有⾃⼰的程序计数器、 虚拟机栈和本地⽅法栈，所以系统在产⽣⼀个线程，或是在各个线程之间作切换⼯作时，负担要 ⽐进程⼩得多，也正因为如此，线程也被称为轻量级进程

⽐如：当我们启动 main 函数时其实就是启动了⼀个 JVM 的进程，⽽ main 函数所在的线程就是这个进程中的⼀个线程，也称主线程。

## 协程？

协程是一种用户态的轻量级线程, 我们的server的发展如下：IO密集型应用：多进程 -> 多线程 ->事件驱动 ->协程 

协程拥有自己的寄存器上下文和栈. 协程调度切换时，将寄存器上下文和栈保存到其他地方，然后去做其他工作，当你的IO解除之后切回原来的状态，恢复先前保存的寄存器上下文和栈。

协程能保留上一次调用时的状态(既所有局部状态的一个特定组合)，每次过程重入时，就相当于进入上一次调用的状态. 也就是相当于LOL艾克的R。

优点：

- 跨平台
- 无需线程上下文切换的开销
- 无需原子操作锁定及同步的开销
- 方便切换控制流，简化编程模型
- 高并发+高扩展行+低成本： 一个CPU支持上万的协程都不是问题，所以很适合用于高并发处理

缺点：

- 无法利用多核资源：协程的本质是一个单线程，它不能同时将单个CPU的多个核作用上，协程需要和进程配合才能运行在多CPU上.
- 进行阻塞(Blocking)操作会阻塞到整个程序; 这一点和事件驱动一样，可以使用异步IO操作来解决.

## 进程之间的通信

> 每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。

1. 管道：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；（pipe）
2. FIFO命名管道：FIFO是一种文件类型，可以在无关的进程之间交换数据，与无名管道不同，FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。（mkfifo）
3. 消息队列：消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。
4. 信号：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
5. 信号量：信号量是一个计数器，信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
6. 共享内存：共享内存指两个或多个进程共享一个给定的存储区，一般配合信号量使用。（mmap）
7. 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。（socket）


### 进程间五种通信方式的比较
1. 管道：速度慢，容量有限，只有父子进程能通讯。
2. FIFO：任何进程间都能通讯，但速度慢。
3. 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题。
4. 信号量：不能传递复杂消息，只能用来同步。
5. 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。

### 为什么共享内存快
采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。

内核支持多种共享内存方式，如mmap()系统调用，Posix共享内存，以及系统V共享内存

### 共享内存的实现(mmap)
mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。

### 系统调用mmap共享内存的两种方式
- 使用普通文件提供的内存映射：适用于任何进程之间；
- 使用特殊文件提供匿名内存映射：适用于具有亲缘关系的进程之间； 由于父子进程特殊的亲缘关系，在父进程中先调用mmap()，然后调用fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区域进行通信了。

## 死锁
- 互斥
- 占有等待
- 不能剥夺
- 循环等待

举例子：还是吃饭（兄妹吃饭哈）
比如有两个菜哈，土豆丝和西红柿鸡蛋
首先哥哥先把土豆丝端到自己旁边，而妹妹把西红柿鸡蛋端到自己旁
此时呢？哥哥也想吃妹妹的西红柿鸡蛋，但是妹妹还没放回去，妹妹其实也想吃哥哥的土豆丝，但是哥哥也没放回去，俩人等了老半天，一直在等，等到天黑都没放回去。害

解决：
预防死锁、避免死锁、检测死锁、解除死锁 、鸵鸟策略

## 用户态和内核态

> 用户态就是提供应用程序运行的空间，为了使应用程序访问到内核管理的资源例如CPU，内存，I/O。内核必须提供一组通用的访问接口，这些接口就叫**系统调用。**

**系统调用**时操作系统的最小功能单位。根据不同的应用场景，不同的Linux发行版本提供的系统调用数量也不尽相同，大致在240-350之间。这些系统调用组成了用户态跟内核态交互的基本接口，**例如：用户态想要申请一块20K大小的动态内存，就需要brk系统调用，将数据段指针向下偏移，如果用户态多处申请20K动态内存，同时又释放呢？这个内存的管理就变得非常的复杂。**

从用户态到内核态切换可以通过三种方式：

- 系统调用，这个上面已经讲解过了。其实系统调用本身就是中断，但是软件中断，跟硬中断不同。
- 异常：如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。
- 外设中断：当外设完成用户的请求时，会向CPU发送中断信号。

## 操作系统内存管理方式，分页分段以及段页式的优缺点

### 分页管理

分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页，并为各页加以编号，从0开始，如第0页、第1页等。相应地，也把内存空间分成与页面相同大小的若干个存储块，称为(物理)块或页框(frame)，也同样为它们加以编号，如0#块、1#块等等。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“页内碎片”。

**优缺点**：**没有外部碎片，内存利用率高。但各页中内容没有关联，不利于编程和共享**。

### 分段管理

程序通过分段(segmentation)划分为多个模块，如代码段、数据段、共享段。内存每段的大小都匹配程序段，不会产生内部碎片。
**优缺点**： 可以针对不同类型的段采取不同的保护。 可以按段为单位来进行共享，包括通过动态链接进行代码共享。 **不会产生内部碎片，但会产生外部碎片，内存利用率比分页低**。

### 段页式管理

一个进程中所包含的具有独立逻辑功能的程序或数据仍被划分为段，并有各自的段号s。这反映相继承了段式管理的特征。其次，对于段s中的程序或数据，则按照一定的大小将其划分为不同的页。和页式系统一样，最后不足一页的部分仍占一页。这反映了段页式管理中的页式特征。从而，段页式管理时的进程的虚拟地址空间中的虚拟地址由三部分组成：即段号s，页号P和页内相对地址d。虚拟空间的最小单位是页而不是段，从而内存可用区也就被划分成为若干个大小相等的页面，且每段所拥有的程序和数据在内存中可以分开存放。分段的大小也不再受内存可用区的限制。
**优缺点：**既有具有独立逻辑功能的段，又以大小相同的页为内存分配单位进而不会产生外部碎片。但仍会有内部碎片。

[操作系统如管理内存](https://blog.csdn.net/hguisu/article/details/5713164)

## 页面置换算法有哪些，FIFO为什么不好？如何改进?LRU思想，手写LRU

> 地址映射过程中，若在页面中发现所要访问的页面不再内存中，则产生缺页中断。当发生缺页中断时操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。常见的置换算法有：

- 最佳置换算法（OPT）：所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。
- 先进先出置换算法（FIFO）：选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面换出，导致缺页率升高。
- 第二次机会算法：当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。
- 最近最久未使用（LRU）算法：为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。


[https://blog.csdn.net/wangsifu2009/article/details/6757352](https://blog.csdn.net/wangsifu2009/article/details/6757352)

## 虚拟内存

虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：
- 每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。
- 这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。
- 当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上。

举个小例子：
吃饭。

比如你和同学去聚餐，根据菜谱点了一堆的菜，有汤，有肉，有素材等。 大可不必一下子全做完一起送过来（如果桌子不给力，比较小，并且时间成本，饭菜都凉了等），比如，同学想吃肉哈？不想先喝汤，那就把肉类端上来，对吧？等同学又想喝汤了，就把汤做一下端过来。

[https://blog.csdn.net/lvyibin890/article/details/82217193](https://blog.csdn.net/lvyibin890/article/details/82217193)

## 同步和互斥的区别
### 同步
同步，又称直接制约关系，是指多个线程（或进程）为了合作完成任务，必须严格按照规定的 某种先后次序来运行。

### 互斥
互斥，又称间接制约关系，是指系统中的某些共享资源，一次只允许一个线程访问。当一个线程正在访问该临界资源时，其它线程必须等待。

### 信号量
信号量的本质是一种数据操作锁、用来负责数据操作过程中的互斥、同步等功能。
信号量用来管理临界资源的。它本身只是一种外部资源的标识、不具有数据交换功能，而是通过控制其他的通信资源实现进程间通信。
可以这样理解，信号量就相当于是一个计数器。当有进程对它所管理的资源进行请求时，进程先要读取信号量的值，大于0，资源可以请求，等于0，资源不可以用，这时进程会进入睡眠状态直至资源可用。

## 操作系统中进程调度策略有哪几种
- FCFS(先来先服务，队列实现，非抢占的)：先请求CPU的进程先分配到CPU
- SJF(最短作业优先调度算法)：平均等待时间最短，但难以知道下一个CPU区间长度
- 优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿；解决方案：老化
- 时间片轮转调度算法(可抢占的)：队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。
- 多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。
- 多级反馈队列调度算法：与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。

[https://blog.csdn.net/justloveyou_/article/details/78304294](https://blog.csdn.net/justloveyou_/article/details/78304294)



# 项目思考

> 碍于面试官喜欢出刁难的场景...
1. 如何确保userid是安全的？（分布式唯一ID）？ Redis的value不存一些安全信息？不怕被攻击？有意思是别人不管通过什么手段获取到userID，然后拿到token，不断的黑嘛？这哥们更狠，源码被窃取了，知道算法加密了，怎么办？

这个问题，我就。。。 我自己都没思考过，在这么短的时间内，我果断没有想出来！！ 经验不足

事后，我思考一下：
如果，我再签证的时候，我可以用版本号？ 什么意思？ 前端第一次登陆，不仅签证token，还要生成一个唯一id（可以设备唯一id和时间戳）作为版本号。

如果还刁难， 就用https的ssl存私密数据！！！！

如果说客户端一直狂刷，狂调用， 那就同一个设备id进行在一段时间内，限制他访问的次数，拿到userid不断攻击也没用

你说源码被窃取，我就～～～～～ 我就撒撒谁啊

启动其他备用源码的加密方案， 更换方案 再刁难？ 还不行？
那我就折服了！！！ 超过了我的经验和知识盲区了。

2. 幂等在redis写消费记录，如何保证写过程当中没有出现问题？出现问题怎么办？
这个问题， 一开始想的是失败就重写被， 还能咋地，没敢说出来。。 我再思考思考 ，，， 问的太刁难我了
那就这样，如果写失败了， 没写进去， 我tm当第二次消费的时候， 肯定缓存数据库是没有的，老子就查一下数据库的状态，确保万无一失是否消费过！！！ （整个消费记录表！！！）。  问的这么刁难我， 那我就数据库和Redis一起用。。 

难不成用自旋锁？

3. 如果订单过期了那一瞬间，后端的监听事件收到了，还没更改状态，用户开始支付，这个时候怎么办？当用户支付成功了，你把状态又改为失效了。

这个瞬间我就想出来了。。。。。。
瞬间就给你扯分布式锁


# Android

## Activity生命周期
Activity 类提供六个核心回调：onCreate()、onStart()、onResume()、onPause()、onStop() 和 onDestroy()。当 Activity 进入新状态时，系统会调用其中每个回调。

- onCreate()：Activity 会在创建后进入“已创建”状态，调用该方法
- onStart()：当 Activity 进入“已开始”状态时，系统会调用此回调
- onResume()：Activity 会在进入“已恢复”状态时来到前台
- onPause()：系统将此方法视为用户将要离开您的 Activity 的第一个标志（尽管这并不总是意味着 Activity 会被销毁）
- onStop()：如果您的 Activity 不再对用户可见，说明其已进入“已停止”状态
- onDestroy()：销毁 Ativity 之前，系统会先调用 onDestroy()

## Activity启动的四种模式
1. standard：标准模式：如果在mainfest中不设置就默认standard；standard就是新建一个Activity就在栈中新建一个activity实例；场景：邮件、mainfest中没有配置就默认标准模式
2. singleTop：栈顶复用模式：与standard相比栈顶复用可以有效减少activity重复创建对资源的消耗，但是这要根据具体情况而定，不能一概而论；场景：登录页面、WXPayEntryActivity、WXEntryActivity 、推送通知栏
3. singleTask：栈内单例模式，栈内只有一个activity实例，栈内已存activity实例，在其他activity中start这个activity，Android直接把这个实例上面其他activity实例踢出栈GC掉；场景：程序模块逻辑入口:主页面（Fragment的containerActivity）、WebView页面、扫一扫页面、电商中：购物界面，确认订单界面，付款界面
4. singleInstance :堆内单例：整个手机操作系统里面只有一个实例存在就是内存单例；场景：系统Launcher、锁屏键、来电显示等系统应用
